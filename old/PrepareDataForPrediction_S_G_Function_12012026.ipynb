{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10de75a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T14:39:41.021391Z",
     "start_time": "2024-07-12T14:39:40.255439Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "\n",
    "# Clear all variables in the global namespace\n",
    "# globals().clear()\n",
    "\n",
    "#########################################################################################\n",
    "# To run this code from jupyter notebook, you need some preliminary installation steps\n",
    "#\n",
    "# 1) We have to install anaconda\n",
    "#\n",
    "# 2) If installed anaconda is not detected by windows, then by this way we can set the path in environment variable \n",
    "#    (in windows11 i dint do this step but in windows 10 i have to do manually)\n",
    "#    https://www.geeksforgeeks.org/how-to-setup-anaconda-path-to-environment-variable/\n",
    "#\n",
    "# 3) From anaconda prompt we have to type the following  \n",
    "#\n",
    "# > conda create -n domino\n",
    "#\n",
    "# You will be asked a question in the prompt about whether you want to create an environment called domino. We have to type \n",
    "# > y\n",
    "# \n",
    "# Then new environment will be created with the name domino. \n",
    "#\n",
    "#########################################################################################\n",
    "\n",
    "#########################################################################################\n",
    "# To start jupyter notebook\n",
    "# From anaconda prompt we have to type the following  \n",
    "#\n",
    "# > conda activate domino\n",
    "# > jupyter notebook\n",
    "# \n",
    "# Then new environment will be created with the name domino. \n",
    "#\n",
    "#########################################################################################\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run('C:\\\\Users\\\\s.nasini\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\pip install pyarrow')\n",
    "subprocess.run('C:\\\\Users\\\\s.nasini\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\pip install pandas')\n",
    "subprocess.run('C:\\\\Users\\\\s.nasini\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\pip install torch torchvision torchaudio')\n",
    "subprocess.run('C:\\\\Users\\\\s.nasini\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Scripts\\\\pip install scipy')\n",
    "\n",
    "### To install libaries in new jupyter environment run the below from a new jupyter notebook cell##\n",
    "!pip install pyarrow\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install pytz\n",
    "############\n",
    "\n",
    "\n",
    "23/09/2025\n",
    "S function changes from t-w to t\n",
    "S function missing status during time\n",
    "\n",
    "############\n",
    "\n",
    "\n",
    "10/10/2025\n",
    "G function plus changes from \"t=1,2,3\" to \"t=0,1,2\"\n",
    "\n",
    "############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce70e83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:16:33.082137Z",
     "start_time": "2025-02-16T11:16:31.954326Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import gc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606737b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:16:33.092264Z",
     "start_time": "2025-02-16T11:16:33.084142Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Data\n",
    "################################################################################\n",
    "\n",
    "# DATA_DIR =  '../data/'\n",
    "DATA_DIR = r'C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data'\n",
    "\n",
    "#project variables\n",
    "# EFFECTIVE_DATA_FILE_PATH = os.path.join(DATA_DIR, 'TMS_EFFECTIVES_2023_04_05_06_V240206.csv')\n",
    "# JUSTIF_DATA_FILE_PATH = os.path.join(DATA_DIR, 'TMS_JUSTIF_2023_04_05_06_V240430.csv')\n",
    "EFFECTIVE_DATA_FILE_PATH = os.path.join(DATA_DIR, 'TMS_EFFECTIVES_2023_04_05_06_V240206.csv')\n",
    "JUSTIF_DATA_FILE_PATH = os.path.join(DATA_DIR, 'JUSTIF_test.csv')\n",
    "MINUTE= 5\n",
    "#T_DATATYPE = 'int64'\n",
    "T_DATATYPE ='int32'\n",
    "\n",
    "TIME_FREQUENCY='5min'\n",
    "#TIME_FORMAT='%Y-%m-%d %H:%M'\n",
    "TIME_FORMAT='%H:%M'\n",
    "\n",
    "EFFECTIVE_DF_CLEANED_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_cleaned_' + TIME_FREQUENCY + '.parquet')\n",
    "EFFECTIVE_DF_DEPARTURE_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_D_i_' + TIME_FREQUENCY + '.parquet')\n",
    "\n",
    "EFFECTIVE_DF_DA_IT_SMALL_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_DA_it_small' + TIME_FREQUENCY + '.parquet')\n",
    "\n",
    "EFFECTIVE_DF_DA_IT_W_FREIGHT_FILE_PATH  = os.path.join(DATA_DIR, 'Effective_df_DA_it_with_freight_' + TIME_FREQUENCY + '.parquet')\n",
    "EFFECTIVE_DF_A_IT_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_a_it_' + TIME_FREQUENCY + '.parquet')\n",
    "EFFECTIVE_DF_A_IT_W0_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_a_it_w0_' + TIME_FREQUENCY + '.parquet')\n",
    "EFFECTIVE_DF_D_IT_FILE_PATH = os.path.join(DATA_DIR, 'Effective_df_d_it_' + TIME_FREQUENCY + '.parquet')\n",
    "\n",
    "EFFECTIVE_DF_STATS_FILE_PATH = os.path.join(DATA_DIR,'effective_df_statistics_'+ TIME_FREQUENCY + '.csv')\n",
    "EFFECTIVE_DF_STATS_DA_IT_FILE_PATH = os.path.join(DATA_DIR,'effective_df_D_it_with_freight_statistics_'+ TIME_FREQUENCY + '.csv')\n",
    "\n",
    "FUNCTION_S_R_W0_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_function_S_r_w0_' + TIME_FREQUENCY + '.parquet')\n",
    "\n",
    "## Delay file path\n",
    "TOTAL_DELAY_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_total_delay_' + TIME_FREQUENCY + '.parquet')\n",
    "PRIMARY_DELAY_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_primary_delay_' + TIME_FREQUENCY + '.parquet')\n",
    "PRIMARY_DELAY_CLEANED_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_primary_delay_cleaned_' + TIME_FREQUENCY + '.parquet')\n",
    "SECONDARY_DELAY_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_secondary_delay_' + TIME_FREQUENCY + '.parquet')\n",
    "SECONDARY_DELAY_CLEANED_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_secondary_delay_cleaned_' + TIME_FREQUENCY + '.parquet')\n",
    "\n",
    "ENDODATA_WITH_G_FILE_PATH  = os.path.join(DATA_DIR, 'Endogenous_data_with_valid_G_values_' + TIME_FREQUENCY + '.parquet')\n",
    "ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH  = os.path.join(DATA_DIR,'Endogenous_data_with_valid_G_values_prim_sec_delay_' + TIME_FREQUENCY + '.parquet')\n",
    "REGRESSION_INPUT_VALID_G_FILE_PATH =  os.path.join(DATA_DIR, 'Endogenous_data_with_valid_G_values_prim_sec_delay_observed_rec_' + TIME_FREQUENCY + '.csv')\n",
    "REGRESSION_INPUT_VALID_G_DALTA_FILE_PATH =  os.path.join(DATA_DIR, 'Endogenous_data_with_valid_G_values_prim_sec_delay_observed_Delta_rec_' + TIME_FREQUENCY + '.csv')\n",
    "\n",
    "## The below can be deleted\n",
    "REGRESSION_INPUT_ALL_ACTIVE_T_W_DUMMIES_FILE_PATH = os.path.join(DATA_DIR, 'Data_for_regression_input_all_active_t_w_dummies_' + TIME_FREQUENCY + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc8c38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:16:33.167311Z",
     "start_time": "2025-02-16T11:16:33.163556Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# This is a helper function to read parquet file. It is not used for the moment, \n",
    "# but it can be used in case we need to read the parquet files.\n",
    "################################################################################\n",
    "\n",
    "def read_function_data(fileName):\n",
    "    temp_df = pd.read_parquet(fileName, engine='fastparquet')\n",
    "    #print(temp_df.dtypes)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79685663",
   "metadata": {},
   "source": [
    "# Explore and check the correctness of effective data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727b6b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T07:58:19.731772Z",
     "start_time": "2024-11-22T07:57:06.667984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22367077, 32)\n",
      "Index(['hd_messageidentifier', 'hd_timestamp', 'tr_bk',\n",
      "       'tr_bk_domesticdeparturedate', 'tr_bk_number', 'tr_isempty',\n",
      "       'tr_traingroup', 'tr_responsible', 'tr_priority',\n",
      "       'tr_is_initialtimetabletype', 'tr_ismodifiedinrealtime', 'tr_isundo',\n",
      "       'info_commercialtype', 'info_maxspeed', 'point_trackingtype',\n",
      "       'point_movement', 'point_ptcarsequencenumber', 'point_isunexpected',\n",
      "       'planned_status', 'planned_timetabletype',\n",
      "       'planned_reservetime_or_buffertim', 'point_ptcarid',\n",
      "       'point_ptcar_symbolicname', 'point_ptcar_shortnamenl',\n",
      "       'point_ptcar_gpslatitude', 'point_ptcar_gpslongitude', 'point_ismanual',\n",
      "       'point_macro_time', 'point_macro_delay', 'point_micro_time',\n",
      "       'point_micro_fromptrefsymbolicnam', 'point_micro_toptrefsymbolicname'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "effective_df_org = pd.read_csv(EFFECTIVE_DATA_FILE_PATH)\n",
    "\n",
    "print(effective_df_org.shape)\n",
    "print(effective_df_org.columns)\n",
    "effective_df_org.head(2)\n",
    "\n",
    "## The below variable of EFFECTIVE_DF_COLS_TO_DROP is used in the function 'preprocess_effective' to drop unused cols\n",
    "EFFECTIVE_DF_COLS_TO_DROP = ['hd_messageidentifier', 'hd_timestamp', 'tr_bk',\n",
    "       'tr_bk_domesticdeparturedate', 'tr_responsible', 'tr_priority',\n",
    "       'tr_is_initialtimetabletype', 'tr_ismodifiedinrealtime', 'tr_isundo',\n",
    "       'info_maxspeed', 'point_trackingtype',\n",
    "       'planned_reservetime_or_buffertim',\n",
    "       'point_ptcar_symbolicname', 'point_ptcar_shortnamenl',\n",
    "       'point_ptcar_gpslatitude', 'point_ptcar_gpslongitude', 'point_ismanual',\n",
    "       'point_macro_time', 'point_micro_toptrefsymbolicname']\n",
    "\n",
    "\n",
    "## The below variable EFFECTIVE_DF_COLS_NEEDED is just to keep track of all the needed variables \n",
    "#for sanity check\n",
    "## when we get new dataset\n",
    "EFFECTIVE_DF_COLS_NEEDED= ['tr_bk_number', 'point_ptcarid','point_macro_time','point_macro_delay',\n",
    "                           'point_movement', 'info_commercialtype', 'point_ptcarsequencenumber', \n",
    "                           'tr_isempty', 'tr_traingroup', 'point_micro_time', 'point_micro_fromptrefsymbolicnam']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b901252",
   "metadata": {},
   "source": [
    "### clean/preprocess effective data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2171d81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:37:18.773391Z",
     "start_time": "2024-11-17T06:37:16.917097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in effective data: 22367077\n",
      "Train number NaN count: 0\n",
      "Train ID NaN count: 0\n",
      "Train type NaN count: 501530\n",
      "Micro time NaN count: 4249963\n",
      "PT car NaN count: 0\n",
      "Macro time NaN count: 0\n",
      "Macro delay NaN count: 103890\n",
      "Point Movement NaN count: 0\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function prints the number of NA per columns in the EFFECTIVE data set\n",
    "################################################################################\n",
    "\n",
    "def check_na_cols(temp_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to verify the cleanliness of the effective dataframe\n",
    "    by checking for NaN values in specific columns.\n",
    "    \"\"\"\n",
    "    # Count NaN values in each column\n",
    "    tr_bk_number_nan_count = temp_df['tr_bk_number'].isna().sum()\n",
    "    tr_bk_nan_count = temp_df['tr_bk'].isna().sum()\n",
    "    tr_type_nan_count = temp_df['info_commercialtype'].isna().sum()\n",
    "    micro_nan_count = temp_df['point_micro_time'].isna().sum()\n",
    "    ptcar_nan_count = temp_df['point_ptcarid'].isna().sum()\n",
    "    macro_nan_count = temp_df['point_macro_time'].isna().sum()\n",
    "    macro_delay_nan_count = temp_df['point_macro_delay'].isna().sum()\n",
    "    point_movement_nan_count = temp_df['point_movement'].isna().sum()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Total rows in effective data:\", temp_df.shape[0])\n",
    "    print(\"Train number NaN count:\", tr_bk_number_nan_count)\n",
    "    print(\"Train ID NaN count:\", tr_bk_nan_count)\n",
    "    print(\"Train type NaN count:\", tr_type_nan_count)\n",
    "    print(\"Micro time NaN count:\", micro_nan_count)\n",
    "    print(\"PT car NaN count:\", ptcar_nan_count)\n",
    "    print(\"Macro time NaN count:\", macro_nan_count)\n",
    "    print(\"Macro delay NaN count:\", macro_delay_nan_count)\n",
    "    print(\"Point Movement NaN count:\", point_movement_nan_count)\n",
    "    \n",
    "check_na_cols(effective_df_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e942d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:38:47.856924Z",
     "start_time": "2024-11-17T06:37:21.562982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22367077, 32)\n",
      "(22367077, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tr_isempty</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>m_org</th>\n",
       "      <th>point_ptcarsequencenumber</th>\n",
       "      <th>point_isunexpected</th>\n",
       "      <th>planned_status</th>\n",
       "      <th>planned_timetabletype</th>\n",
       "      <th>s</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>point_micro_time</th>\n",
       "      <th>point_micro_fromptrefsymbolicnam</th>\n",
       "      <th>day_name</th>\n",
       "      <th>formatted_point_macro_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17831</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>out</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1084</td>\n",
       "      <td>-5317.00</td>\n",
       "      <td>01APR2023:00:01:27.000000</td>\n",
       "      <td>276011.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-31 23:59:23+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-86432</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>out</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1195</td>\n",
       "      <td>-3695.00</td>\n",
       "      <td>01APR2023:00:00:33.000000</td>\n",
       "      <td>402071.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-31 23:59:25+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8436</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>456</td>\n",
       "      <td>-112.36</td>\n",
       "      <td>01APR2023:00:00:11.000000</td>\n",
       "      <td>592792.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>out</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>349</td>\n",
       "      <td>130.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:10+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  tr_isempty tr_traingroup tr_type m_org  point_ptcarsequencenumber  \\\n",
       "0 -17831           0       FREIGHT    HKM5   out                        109   \n",
       "1 -86432           0       FREIGHT    HKM5   out                        103   \n",
       "2  -8436           0       FREIGHT   Ntype   out                        101   \n",
       "3 -85230           0     PASSENGER       L   out                          3   \n",
       "\n",
       "   point_isunexpected planned_status planned_timetabletype     s   w(i,t)  \\\n",
       "0                   0         ACTIVE     IMPORTANT_PASSAGE  1084 -5317.00   \n",
       "1                   0         ACTIVE     IMPORTANT_PASSAGE  1195 -3695.00   \n",
       "2                   0         ACTIVE       COMMERCIAL_STOP   456  -112.36   \n",
       "3                   0         ACTIVE       COMMERCIAL_STOP   349   130.00   \n",
       "\n",
       "            point_micro_time  point_micro_fromptrefsymbolicnam  day_name  \\\n",
       "0  01APR2023:00:01:27.000000                          276011.0    Friday   \n",
       "1  01APR2023:00:00:33.000000                          402071.0    Friday   \n",
       "2  01APR2023:00:00:11.000000                          592792.0  Saturday   \n",
       "3                        NaN                               NaN  Saturday   \n",
       "\n",
       "  formatted_point_macro_time  \n",
       "0  2023-03-31 23:59:23+02:00  \n",
       "1  2023-03-31 23:59:25+02:00  \n",
       "2  2023-04-01 00:00:07+02:00  \n",
       "3  2023-04-01 00:00:10+02:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Function to convert date format of EFFECTIVE data to match justif data, \n",
    "# the new timestamp column created is named as 'formatted_point_macro_time',\n",
    "# we use 'formatted_point_macro_time' to create 't',r0,r1,r2, \n",
    "\n",
    "# we convert the datatype for tr_bk_number (which is the train identifier) and point_ptcarid (which is the station identifier) \n",
    "# from double to int. Next, we fill the nan values with 0 for point_macro_delay\n",
    "# We rename the column names for \n",
    "    # tr_bk_number as 'i'\n",
    "    # point_ptcarid as 's'\n",
    "    # point_movement as 'm_org'\n",
    "    # point_macro_delay as'w(i,t)'\n",
    "################################################################################\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def preprocess_effective(temp_df):\n",
    "\n",
    "    # Function to preprocess and clean the effective data \n",
    "    # It returns a reduced data frame with 6 columns\n",
    "\n",
    "    temp_df.dropna(how='all', inplace=True)\n",
    "    print(temp_df.shape)\n",
    "    \n",
    "    # Convert 'point_macro_time' to datetime format and sort\n",
    "    temp_df['point_macro_time'] = pd.to_datetime(temp_df['point_macro_time'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "    temp_df = temp_df.sort_values(by='point_macro_time').reset_index(drop=True)\n",
    "    temp_df['day_name'] = temp_df['point_macro_time'].dt.day_name()\n",
    "    \n",
    "    # conver the point_macro_time to the date format that matches justif data\n",
    "    temp_df['formatted_point_macro_time'] = pd.to_datetime(temp_df['point_macro_time']).dt.tz_localize(pytz.timezone('Europe/Paris'))\n",
    "    \n",
    "    # Convert 'tr_bk_number' and 'point_ptcarid' to integer format\n",
    "    temp_df['tr_bk_number'] = temp_df['tr_bk_number'].astype(int)\n",
    "    temp_df['info_commercialtype'] = temp_df['info_commercialtype'].fillna('Ntype')\n",
    "    temp_df['point_ptcarid'] = temp_df['point_ptcarid'].astype(int)\n",
    "    temp_df['point_macro_delay'] = temp_df['point_macro_delay'].fillna(0)\n",
    "    temp_df['point_ptcarsequencenumber'] = pd.to_numeric(temp_df['point_ptcarsequencenumber'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    # Dictionary of old and new column names\n",
    "    new_column_names = {\n",
    "        'tr_bk_number': 'i',\n",
    "        'info_commercialtype': 'tr_type',\n",
    "        'point_ptcarid': 's',\n",
    "        'point_movement': 'm_org',\n",
    "        'point_macro_delay': 'w(i,t)'\n",
    "    }\n",
    "        \n",
    "    \n",
    "    # Rename columns\n",
    "    temp_df.rename(columns=new_column_names, inplace=True)\n",
    "    \n",
    "    # drop unused columns\n",
    "    temp_df.drop(EFFECTIVE_DF_COLS_TO_DROP, axis=1, inplace=True)\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "# Note that 'effective_df' is a reduced data frame with 9 columns\n",
    "effective_df = preprocess_effective(effective_df_org)\n",
    "print(effective_df.shape )\n",
    "effective_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d22604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:38:52.527653Z",
     "start_time": "2024-11-17T06:38:47.864008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# we are deleting the effective_df_org to save memory\n",
    "################################################################################\n",
    "\n",
    "del effective_df_org\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6306fda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:38:54.244593Z",
     "start_time": "2024-11-17T06:38:52.528661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22367075, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tr_isempty</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>m_org</th>\n",
       "      <th>point_ptcarsequencenumber</th>\n",
       "      <th>point_isunexpected</th>\n",
       "      <th>planned_status</th>\n",
       "      <th>planned_timetabletype</th>\n",
       "      <th>s</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>point_micro_time</th>\n",
       "      <th>point_micro_fromptrefsymbolicnam</th>\n",
       "      <th>day_name</th>\n",
       "      <th>formatted_point_macro_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8436</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>456</td>\n",
       "      <td>-112.36</td>\n",
       "      <td>01APR2023:00:00:11.000000</td>\n",
       "      <td>592792.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>out</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>349</td>\n",
       "      <td>130.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:10+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  tr_isempty tr_traingroup tr_type m_org  point_ptcarsequencenumber  \\\n",
       "0  -8436           0       FREIGHT   Ntype   out                        101   \n",
       "1 -85230           0     PASSENGER       L   out                          3   \n",
       "\n",
       "   point_isunexpected planned_status planned_timetabletype    s  w(i,t)  \\\n",
       "0                   0         ACTIVE       COMMERCIAL_STOP  456 -112.36   \n",
       "1                   0         ACTIVE       COMMERCIAL_STOP  349  130.00   \n",
       "\n",
       "            point_micro_time  point_micro_fromptrefsymbolicnam  day_name  \\\n",
       "0  01APR2023:00:00:11.000000                          592792.0  Saturday   \n",
       "1                        NaN                               NaN  Saturday   \n",
       "\n",
       "  formatted_point_macro_time  \n",
       "0  2023-04-01 00:00:07+02:00  \n",
       "1  2023-04-01 00:00:10+02:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "## The effective_df contains 2 records from march 31st in the point_micro_time, \n",
    "# As our dataset is already sorted, we are dropping those first 2 rows here and reseting the index\n",
    "################################################################################\n",
    "\n",
    "effective_df = effective_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "print(effective_df.shape)\n",
    "effective_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d19dfc-eabd-4bc6-aef2-27a5239b94da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tr_isempty</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>m_org</th>\n",
       "      <th>point_ptcarsequencenumber</th>\n",
       "      <th>point_isunexpected</th>\n",
       "      <th>planned_status</th>\n",
       "      <th>planned_timetabletype</th>\n",
       "      <th>s</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>point_micro_time</th>\n",
       "      <th>point_micro_fromptrefsymbolicnam</th>\n",
       "      <th>day_name</th>\n",
       "      <th>formatted_point_macro_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8436</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>456</td>\n",
       "      <td>-112.36</td>\n",
       "      <td>01APR2023:00:00:11.000000</td>\n",
       "      <td>592792.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>out</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>349</td>\n",
       "      <td>130.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:10+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-87651</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>OPERATIONAL_STOP</td>\n",
       "      <td>78</td>\n",
       "      <td>-214.68</td>\n",
       "      <td>01APR2023:00:00:41.000000</td>\n",
       "      <td>780041.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:25+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>in</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>871</td>\n",
       "      <td>-1288.00</td>\n",
       "      <td>01APR2023:00:00:23.000000</td>\n",
       "      <td>273281.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:32+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>out</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>871</td>\n",
       "      <td>-1288.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:32+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-17831</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>in</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1622</td>\n",
       "      <td>-5300.04</td>\n",
       "      <td>01APR2023:00:01:27.000000</td>\n",
       "      <td>276011.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:39+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-17831</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>out</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1622</td>\n",
       "      <td>-5300.04</td>\n",
       "      <td>01APR2023:00:01:27.000000</td>\n",
       "      <td>276011.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:39+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>out</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>883</td>\n",
       "      <td>-1264.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:56+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>in</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>883</td>\n",
       "      <td>-1264.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:56+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>out</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>349</td>\n",
       "      <td>187.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:01:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-20520</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>769</td>\n",
       "      <td>83.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:01:23+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-17831</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>out</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1526</td>\n",
       "      <td>-5358.00</td>\n",
       "      <td>01APR2023:00:03:14.000000</td>\n",
       "      <td>271991.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:01:42+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-17831</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>HKM5</td>\n",
       "      <td>in</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1526</td>\n",
       "      <td>-5358.00</td>\n",
       "      <td>01APR2023:00:01:27.000000</td>\n",
       "      <td>276011.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:01:42+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-87651</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>in</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>2110</td>\n",
       "      <td>-235.00</td>\n",
       "      <td>01APR2023:00:00:41.000000</td>\n",
       "      <td>780041.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:05+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-87651</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>out</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>2110</td>\n",
       "      <td>-235.00</td>\n",
       "      <td>01APR2023:00:00:41.000000</td>\n",
       "      <td>780041.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:05+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>out</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>566</td>\n",
       "      <td>-1253.32</td>\n",
       "      <td>01APR2023:00:02:47.000000</td>\n",
       "      <td>531962.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:06+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>in</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>566</td>\n",
       "      <td>-1253.32</td>\n",
       "      <td>01APR2023:00:02:47.000000</td>\n",
       "      <td>531962.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:06+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>out</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1546</td>\n",
       "      <td>-1252.00</td>\n",
       "      <td>01APR2023:00:02:47.000000</td>\n",
       "      <td>531962.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:08+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-91842</td>\n",
       "      <td>1</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>HPV</td>\n",
       "      <td>in</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1546</td>\n",
       "      <td>-1252.00</td>\n",
       "      <td>01APR2023:00:01:58.000000</td>\n",
       "      <td>531052.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:08+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-53372</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>219</td>\n",
       "      <td>8.84</td>\n",
       "      <td>01APR2023:00:02:29.000000</td>\n",
       "      <td>367064.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:08+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        i  tr_isempty tr_traingroup tr_type m_org  point_ptcarsequencenumber  \\\n",
       "0   -8436           0       FREIGHT   Ntype   out                        101   \n",
       "1  -85230           0     PASSENGER       L   out                          3   \n",
       "2  -87651           1     PASSENGER   Ntype   out                        101   \n",
       "3  -91842           1     PASSENGER     HPV    in                        103   \n",
       "4  -91842           1     PASSENGER     HPV   out                        103   \n",
       "5  -17831           0       FREIGHT    HKM5    in                        110   \n",
       "6  -17831           0       FREIGHT    HKM5   out                        110   \n",
       "7  -91842           1     PASSENGER     HPV   out                        104   \n",
       "8  -91842           1     PASSENGER     HPV    in                        104   \n",
       "9  -85230           0     PASSENGER       L   out                          3   \n",
       "10 -20520           0     PASSENGER   Ntype   out                          1   \n",
       "11 -17831           0       FREIGHT    HKM5   out                        111   \n",
       "12 -17831           0       FREIGHT    HKM5    in                        111   \n",
       "13 -87651           1     PASSENGER     HPV    in                        102   \n",
       "14 -87651           1     PASSENGER     HPV   out                        102   \n",
       "15 -91842           1     PASSENGER     HPV   out                        106   \n",
       "16 -91842           1     PASSENGER     HPV    in                        106   \n",
       "17 -91842           1     PASSENGER     HPV   out                        105   \n",
       "18 -91842           1     PASSENGER     HPV    in                        105   \n",
       "19 -53372           0     PASSENGER   Ntype   out                        101   \n",
       "\n",
       "    point_isunexpected planned_status planned_timetabletype     s   w(i,t)  \\\n",
       "0                    0         ACTIVE       COMMERCIAL_STOP   456  -112.36   \n",
       "1                    0         ACTIVE       COMMERCIAL_STOP   349   130.00   \n",
       "2                    0         ACTIVE      OPERATIONAL_STOP    78  -214.68   \n",
       "3                    0         ACTIVE     IMPORTANT_PASSAGE   871 -1288.00   \n",
       "4                    0         ACTIVE     IMPORTANT_PASSAGE   871 -1288.00   \n",
       "5                    0         ACTIVE     IMPORTANT_PASSAGE  1622 -5300.04   \n",
       "6                    0         ACTIVE     IMPORTANT_PASSAGE  1622 -5300.04   \n",
       "7                    0         ACTIVE     IMPORTANT_PASSAGE   883 -1264.00   \n",
       "8                    0         ACTIVE     IMPORTANT_PASSAGE   883 -1264.00   \n",
       "9                    0         ACTIVE       COMMERCIAL_STOP   349   187.00   \n",
       "10                   0         ACTIVE       COMMERCIAL_STOP   769    83.00   \n",
       "11                   0         ACTIVE     IMPORTANT_PASSAGE  1526 -5358.00   \n",
       "12                   0         ACTIVE     IMPORTANT_PASSAGE  1526 -5358.00   \n",
       "13                   0         ACTIVE     IMPORTANT_PASSAGE  2110  -235.00   \n",
       "14                   0         ACTIVE     IMPORTANT_PASSAGE  2110  -235.00   \n",
       "15                   0         ACTIVE     IMPORTANT_PASSAGE   566 -1253.32   \n",
       "16                   0         ACTIVE     IMPORTANT_PASSAGE   566 -1253.32   \n",
       "17                   0         ACTIVE     IMPORTANT_PASSAGE  1546 -1252.00   \n",
       "18                   0         ACTIVE     IMPORTANT_PASSAGE  1546 -1252.00   \n",
       "19                   0         ACTIVE       COMMERCIAL_STOP   219     8.84   \n",
       "\n",
       "             point_micro_time  point_micro_fromptrefsymbolicnam  day_name  \\\n",
       "0   01APR2023:00:00:11.000000                          592792.0  Saturday   \n",
       "1                         NaN                               NaN  Saturday   \n",
       "2   01APR2023:00:00:41.000000                          780041.0  Saturday   \n",
       "3   01APR2023:00:00:23.000000                          273281.0  Saturday   \n",
       "4                         NaN                               NaN  Saturday   \n",
       "5   01APR2023:00:01:27.000000                          276011.0  Saturday   \n",
       "6   01APR2023:00:01:27.000000                          276011.0  Saturday   \n",
       "7                         NaN                               NaN  Saturday   \n",
       "8                         NaN                               NaN  Saturday   \n",
       "9                         NaN                               NaN  Saturday   \n",
       "10                        NaN                               NaN  Saturday   \n",
       "11  01APR2023:00:03:14.000000                          271991.0  Saturday   \n",
       "12  01APR2023:00:01:27.000000                          276011.0  Saturday   \n",
       "13  01APR2023:00:00:41.000000                          780041.0  Saturday   \n",
       "14  01APR2023:00:00:41.000000                          780041.0  Saturday   \n",
       "15  01APR2023:00:02:47.000000                          531962.0  Saturday   \n",
       "16  01APR2023:00:02:47.000000                          531962.0  Saturday   \n",
       "17  01APR2023:00:02:47.000000                          531962.0  Saturday   \n",
       "18  01APR2023:00:01:58.000000                          531052.0  Saturday   \n",
       "19  01APR2023:00:02:29.000000                          367064.0  Saturday   \n",
       "\n",
       "   formatted_point_macro_time  \n",
       "0   2023-04-01 00:00:07+02:00  \n",
       "1   2023-04-01 00:00:10+02:00  \n",
       "2   2023-04-01 00:00:25+02:00  \n",
       "3   2023-04-01 00:00:32+02:00  \n",
       "4   2023-04-01 00:00:32+02:00  \n",
       "5   2023-04-01 00:00:39+02:00  \n",
       "6   2023-04-01 00:00:39+02:00  \n",
       "7   2023-04-01 00:00:56+02:00  \n",
       "8   2023-04-01 00:00:56+02:00  \n",
       "9   2023-04-01 00:01:07+02:00  \n",
       "10  2023-04-01 00:01:23+02:00  \n",
       "11  2023-04-01 00:01:42+02:00  \n",
       "12  2023-04-01 00:01:42+02:00  \n",
       "13  2023-04-01 00:02:05+02:00  \n",
       "14  2023-04-01 00:02:05+02:00  \n",
       "15  2023-04-01 00:02:06+02:00  \n",
       "16  2023-04-01 00:02:06+02:00  \n",
       "17  2023-04-01 00:02:08+02:00  \n",
       "18  2023-04-01 00:02:08+02:00  \n",
       "19  2023-04-01 00:02:08+02:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821063e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:38:54.260690Z",
     "start_time": "2024-11-17T06:38:54.245600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-04-01 00:00:00+0200', tz='Europe/Paris')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Function to Extract strting time of our data from the column formatted_point_macro_time in effective data\n",
    "#  The function Sets the global variable 'start_timestamp' to the starting timestamp extracted from the DataFrame\n",
    "################################################################################\n",
    "\n",
    "global start_timestamp \n",
    "\n",
    "def extract_start_timestamp_from_effective(df,time_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts the starting timestamp from the specified column in the DataFrame.\n",
    "    The starting timestamp is set as a global variable 'start_timestamp' for\n",
    "    accessibility from anywhere after calling this function..\n",
    "\n",
    "    Args:\n",
    "    - df: pandas DataFrame containing the timestamps.\n",
    "    - time_column: str, the name of the column containing timestamps that is same as justif timestamp format.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Timestamp: The starting timestamp extracted from the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    start_timestamp = df[time_column].iloc[0].normalize()\n",
    "    start_timestamp = start_timestamp+ pd.Timedelta(hours=0)\n",
    "    return start_timestamp\n",
    "     \n",
    "\n",
    "start_timestamp = extract_start_timestamp_from_effective(effective_df,'formatted_point_macro_time')\n",
    "start_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95923f8e",
   "metadata": {},
   "source": [
    "## Prepare timestamp column for delay in the Effective data set\n",
    "\n",
    "We define $r_0(t)$, $r_1(t)$, and $r_2(t)$ as the respective time of the day (in minutes), the day of the week (from one to seven) and month of the year (from one to seven), corresponding to data time $t$. We introduce the notation $\\boldsymbol{r}(t) = (r_0(t), r_1(t), r_2(t))$.\n",
    "\n",
    "The following code is to create $r_0(t)$ in blocks of 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4d7c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:39:00.045933Z",
     "start_time": "2024-11-17T06:38:54.264712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tr_isempty</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>m_org</th>\n",
       "      <th>point_ptcarsequencenumber</th>\n",
       "      <th>point_isunexpected</th>\n",
       "      <th>planned_status</th>\n",
       "      <th>planned_timetabletype</th>\n",
       "      <th>s</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>point_micro_time</th>\n",
       "      <th>point_micro_fromptrefsymbolicnam</th>\n",
       "      <th>day_name</th>\n",
       "      <th>formatted_point_macro_time</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8436</td>\n",
       "      <td>0</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>456</td>\n",
       "      <td>-112.36</td>\n",
       "      <td>01APR2023:00:00:11.000000</td>\n",
       "      <td>592792.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:07+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>out</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>349</td>\n",
       "      <td>130.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:00:10+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  tr_isempty tr_traingroup tr_type m_org  point_ptcarsequencenumber  \\\n",
       "0  -8436           0       FREIGHT   Ntype   out                        101   \n",
       "1 -85230           0     PASSENGER       L   out                          3   \n",
       "\n",
       "   point_isunexpected planned_status planned_timetabletype    s  w(i,t)  \\\n",
       "0                   0         ACTIVE       COMMERCIAL_STOP  456 -112.36   \n",
       "1                   0         ACTIVE       COMMERCIAL_STOP  349  130.00   \n",
       "\n",
       "            point_micro_time  point_micro_fromptrefsymbolicnam  day_name  \\\n",
       "0  01APR2023:00:00:11.000000                          592792.0  Saturday   \n",
       "1                        NaN                               NaN  Saturday   \n",
       "\n",
       "  formatted_point_macro_time  r0  r1  r2  \n",
       "0  2023-04-01 00:00:07+02:00   0   6   4  \n",
       "1  2023-04-01 00:00:10+02:00   0   6   4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Function to create r0, r1 and r2 by removing seconds and timezone from the  \n",
    "# columns 'formatted_point_macro_time' in the effective_df\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "def Append_r0_r1_r2(df, time_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function adds a new column to df by converting timestamps in a specified column to simplified time units where each 5-minute interval is considered a unit.\n",
    "    \n",
    "    Input Args:\n",
    "    - df: pandas DataFrame containing the timestamps.\n",
    "    - time_column: the name of the column containing timestamps in ISO 8601 format.\n",
    "   \n",
    "    Output Returns:\n",
    "    - A pandas DataFrame contructed from df, with an additional column 'simplified_t' containing the simplified time units.\n",
    "    - r0: the name of the 'minute' column that this function is going to append to df\n",
    "    - r1 the name of the 'week' column that this function is going to append to df\n",
    "    - r2 the name of the 'month' column that this function is going to append to df\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the time_column to datetime if not done earlier\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[time_column]):\n",
    "        df[time_column] = pd.to_datetime(df[time_column])\n",
    "\n",
    "    # Extract hours and minutes\n",
    "    hours = df[time_column].dt.hour\n",
    "    minutes = df[time_column].dt.minute\n",
    "\n",
    "    # Calculate total minutes from the start of the day\n",
    "    total_minutes = hours * 60 + minutes\n",
    "\n",
    "    # Convert to simplified time units\n",
    "    r0 = np.ceil(total_minutes // MINUTE).astype(int)\n",
    "\n",
    "    r1 = df[time_column].dt.dayofweek + 1  # Adding 1 to shift from 0-6 to 1-7\n",
    "    r2 = df[time_column].dt.month\n",
    "\n",
    "    return r0.astype('int16'),r1.astype('int8'),r2.astype('int8')\n",
    "\n",
    "\n",
    "# After this operation 'effectiv_df' will have 12 columns (the 9 original columns + r0 + r1 + r2)\n",
    "\n",
    "r0, r1, r2 = Append_r0_r1_r2(effective_df, 'formatted_point_macro_time')\n",
    "effective_df['r0'] = r0\n",
    "effective_df['r1'] = r1\n",
    "effective_df['r2'] = r2\n",
    "effective_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4bd63d-5c9b-45ac-a4d8-2c78c3c5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_df['point_micro_time'] = (\n",
    "    pd.to_datetime(effective_df['point_micro_time'], format=\"%d%b%Y:%H:%M:%S.%f\")\n",
    "      .dt.tz_localize(\"Europe/Paris\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63005045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:13:38.059721Z",
     "start_time": "2024-11-29T11:13:38.055977Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# This function takes timestamp column as input  and returns 't' (in blocks of 5 minutes) \n",
    "# by removing seconds and timezone. For ex. we can pass the columns 'formatted_point_macro_time' \n",
    "# in the effecctive_df data, as input to the function.\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "def Append_t(df_time_column):\n",
    "    \"\"\"\n",
    "    Converts the input timestamps to simplified time units where each 5-minute interval is considered a unit.\n",
    "\n",
    "    Args:\n",
    "    - df_time_column: pandas Series, the column containing timestamps in ISO 8601 format.\n",
    "\n",
    "    Returns:\n",
    "    -pandas Series: A Series containing the converted values of the timestamp column.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the difference in minutes from the starting timestamp\n",
    "    diff_in_minutes_from_start_timestamp= ((df_time_column - start_timestamp).dt.total_seconds() / 60).round(2)\n",
    "\n",
    "    # Divide the difference by 5 to get the running number in minutes\n",
    "    current_minute= (diff_in_minutes_from_start_timestamp// MINUTE).astype(T_DATATYPE) \n",
    "\n",
    "    return current_minute\n",
    "\n",
    "# After this operation 'effectiv_df' will have 13 columns (the 12 original columns + t)\n",
    "effective_df['t'] = Append_t(effective_df['formatted_point_macro_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298e40f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:39:01.112584Z",
     "start_time": "2024-11-17T06:39:01.093304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r0: 84\n",
      "r1: 2\n",
      "r2: 4\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions `get_r0(t)`, `get_r1(t)`, and `get_r2(t)` are helper functions that take \n",
    "# an integer 't' or a panda series(column) containing simplified time units 't' (in blocks of 5 minutes) as input \n",
    "# and returns an integer or a panda series containing\n",
    "# - r0: The minute unit (0 to 287, where 0 represents the first minute and 287 represents the last minute of a day).\n",
    "# - r1: The day of the week (1 to 7, where 1 is Monday and 7 is Sunday).\n",
    "# - r2: The month (1 to 12, where 1 is January and 12 is December).\n",
    "################################################################################\n",
    "\n",
    "def get_r0(t):\n",
    "    \"\"\"\n",
    "    Takes an integer t (simplified time units) or pd.Series 't'.\n",
    "\n",
    "    Args:\n",
    "    - t: int or pd.series format the simplified time unit.\n",
    "\n",
    "    Returns:\n",
    "    - r0: returns int if 't' is int or pd.series if 't' is pd.series\n",
    "    \"\"\"\n",
    "    if type(t) == int:\n",
    "\n",
    "        timestamp = start_timestamp + pd.Timedelta(minutes=t * MINUTE)\n",
    "        total_minutes = (timestamp.hour * 60) + timestamp.minute\n",
    "\n",
    "        # Convert to simplified time units\n",
    "        r0 = np.ceil(total_minutes // MINUTE).astype(int)\n",
    "\n",
    "    else:\n",
    "\n",
    "        timedelta_values = pd.to_timedelta(t * MINUTE, unit='m')\n",
    "        timestamp_val = start_timestamp + timedelta_values\n",
    "    \n",
    "        r0 = np.ceil((timestamp_val.dt.hour * 60 + timestamp_val.dt.minute) // MINUTE).astype(int)\n",
    "    \n",
    "    return r0\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "def get_r1(t):   \n",
    "    \"\"\"\n",
    "    Takes an integer t (simplified time units) or pd.Series 't'.\n",
    "\n",
    "    Args:\n",
    "    - t: int or pd.series format the simplified time unit.\n",
    "\n",
    "    Returns:\n",
    "    - r1: returns int if 't' is int or pd.series if 't' is pd.series\n",
    "    \"\"\"\n",
    "    if type(t) == int:\n",
    "        \n",
    "        timestamp = start_timestamp + pd.Timedelta(minutes=t * MINUTE)\n",
    "        r1 = timestamp.dayofweek + 1\n",
    "\n",
    "    else:\n",
    "    \n",
    "        timedelta_values = pd.to_timedelta(t * MINUTE, unit='m')\n",
    "        timestamp_val = start_timestamp + timedelta_values\n",
    "        r1 = timestamp_val.dt.dayofweek + 1\n",
    "\n",
    "    return r1\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "    \n",
    "def get_r2(t):\n",
    "    \"\"\"\n",
    "    Takes an integer t (simplified time units) or pd.Series 't'.\n",
    "\n",
    "    Args:\n",
    "    - t: int or pd.series format the simplified time unit.\n",
    "\n",
    "    Returns:\n",
    "    - r2: returns int if 't' is int or pd.series if 't' is pd.series\n",
    "    \"\"\"\n",
    "    if type(t) == int:\n",
    "            \n",
    "        timestamp = start_timestamp + pd.Timedelta(minutes=t * MINUTE)\n",
    "        r2 = timestamp.month\n",
    "\n",
    "    else:\n",
    "        timedelta_values = pd.to_timedelta(t * MINUTE, unit='m')\n",
    "        timestamp_val = start_timestamp + timedelta_values\n",
    "        r2 = timestamp_val.dt.month\n",
    "\n",
    "    return r2\n",
    "\n",
    "# Example usage:\n",
    "t = 948  # Example simplified time unit\n",
    "print(\"r0:\", get_r0(t))\n",
    "print(\"r1:\", get_r1(t))\n",
    "print(\"r2:\", get_r2(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250e859",
   "metadata": {},
   "source": [
    "## preparing the statistics of empty and freight trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f1dc94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T02:36:15.636118Z",
     "start_time": "2024-08-18T02:36:12.213917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FREIGHT</th>\n",
       "      <th>PASSENGER</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No.of Trains</th>\n",
       "      <td>3811</td>\n",
       "      <td>5869</td>\n",
       "      <td>9680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FREIGHT PASSENGER  Total\n",
       "No.of Trains    3811      5869   9680"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function takes an dataframe as input and  extracts the traingroup statistics\n",
    "################################################################################\n",
    "\n",
    "def get_traingroup_statistics_for_df(sample_df,file_name):\n",
    "    sample_df = sample_df[sample_df['point_ptcarsequencenumber'] >= 101]\n",
    "    unique_i_tr_traingroup = sample_df[['i', 'tr_traingroup']].drop_duplicates()\n",
    "\n",
    "    # Calculate total number of unique trains & unique train groups\n",
    "    total_trains = unique_i_tr_traingroup['i'].nunique()\n",
    "    unique_train_group = unique_i_tr_traingroup['tr_traingroup'].unique()\n",
    "\n",
    "    # Count the number of trains in each group\n",
    "    group_counts = unique_i_tr_traingroup['tr_traingroup'].value_counts().reset_index()\n",
    "    group_counts.columns = ['tr_traingroup', 'number_of_trains']\n",
    "\n",
    "    # create a dataframe\n",
    "    summ_df = pd.DataFrame(index=['No.of Trains'], columns=unique_train_group)\n",
    "\n",
    "    # Assign counts to the corresponding columns\n",
    "    for _, row in group_counts.iterrows():\n",
    "        summ_df.at['No.of Trains', row['tr_traingroup']] = row['number_of_trains']\n",
    "\n",
    "    # Add the total number of trains to the DataFrame and make the type to int\n",
    "    summ_df.at['No.of Trains', 'Total'] = total_trains\n",
    "    summ_df = summ_df.astype({\"Total\": int})\n",
    "    \n",
    "    summ_df.to_csv(file_name, index=False)\n",
    "    return summ_df,unique_i_tr_traingroup\n",
    "\n",
    "summ_df,unique_i_tr_traingroup = get_traingroup_statistics_for_df(effective_df,EFFECTIVE_DF_STATS_FILE_PATH)\n",
    "summ_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0bf5b7",
   "metadata": {},
   "source": [
    "### Extracting the Departure and Arrival time of all trains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307466c",
   "metadata": {},
   "source": [
    "Extracting the Departure and Arrival time of all trains. This is needed to construct $D_{i,t}$  and $a_{i,t}(w_{i,t})$:\n",
    "$$\n",
    "a_{i,t}(w_{i,t})  ~:=~  \\text{whether train $i$ is active at time $t$,}\n",
    "$$\n",
    "so that\n",
    "$$\n",
    "D_{i,t} = \\underset{s}{\\min } ~ s ~ \\text{ subject to } a_{i, s}(0) \\geq 1,  ~ r_1(s) = r_1(t),\n",
    "$$\n",
    "which implies $a_{i,D_{i,t}}(0) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7796b699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T05:59:11.125421Z",
     "start_time": "2024-08-18T05:55:08.077435Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 101 point_ptcarsequencenumber for train -99983, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -99981, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -98848, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -97694, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -97065, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -95761, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -95598, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -95125, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -95035, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -94410, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -94330, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -94013, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -93788, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -93775, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -93675, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -93300, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -93199, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -92672, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -92447, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -90362, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -89389, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -89017, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -87326, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -87186, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -86818, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -86809, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -86442, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -84942, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -84070, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -83788, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -83779, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -83646, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -82579, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -82205, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -81689, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -81597, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -81524, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -81508, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -80508, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -79864, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -79744, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -78999, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -78035, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -78027, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -77686, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -77487, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -77474, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -77372, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -77016, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -76990, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -76650, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -76212, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -76127, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -75679, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -74083, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -73704, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -73552, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -73195, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -73140, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -73020, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -72995, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -72734, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -72521, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -72410, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -71939, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -70809, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -70576, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -70208, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -69840, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -69647, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -68719, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -68704, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -68174, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -67571, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -67248, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -67199, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -66869, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -65530, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -63839, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -63686, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -63399, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -63181, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -62938, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -62685, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -61770, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -60484, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -58711, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -58166, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -57828, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -56979, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -56611, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -54903, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -54649, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -54362, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -54082, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -54026, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -53593, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -53061, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -52872, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -50940, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -50521, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -50384, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -49726, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -49633, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -48478, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -48469, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -48127, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -48096, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -47862, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -47448, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -46784, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -46775, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -46234, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -45796, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -45650, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -45050, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -44960, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -44709, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -44169, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -43368, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -43272, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -42932, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -42763, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -41887, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -41563, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -41027, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -40766, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -40314, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -38903, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -37405, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -37383, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -36465, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -36057, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -34534, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -34032, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -34008, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -33488, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -33266, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -33121, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -33064, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -32981, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -32705, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -31852, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -31789, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -31333, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -31051, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -30820, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -29596, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -29008, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -28300, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -28167, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -27820, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -27587, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -27372, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -26361, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -26317, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -26181, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -25358, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -25152, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -25069, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -24811, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -24804, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -24752, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -23997, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -23720, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -23419, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -22851, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -22770, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -22293, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -21293, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -21190, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -19714, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -19542, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -18072, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -17929, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -16751, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -16494, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -15881, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -15762, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -15635, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -15224, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -15125, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -13684, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -13095, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -12287, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -10718, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -8988, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -7827, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -7411, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -7034, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -6673, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -6478, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -5210, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -4401, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -3625, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -3547, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -2540, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -2216, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -1427, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -1328, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -1279, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -1105, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -987, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -416, so using the first available point as start.\n",
      "No 101 point_ptcarsequencenumber for train -239, so using the first available point as start.\n",
      "\n",
      " (419473, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>start_t</th>\n",
       "      <th>start_wit</th>\n",
       "      <th>start_t-wit</th>\n",
       "      <th>start_s</th>\n",
       "      <th>end_t</th>\n",
       "      <th>end_wit</th>\n",
       "      <th>end_t-wit</th>\n",
       "      <th>end_s</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_isempty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99992</td>\n",
       "      <td>978</td>\n",
       "      <td>9013.36</td>\n",
       "      <td>948</td>\n",
       "      <td>1010</td>\n",
       "      <td>979</td>\n",
       "      <td>8899.40</td>\n",
       "      <td>950</td>\n",
       "      <td>1715</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-99992</td>\n",
       "      <td>13085</td>\n",
       "      <td>12423.00</td>\n",
       "      <td>13044</td>\n",
       "      <td>1011</td>\n",
       "      <td>13086</td>\n",
       "      <td>12286.00</td>\n",
       "      <td>13046</td>\n",
       "      <td>1715</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2175</td>\n",
       "      <td>420.75</td>\n",
       "      <td>2174</td>\n",
       "      <td>175</td>\n",
       "      <td>2178</td>\n",
       "      <td>871.00</td>\n",
       "      <td>2176</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2456</td>\n",
       "      <td>-1628.00</td>\n",
       "      <td>2462</td>\n",
       "      <td>175</td>\n",
       "      <td>2458</td>\n",
       "      <td>-1335.00</td>\n",
       "      <td>2463</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99991</td>\n",
       "      <td>4948</td>\n",
       "      <td>-2067.00</td>\n",
       "      <td>4955</td>\n",
       "      <td>1034</td>\n",
       "      <td>4950</td>\n",
       "      <td>-1950.64</td>\n",
       "      <td>4957</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-99991</td>\n",
       "      <td>5236</td>\n",
       "      <td>-2040.00</td>\n",
       "      <td>5243</td>\n",
       "      <td>1034</td>\n",
       "      <td>5238</td>\n",
       "      <td>-1817.64</td>\n",
       "      <td>5245</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-99991</td>\n",
       "      <td>5521</td>\n",
       "      <td>-2900.00</td>\n",
       "      <td>5531</td>\n",
       "      <td>1034</td>\n",
       "      <td>5523</td>\n",
       "      <td>-2776.64</td>\n",
       "      <td>5533</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-99991</td>\n",
       "      <td>5810</td>\n",
       "      <td>-2593.00</td>\n",
       "      <td>5819</td>\n",
       "      <td>1034</td>\n",
       "      <td>5812</td>\n",
       "      <td>-2464.32</td>\n",
       "      <td>5821</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-99991</td>\n",
       "      <td>15951</td>\n",
       "      <td>1163.76</td>\n",
       "      <td>15948</td>\n",
       "      <td>205</td>\n",
       "      <td>15961</td>\n",
       "      <td>1484.92</td>\n",
       "      <td>15957</td>\n",
       "      <td>981</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-99990</td>\n",
       "      <td>10390</td>\n",
       "      <td>1374.64</td>\n",
       "      <td>10386</td>\n",
       "      <td>417</td>\n",
       "      <td>10390</td>\n",
       "      <td>1331.92</td>\n",
       "      <td>10386</td>\n",
       "      <td>1025</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-99983</td>\n",
       "      <td>8412</td>\n",
       "      <td>938.43</td>\n",
       "      <td>8409</td>\n",
       "      <td>1499</td>\n",
       "      <td>8412</td>\n",
       "      <td>938.43</td>\n",
       "      <td>8409</td>\n",
       "      <td>1499</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-99981</td>\n",
       "      <td>5786</td>\n",
       "      <td>3218.41</td>\n",
       "      <td>5776</td>\n",
       "      <td>1616</td>\n",
       "      <td>5841</td>\n",
       "      <td>2061.60</td>\n",
       "      <td>5835</td>\n",
       "      <td>83</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-99981</td>\n",
       "      <td>11818</td>\n",
       "      <td>-1639.73</td>\n",
       "      <td>11824</td>\n",
       "      <td>1616</td>\n",
       "      <td>11873</td>\n",
       "      <td>-3126.88</td>\n",
       "      <td>11884</td>\n",
       "      <td>311</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-99981</td>\n",
       "      <td>13838</td>\n",
       "      <td>-298.11</td>\n",
       "      <td>13839</td>\n",
       "      <td>49</td>\n",
       "      <td>13860</td>\n",
       "      <td>-865.56</td>\n",
       "      <td>13863</td>\n",
       "      <td>983</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-99981</td>\n",
       "      <td>23909</td>\n",
       "      <td>-1760.73</td>\n",
       "      <td>23915</td>\n",
       "      <td>1616</td>\n",
       "      <td>23969</td>\n",
       "      <td>-3231.88</td>\n",
       "      <td>23980</td>\n",
       "      <td>311</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-99981</td>\n",
       "      <td>25932</td>\n",
       "      <td>82.27</td>\n",
       "      <td>25932</td>\n",
       "      <td>1616</td>\n",
       "      <td>25984</td>\n",
       "      <td>-3399.88</td>\n",
       "      <td>25996</td>\n",
       "      <td>311</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-99970</td>\n",
       "      <td>230</td>\n",
       "      <td>28.56</td>\n",
       "      <td>230</td>\n",
       "      <td>158</td>\n",
       "      <td>249</td>\n",
       "      <td>13.68</td>\n",
       "      <td>249</td>\n",
       "      <td>1048</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-99970</td>\n",
       "      <td>518</td>\n",
       "      <td>29.56</td>\n",
       "      <td>518</td>\n",
       "      <td>158</td>\n",
       "      <td>537</td>\n",
       "      <td>7.68</td>\n",
       "      <td>537</td>\n",
       "      <td>1048</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-99970</td>\n",
       "      <td>800</td>\n",
       "      <td>-98.16</td>\n",
       "      <td>801</td>\n",
       "      <td>1744</td>\n",
       "      <td>802</td>\n",
       "      <td>-48.68</td>\n",
       "      <td>803</td>\n",
       "      <td>158</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-99970</td>\n",
       "      <td>808</td>\n",
       "      <td>21.56</td>\n",
       "      <td>808</td>\n",
       "      <td>158</td>\n",
       "      <td>839</td>\n",
       "      <td>345.16</td>\n",
       "      <td>838</td>\n",
       "      <td>1161</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        i  start_t  start_wit  start_t-wit  start_s  end_t   end_wit  \\\n",
       "0  -99992      978    9013.36          948     1010    979   8899.40   \n",
       "1  -99992    13085   12423.00        13044     1011  13086  12286.00   \n",
       "2  -99991     2175     420.75         2174      175   2178    871.00   \n",
       "3  -99991     2456   -1628.00         2462      175   2458  -1335.00   \n",
       "4  -99991     4948   -2067.00         4955     1034   4950  -1950.64   \n",
       "5  -99991     5236   -2040.00         5243     1034   5238  -1817.64   \n",
       "6  -99991     5521   -2900.00         5531     1034   5523  -2776.64   \n",
       "7  -99991     5810   -2593.00         5819     1034   5812  -2464.32   \n",
       "8  -99991    15951    1163.76        15948      205  15961   1484.92   \n",
       "9  -99990    10390    1374.64        10386      417  10390   1331.92   \n",
       "10 -99983     8412     938.43         8409     1499   8412    938.43   \n",
       "11 -99981     5786    3218.41         5776     1616   5841   2061.60   \n",
       "12 -99981    11818   -1639.73        11824     1616  11873  -3126.88   \n",
       "13 -99981    13838    -298.11        13839       49  13860   -865.56   \n",
       "14 -99981    23909   -1760.73        23915     1616  23969  -3231.88   \n",
       "15 -99981    25932      82.27        25932     1616  25984  -3399.88   \n",
       "16 -99970      230      28.56          230      158    249     13.68   \n",
       "17 -99970      518      29.56          518      158    537      7.68   \n",
       "18 -99970      800     -98.16          801     1744    802    -48.68   \n",
       "19 -99970      808      21.56          808      158    839    345.16   \n",
       "\n",
       "    end_t-wit  end_s tr_traingroup  tr_isempty  \n",
       "0         950   1715     PASSENGER           1  \n",
       "1       13046   1715     PASSENGER           1  \n",
       "2        2176    848       FREIGHT           0  \n",
       "3        2463    848       FREIGHT           0  \n",
       "4        4957    848       FREIGHT           0  \n",
       "5        5245    848       FREIGHT           0  \n",
       "6        5533    848       FREIGHT           0  \n",
       "7        5821    848       FREIGHT           0  \n",
       "8       15957    981       FREIGHT           0  \n",
       "9       10386   1025       FREIGHT           0  \n",
       "10       8409   1499       FREIGHT           0  \n",
       "11       5835     83       FREIGHT           0  \n",
       "12      11884    311       FREIGHT           1  \n",
       "13      13863    983       FREIGHT           1  \n",
       "14      23980    311       FREIGHT           1  \n",
       "15      25996    311       FREIGHT           1  \n",
       "16        249   1048     PASSENGER           0  \n",
       "17        537   1048     PASSENGER           0  \n",
       "18        803    158     PASSENGER           1  \n",
       "19        838   1161     PASSENGER           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions uses effective_df with freight and empty trains\n",
    "# and extracts the departure time 't' and arrival time 't' . \n",
    "# The departure time 't' for every train 'i' corresponding to the point_ptcarsequencenumber 101  \n",
    "# Note: (for some trains 101 is not present so it takes the next available minimum number \n",
    "# in the point_ptcarsequencenumber for ex. 102) as departure time 't' train of train 'i'\n",
    "# and arrival time 't' corresponding to the max point_ptcarsequencenumber for the train 'i' \n",
    "# and saves the result to the local file EFFECTIVE_DF_DA_IT_W_FREIGHT_FILE_PATH\n",
    "#\n",
    "# The function returns a dataframe with 7 columns:\n",
    "#                   'i': train,\n",
    "#                    'start_t': group.loc[start_idx, 't'],\n",
    "#                    'start_wit': group.loc[start_idx, 'w(i,t)'],\n",
    "#                    'start_t-wit': start_t_minus_wit,\n",
    "#                    'start_s': group.loc[start_idx, 's'],\n",
    "#                    'end_t': group.loc[idx - 1, 't'],\n",
    "#                    'end_wit': group.loc[idx - 1, 'w(i,t)'],\n",
    "#                    'end_t-wit': end_t_minus_wit,\n",
    "#                    'end_s': group.loc[idx - 1, 's'],\n",
    "#                    'tr_traingroup':  group.loc[start_idx, 'tr_traingroup'], \n",
    "#                    'tr_isempty':  group.loc[start_idx, 'tr_isempty']  \n",
    "### This dataframe stored in the file is used to drop the frieght and empty trains at secondary_delay_df\n",
    "################################################################################\n",
    "\n",
    "def create_formatted_data_DA_it():\n",
    "    # Filter and sort the DataFrame\n",
    "    temp_effective_df = effective_df[effective_df['point_ptcarsequencenumber'] >= 101]\n",
    "    temp_effective_df = temp_effective_df.groupby(['i', 't', 's', 'point_ptcarsequencenumber',\n",
    "                                                   'tr_isempty','tr_traingroup'])['w(i,t)'].max().reset_index()\n",
    "    temp_effective_df.drop_duplicates(inplace=True)\n",
    "    temp_effective_df.sort_values(by=['i', 't'], ascending=[True, True], inplace=True)\n",
    "    \n",
    "    result_data = []\n",
    "    \n",
    "    # Group by 'i'\n",
    "    for train, group in temp_effective_df.groupby('i'):\n",
    "        group.sort_values(by=['t','point_ptcarsequencenumber'], ascending=[True, True], inplace=True)\n",
    "        group = group.reset_index(drop=True)\n",
    "        \n",
    "        indices = group.index[group['point_ptcarsequencenumber'] == 101].tolist()\n",
    "\n",
    "        if not indices:\n",
    "            print(f\"No 101 point_ptcarsequencenumber for train {train}, so using the first available point as start.\")\n",
    "\n",
    "        # Iterate over the group to detect sudden decreases in sequence numbers\n",
    "        start_idx = 0\n",
    "        for idx in range(1, len(group)):\n",
    "            # If decrease detected in the point_ptcarsequencenumber, end the current trip\n",
    "            if group.loc[idx, 'point_ptcarsequencenumber'] < group.loc[idx - 1, 'point_ptcarsequencenumber']:\n",
    "                start_t_minus_wit = group.loc[start_idx, 't'] - (group.loc[start_idx, 'w(i,t)'] // (60*5)).astype(T_DATATYPE) \n",
    "                end_t_minus_wit = group.loc[idx-1, 't'] - (group.loc[idx-1, 'w(i,t)'] // (60*5)).astype(T_DATATYPE) \n",
    "                \n",
    "                result_data.append({\n",
    "                    'i': train,\n",
    "                    'start_t': group.loc[start_idx, 't'],\n",
    "                    'start_wit': group.loc[start_idx, 'w(i,t)'],\n",
    "                    'start_t-wit': start_t_minus_wit,\n",
    "                    'start_s': group.loc[start_idx, 's'],\n",
    "                    'end_t': group.loc[idx - 1, 't'],\n",
    "                    'end_wit': group.loc[idx - 1, 'w(i,t)'],\n",
    "                    'end_t-wit': end_t_minus_wit,\n",
    "                    'end_s': group.loc[idx - 1, 's'],\n",
    "                    'tr_traingroup':  group.loc[start_idx, 'tr_traingroup'], \n",
    "                    'tr_isempty':  group.loc[start_idx, 'tr_isempty']  \n",
    "                })\n",
    "                \n",
    "                # Start a new trip\n",
    "                start_idx = idx\n",
    "\n",
    "        # Extract the last trip\n",
    "        start_t_minus_wit = group.loc[start_idx, 't'] - (group.loc[start_idx, 'w(i,t)'] // (60*5)).astype(T_DATATYPE) \n",
    "        end_t_minus_wit =  group.iloc[-1]['t'] - (group.iloc[-1] ['w(i,t)'] // (60*5)).astype(T_DATATYPE) \n",
    "        result_data.append({\n",
    "            'i': train,\n",
    "            'start_t': group.loc[start_idx, 't'],\n",
    "            'start_wit': group.loc[start_idx, 'w(i,t)'],\n",
    "            'start_t-wit': start_t_minus_wit,\n",
    "            'start_s': group.loc[start_idx, 's'],\n",
    "            'end_t': group.iloc[-1]['t'],\n",
    "            'end_wit': group.iloc[-1]['w(i,t)'],\n",
    "            'end_t-wit': end_t_minus_wit,\n",
    "            'end_s': group.iloc[-1]['s'],\n",
    "            'tr_traingroup':  group.loc[start_idx, 'tr_traingroup'], \n",
    "            'tr_isempty':  group.loc[start_idx, 'tr_isempty']  \n",
    "        })\n",
    "    \n",
    "    result_df = pd.DataFrame(result_data).drop_duplicates()\n",
    "    result_df.to_parquet(EFFECTIVE_DF_DA_IT_W_FREIGHT_FILE_PATH, index=False)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "DA_it_df = create_formatted_data_DA_it()\n",
    "print(\"\\n\", DA_it_df.shape)\n",
    "DA_it_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d31a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:39:30.321682Z",
     "start_time": "2024-11-17T06:39:19.983544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before clean:  (22367075, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w.bi\\AppData\\Local\\Temp\\ipykernel_22188\\3448232281.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  effective_df.drop_duplicates(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After clean:  (18209777, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>tr_isempty</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>m_org</th>\n",
       "      <th>point_ptcarsequencenumber</th>\n",
       "      <th>point_isunexpected</th>\n",
       "      <th>planned_status</th>\n",
       "      <th>planned_timetabletype</th>\n",
       "      <th>s</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>point_micro_time</th>\n",
       "      <th>point_micro_fromptrefsymbolicnam</th>\n",
       "      <th>day_name</th>\n",
       "      <th>formatted_point_macro_time</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-53372</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>Ntype</td>\n",
       "      <td>out</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>COMMERCIAL_STOP</td>\n",
       "      <td>219</td>\n",
       "      <td>8.84</td>\n",
       "      <td>2023-04-01 00:02:29+02:00</td>\n",
       "      <td>367064.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:08+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85230</td>\n",
       "      <td>0</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>L</td>\n",
       "      <td>in</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>IMPORTANT_PASSAGE</td>\n",
       "      <td>1196</td>\n",
       "      <td>131.00</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "      <td>401061.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2023-04-01 00:02:11+02:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  tr_isempty tr_traingroup tr_type m_org  point_ptcarsequencenumber  \\\n",
       "0 -53372           0     PASSENGER   Ntype   out                        101   \n",
       "1 -85230           0     PASSENGER       L    in                        101   \n",
       "\n",
       "   point_isunexpected planned_status planned_timetabletype     s  w(i,t)  \\\n",
       "0                   0         ACTIVE       COMMERCIAL_STOP   219    8.84   \n",
       "1                   0         ACTIVE     IMPORTANT_PASSAGE  1196  131.00   \n",
       "\n",
       "           point_micro_time  point_micro_fromptrefsymbolicnam  day_name  \\\n",
       "0 2023-04-01 00:02:29+02:00                          367064.0  Saturday   \n",
       "1 2023-04-01 00:03:07+02:00                          401061.0  Saturday   \n",
       "\n",
       "  formatted_point_macro_time  r0  r1  r2  t  \n",
       "0  2023-04-01 00:02:08+02:00   0   6   4  0  \n",
       "1  2023-04-01 00:02:11+02:00   0   6   4  0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function drops three categories: \n",
    "#    - point_ptcarsequencenumber< 101, \n",
    "#    - empty trains \n",
    "#    - frieght trains \n",
    "# \n",
    "# It finally generates an external local file in the working directory specified \n",
    "# in the EFFECTIVE_DF_CLEANED_FILE_PATH, that contains only the needed columns of effective_df\n",
    "################################################################################\n",
    "\n",
    "def store_cleaned_effective_df(effective_df):\n",
    "    print('Before clean: ', effective_df.shape)\n",
    "    effective_df = effective_df[\n",
    "        (effective_df['point_ptcarsequencenumber'] >= 101) &\n",
    "        (effective_df['tr_isempty'] != 1) &\n",
    "        (effective_df['tr_traingroup'] != 'FREIGHT')\n",
    "    ]\n",
    "\n",
    "    effective_df.drop_duplicates(inplace=True)\n",
    "    effective_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print('After clean: ', effective_df.shape)\n",
    "    \n",
    "    effective_df.to_parquet(EFFECTIVE_DF_CLEANED_FILE_PATH, index=False)\n",
    "    return effective_df\n",
    "\n",
    "effective_df = store_cleaned_effective_df(effective_df)\n",
    "effective_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df374775-ed04-4abb-8ace-ea8274436c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_it_df = read_function_data(EFFECTIVE_DF_DA_IT_W_FREIGHT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db954585-e5cc-4ad6-b1e6-24282b657eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>start_t</th>\n",
       "      <th>start_wit</th>\n",
       "      <th>start_t-wit</th>\n",
       "      <th>start_s</th>\n",
       "      <th>end_t</th>\n",
       "      <th>end_wit</th>\n",
       "      <th>end_t-wit</th>\n",
       "      <th>end_s</th>\n",
       "      <th>tr_traingroup</th>\n",
       "      <th>tr_isempty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99992</td>\n",
       "      <td>978</td>\n",
       "      <td>9013.36</td>\n",
       "      <td>948</td>\n",
       "      <td>1010</td>\n",
       "      <td>979</td>\n",
       "      <td>8899.40</td>\n",
       "      <td>950</td>\n",
       "      <td>1715</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-99992</td>\n",
       "      <td>13085</td>\n",
       "      <td>12423.00</td>\n",
       "      <td>13044</td>\n",
       "      <td>1011</td>\n",
       "      <td>13086</td>\n",
       "      <td>12286.00</td>\n",
       "      <td>13046</td>\n",
       "      <td>1715</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2175</td>\n",
       "      <td>420.75</td>\n",
       "      <td>2174</td>\n",
       "      <td>175</td>\n",
       "      <td>2178</td>\n",
       "      <td>871.00</td>\n",
       "      <td>2176</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2456</td>\n",
       "      <td>-1628.00</td>\n",
       "      <td>2462</td>\n",
       "      <td>175</td>\n",
       "      <td>2458</td>\n",
       "      <td>-1335.00</td>\n",
       "      <td>2463</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99991</td>\n",
       "      <td>4948</td>\n",
       "      <td>-2067.00</td>\n",
       "      <td>4955</td>\n",
       "      <td>1034</td>\n",
       "      <td>4950</td>\n",
       "      <td>-1950.64</td>\n",
       "      <td>4957</td>\n",
       "      <td>848</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419468</th>\n",
       "      <td>-17</td>\n",
       "      <td>24961</td>\n",
       "      <td>59.60</td>\n",
       "      <td>24961</td>\n",
       "      <td>642</td>\n",
       "      <td>24984</td>\n",
       "      <td>266.72</td>\n",
       "      <td>24984</td>\n",
       "      <td>219</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419469</th>\n",
       "      <td>-17</td>\n",
       "      <td>25249</td>\n",
       "      <td>46.60</td>\n",
       "      <td>25249</td>\n",
       "      <td>642</td>\n",
       "      <td>25272</td>\n",
       "      <td>393.72</td>\n",
       "      <td>25271</td>\n",
       "      <td>219</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419470</th>\n",
       "      <td>-17</td>\n",
       "      <td>25537</td>\n",
       "      <td>53.60</td>\n",
       "      <td>25537</td>\n",
       "      <td>642</td>\n",
       "      <td>25559</td>\n",
       "      <td>14.72</td>\n",
       "      <td>25559</td>\n",
       "      <td>219</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419471</th>\n",
       "      <td>-17</td>\n",
       "      <td>25825</td>\n",
       "      <td>43.60</td>\n",
       "      <td>25825</td>\n",
       "      <td>642</td>\n",
       "      <td>25847</td>\n",
       "      <td>-5.28</td>\n",
       "      <td>25848</td>\n",
       "      <td>219</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419472</th>\n",
       "      <td>-17</td>\n",
       "      <td>26113</td>\n",
       "      <td>29.60</td>\n",
       "      <td>26113</td>\n",
       "      <td>642</td>\n",
       "      <td>26136</td>\n",
       "      <td>212.72</td>\n",
       "      <td>26136</td>\n",
       "      <td>219</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419473 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            i  start_t  start_wit  start_t-wit  start_s  end_t   end_wit  \\\n",
       "0      -99992      978    9013.36          948     1010    979   8899.40   \n",
       "1      -99992    13085   12423.00        13044     1011  13086  12286.00   \n",
       "2      -99991     2175     420.75         2174      175   2178    871.00   \n",
       "3      -99991     2456   -1628.00         2462      175   2458  -1335.00   \n",
       "4      -99991     4948   -2067.00         4955     1034   4950  -1950.64   \n",
       "...       ...      ...        ...          ...      ...    ...       ...   \n",
       "419468    -17    24961      59.60        24961      642  24984    266.72   \n",
       "419469    -17    25249      46.60        25249      642  25272    393.72   \n",
       "419470    -17    25537      53.60        25537      642  25559     14.72   \n",
       "419471    -17    25825      43.60        25825      642  25847     -5.28   \n",
       "419472    -17    26113      29.60        26113      642  26136    212.72   \n",
       "\n",
       "        end_t-wit  end_s tr_traingroup  tr_isempty  \n",
       "0             950   1715     PASSENGER           1  \n",
       "1           13046   1715     PASSENGER           1  \n",
       "2            2176    848       FREIGHT           0  \n",
       "3            2463    848       FREIGHT           0  \n",
       "4            4957    848       FREIGHT           0  \n",
       "...           ...    ...           ...         ...  \n",
       "419468      24984    219     PASSENGER           0  \n",
       "419469      25271    219     PASSENGER           0  \n",
       "419470      25559    219     PASSENGER           0  \n",
       "419471      25848    219     PASSENGER           0  \n",
       "419472      26136    219     PASSENGER           0  \n",
       "\n",
       "[419473 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_it_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b965af83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:54:49.431282Z",
     "start_time": "2024-11-21T10:54:45.275636Z"
    }
   },
   "outputs": [],
   "source": [
    "effective_df = read_function_data(EFFECTIVE_DF_CLEANED_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf681c8",
   "metadata": {},
   "source": [
    "#### Filling the a_it array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafada12",
   "metadata": {},
   "source": [
    "Filling a dataframe to fill if a train is active at time 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9d4c99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T06:45:14.570054Z",
     "start_time": "2024-08-23T06:45:14.078369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (26209, 5469)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-99970</th>\n",
       "      <th>-99968</th>\n",
       "      <th>-99967</th>\n",
       "      <th>-99936</th>\n",
       "      <th>-99929</th>\n",
       "      <th>-99927</th>\n",
       "      <th>-99925</th>\n",
       "      <th>-99910</th>\n",
       "      <th>-99879</th>\n",
       "      <th>-99876</th>\n",
       "      <th>...</th>\n",
       "      <th>-240</th>\n",
       "      <th>-218</th>\n",
       "      <th>-200</th>\n",
       "      <th>-198</th>\n",
       "      <th>-97</th>\n",
       "      <th>-88</th>\n",
       "      <th>-85</th>\n",
       "      <th>-82</th>\n",
       "      <th>-79</th>\n",
       "      <th>-17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  5469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   -99970  -99968  -99967  -99936  -99929  -99927  -99925  -99910  -99879  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "5       0       0       0       0       0       0       0       0       0   \n",
       "6       0       0       0       0       0       0       0       0       0   \n",
       "7       0       0       0       0       0       0       0       0       0   \n",
       "8       0       0       0       0       0       0       0       0       0   \n",
       "9       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   -99876  ...  -240    -218    -200    -198    -97     -88     -85     \\\n",
       "0       0  ...       0       0       0       0       0       0       0   \n",
       "1       0  ...       0       0       0       0       0       0       0   \n",
       "2       0  ...       0       0       0       0       0       0       0   \n",
       "3       0  ...       0       0       0       0       0       0       0   \n",
       "4       0  ...       0       0       0       0       0       0       0   \n",
       "5       0  ...       0       0       0       0       0       0       0   \n",
       "6       0  ...       0       0       0       0       0       0       0   \n",
       "7       0  ...       0       0       0       0       0       0       0   \n",
       "8       0  ...       0       0       0       0       0       0       0   \n",
       "9       0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "   -82     -79     -17     \n",
       "0       0       0       0  \n",
       "1       0       0       0  \n",
       "2       0       0       0  \n",
       "3       0       0       0  \n",
       "4       0       0       0  \n",
       "5       0       0       0  \n",
       "6       0       0       0  \n",
       "7       0       0       0  \n",
       "8       0       0       0  \n",
       "9       0       0       0  \n",
       "\n",
       "[10 rows x 5469 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions uses DA_it_adjusted_df and creates a new dataframe with \n",
    "# 't' as row index and train i as column index. The cells contains Boolean values  \n",
    "# encoding whether train i is active at time t.\n",
    "# This resulting binary matrix is saved to the local file EFFECTIVE_DF_A_IT_FILE_PATH\n",
    "################################################################################\n",
    "\n",
    "def create_formatted_data_a_it(effective_df, DA_it_df, start_t_col, end_t_col, fileName):\n",
    "    # Filter only passenger trains and non empty trains from DA_it_df    \n",
    "    D_it_df = DA_it_df[(DA_it_df['tr_traingroup'] == 'PASSENGER') & (DA_it_df['tr_isempty'] == 0)]\n",
    "\n",
    "    # Fill 't' index with 0 to the max 't' value from effective_df\n",
    "    max_t = effective_df['t'].max()\n",
    "    t = np.arange(0, max_t + 1)\n",
    "\n",
    "    unique_i = D_it_df['i'].unique()\n",
    "\n",
    "    # Create an empty DataFrame with 't' as index and unique 'i' values as columns\n",
    "    a_it_df = pd.DataFrame(index=t, columns=unique_i, data=np.zeros((len(t), len(unique_i)), dtype=int))\n",
    "\n",
    "    # Iterate over each row in D_it_df to populate the a_it_df DataFrame\n",
    "    for _, row in D_it_df.iterrows():\n",
    "        # Get indices for the range of 't' values between 'start_t_col' and 'end_t_col'\n",
    "        #https://numpy.org/doc/stable/reference/generated/numpy.searchsorted.html\n",
    "        start_idx = np.searchsorted(t, row[start_t_col], side='left')\n",
    "        end_idx = np.searchsorted(t, row[end_t_col], side='right')\n",
    "\n",
    "        # Set '1' for 't' values between 'start_t' and 'end_t' for each 'i'\n",
    "        a_it_df.iloc[start_idx:end_idx, a_it_df.columns.get_loc(row['i'])] = 1\n",
    "\n",
    "    a_it_df.to_parquet(fileName, index=False)\n",
    "    \n",
    "    return a_it_df\n",
    "\n",
    "\n",
    "a_it_df = create_formatted_data_a_it(effective_df, DA_it_df, 'start_t', 'end_t', EFFECTIVE_DF_A_IT_FILE_PATH)\n",
    "a_it_w0_df = create_formatted_data_a_it(effective_df, DA_it_df, 'start_t-wit', 'end_t-wit', EFFECTIVE_DF_A_IT_W0_FILE_PATH)\n",
    "\n",
    "print(\"\\n\", a_it_df.shape)\n",
    "a_it_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c8506",
   "metadata": {},
   "source": [
    "### Departure of train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7593785",
   "metadata": {},
   "source": [
    "Filling a dataframe with earliest deperature of train 'i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e341f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T10:04:21.523459Z",
     "start_time": "2024-09-14T10:04:06.346062Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m     D_it_df\u001b[38;5;241m.\u001b[39mto_parquet(EFFECTIVE_DF_D_IT_FILE_PATH, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Create the optimized D_it_df DataFrame\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m create_formatted_data_D_it(a_it_df)\n",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m, in \u001b[0;36mcreate_formatted_data_D_it\u001b[1;34m(a_it_df)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize the DataFrame for D_it_df\u001b[39;00m\n\u001b[0;32m     22\u001b[0m a_it_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m a_it_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m D_it_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39ma_it_df\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39ma_it_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     24\u001b[0m max_index \u001b[38;5;241m=\u001b[39m a_it_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Process each train identifier\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:876\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    867\u001b[0m             mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    868\u001b[0m                 data,\n\u001b[0;32m    869\u001b[0m                 index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    874\u001b[0m             )\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 876\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    877\u001b[0m             {},\n\u001b[0;32m    878\u001b[0m             index,\n\u001b[0;32m    879\u001b[0m             columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_index(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    880\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    881\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    882\u001b[0m         )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;66;03m# For data is scalar\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m _stack_arrays(\u001b[38;5;28mlist\u001b[39m(tup_block), dtype)\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2254\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m-> 2254\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions uses a_it_df and creates a new dataframe with \n",
    "# 't' as row index and train i as column index. The cells \n",
    "# contains the earliest departure time of train 'i' or when the train was active from the a_it_df\n",
    "# This resulting dataframe is saved to the local file EFFECTIVE_DF_D_IT_FILE_PATH\n",
    "################################################################################\n",
    "\n",
    "a_it_df = read_function_data(EFFECTIVE_DF_A_IT_FILE_PATH)\n",
    "a_it_df.columns = a_it_df.columns.astype(int)\n",
    "\n",
    "\n",
    "def create_formatted_data_D_it(a_it_df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - a_it_df: The DataFrame with 'a_it' values (train active at each time 't').\n",
    "\n",
    "    Returns:\n",
    "    - D_it_df: DataFrame with row index as time (t), columns as train IDs (i), and values as D_it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the DataFrame for D_it_df\n",
    "    a_it_df.columns = a_it_df.columns.astype(int)\n",
    "    D_it_df = pd.DataFrame(index=a_it_df.index, columns=a_it_df.columns)\n",
    "    max_index = a_it_df.index.max()\n",
    "    \n",
    "    # Process each train identifier\n",
    "    for col in a_it_df.columns:\n",
    "        column_data = a_it_df[col]\n",
    "        \n",
    "        # Identify points where the series changed from 0 to 1, earliest departure time of train 'i' \n",
    "        trip_starts = (column_data.shift(1, fill_value=0) == 0) & (column_data == 1)\n",
    "        start_index = column_data.index[trip_starts]\n",
    "        \n",
    "        # Identify points after which the series changes from 1 to 0, indicating the last active time of train\n",
    "        trip_ends = (column_data.shift(-1, fill_value=0) == 0) & (column_data == 1)\n",
    "        end_index = column_data.index[trip_ends]\n",
    "        \n",
    "        ## Fetch all the index at which train stopped\n",
    "        train_halt_index = end_index + 1\n",
    "        \n",
    "        # Filter out invalid indices greater than max_index\n",
    "        valid_mask = train_halt_index <= max_index\n",
    "        train_halt_index = train_halt_index[valid_mask]\n",
    "        #end_index = end_index[valid_mask]\n",
    "        \n",
    "        # Initialize the DataFrame to hold the trip times\n",
    "        trip_df = pd.DataFrame(index=a_it_df.index, columns=[col])\n",
    "        trip_df[col] = np.nan\n",
    "\n",
    "        # Assign the earliest departure time of train 'i' and last active time of train\n",
    "        trip_df.loc[start_index, col] = start_index\n",
    "        trip_df.loc[train_halt_index, col] = -1\n",
    "\n",
    "        # Backward fill the trip times\n",
    "        trip_df.ffill(inplace=True)\n",
    "\n",
    "        # Assign the trip to D_it_df\n",
    "        D_it_df[col] = trip_df[col]\n",
    "        D_it_df[col] = D_it_df[col].fillna(-1).astype(int)\n",
    "        \n",
    "\n",
    "    D_it_df.to_parquet(EFFECTIVE_DF_D_IT_FILE_PATH, index=False)\n",
    "        \n",
    "        \n",
    "# Create the optimized D_it_df DataFrame\n",
    "create_formatted_data_D_it(a_it_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e73cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T02:15:44.794527Z",
     "start_time": "2024-11-15T02:15:44.790221Z"
    }
   },
   "source": [
    "Extracting the earliest deperature of train 'i' at w.r.t time 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1789c300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:28:57.038985Z",
     "start_time": "2025-02-16T09:28:56.369647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n"
     ]
    }
   ],
   "source": [
    "D_it_df = read_function_data(EFFECTIVE_DF_D_IT_FILE_PATH)\n",
    "D_it_df.columns = D_it_df.columns.astype(int)\n",
    "\n",
    "def get_D_it(i, t, row=None, df=D_it_df):\n",
    "    \"\"\"\n",
    "    Check earliest departure time of train 'i' corresponding to time 't'\n",
    "    \n",
    "    Args:\n",
    "    - i: Value for 'i' column (train)\n",
    "    - t: time 't' \n",
    "    - row: pd.Series, optional DataFrame row containing the values for i and t.\n",
    "\n",
    "    Returns:\n",
    "    - int: The latest index where a change from 0 to 1 occurred before or at 't', \n",
    "            or the latest occurrence of 1 before 't'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If a dataframe row is provided as input we extract 'i' and 't' from the row\n",
    "    if row is not None:\n",
    "        i = row[i]\n",
    "        t = row[t]\n",
    "        \n",
    "    if(D_it_df[i].iloc[t]==-1):\n",
    "        return t\n",
    "    else:\n",
    "        return D_it_df[i].iloc[t]\n",
    "\n",
    "# start_t = get_D_it(-43095, 73)\n",
    "# print(\"Start Index of 't':\", start_t)\n",
    "\n",
    "# start_t = get_D_it(-43095, 71)\n",
    "# print(\"Start Index of 't':\", start_t)\n",
    "\n",
    "# print(get_D_it(-99970, 518))\n",
    "# print(get_D_it(-99970, 537))\n",
    "# print(get_D_it(-99970, 538))\n",
    "# print(get_D_it(-99970, 710))\n",
    "print(get_D_it(-99970, 809))\n",
    "# get_D_it(-9003, 105)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31807bb8",
   "metadata": {},
   "source": [
    "## EndogenousData class"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba1b8b69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T02:38:38.626954Z",
     "start_time": "2024-07-29T02:38:38.575531Z"
    }
   },
   "source": [
    "class EndogenousData:\n",
    "\n",
    "    # This contains a dataframe with the following columns:\n",
    "    # - i\n",
    "    # - j\n",
    "    # - t\n",
    "    # - c\n",
    "    # - w_{i,j,t}^c\n",
    "\n",
    "    # Only in this file 'PrepareDataForPrediction.ipynb' the w_{i,j,t}^c in EndogenousData coincides with the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe24f371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:28:27.656055Z",
     "start_time": "2025-02-16T09:28:27.650627Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following is a Class named 'EndogenousData' that contains a dataframe with the following columns:\n",
    "#class EndogenousData:\n",
    "\n",
    "    # This contains a dataframe with the following columns:\n",
    "    # - i\n",
    "    # - j\n",
    "    # - t\n",
    "    # - c\n",
    "    # - w_{i,j,t}^c\n",
    "    \n",
    " # Only in this file 'PrepareDataForPrediction.ipynb' the w_{i,j,t}^c in EndogenousData coincides with the observed data\n",
    "#############################################################################\n",
    "\n",
    "class EndogenousData:\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Initializes the EndogenousData class with a DataFrame.\n",
    "\n",
    "        :param dataframe: A pandas DataFrame containing columns 'i', 'j', 't', 'c', and 'w_{i,j,t}^c'.\n",
    "        :raises ValueError: If the DataFrame does not contain the required columns.\n",
    "        \"\"\"\n",
    "        required_columns = {'i', 'j', 't', 'c', 'w_{i,j,t}^c'}\n",
    "        \n",
    "        # Check if all required columns are present in the DataFrame\n",
    "        if not required_columns.issubset(dataframe.columns):\n",
    "            raise ValueError(f\"DataFrame must contain the following columns: {required_columns}\")\n",
    "        \n",
    "        # Initialize the instance with the DataFrame\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Returns the DataFrame containing the observed data.\n",
    "\n",
    "        :return: A pandas DataFrame with the data.\n",
    "        \"\"\"\n",
    "        return self.dataframe\n",
    "\n",
    "    def filter_data(self, i=None, j=None, t=None, c=None):\n",
    "        \"\"\"\n",
    "        Filters the DataFrame based on the provided criteria.\n",
    "\n",
    "        :param i: Value to filter column 'i'. If None, no filter is applied for 'i'.\n",
    "        :param j: Value to filter column 'j'. If None, no filter is applied for 'j'.\n",
    "        :param t: Value to filter column 't'. If None, no filter is applied for 't'.\n",
    "        :param c: Value to filter column 'c'. If None, no filter is applied for 'c'.\n",
    "\n",
    "        :return: A pandas DataFrame containing the filtered data.\n",
    "        \"\"\"\n",
    "        df = self.dataframe\n",
    "        \n",
    "        # Apply filters based on provided criteria\n",
    "        if i is not None:\n",
    "            df = df[df['i'] == i]\n",
    "        if j is not None:\n",
    "            df = df[df['j'] == j]\n",
    "        if t is not None:\n",
    "            df = df[df['t'] == t]\n",
    "        if c is not None:\n",
    "            df = df[df['c'] == c]\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b698dc",
   "metadata": {},
   "source": [
    "## Prepare column for function S in the EFFECTIVE data set\n",
    "\n",
    "We define $r_0(t)$, $r_1(t)$, and $r_2(t)$ as the respective time of the day (in minutes), the day of the week (from one to seven) and month of the year (from one to seven), corresponding to data time $t$. We introduce the notation $\\boldsymbol{r}(t) = (r_0(t), r_1(t), r_2(t))$.\n",
    "\n",
    "The following code is to create $r_0(t)$, $r_1(t)$, $r_2(t)$ in blocks of 5 minutes, as well as to build function S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421499d",
   "metadata": {},
   "source": [
    "We need fo construct the following function:\n",
    "$$\n",
    "S_{i,s}^{\\boldsymbol{r}(t)}(w_{i,t}) :=~  \\text{whether train $i$ passes through station $s$ at time $r_0(t)$, day $r_1(t)$, month $r_2(t)$ } \n",
    "$$\n",
    "When $w_{i,t}/5$ seconds of delay is experience by train $i$ at clock time $r_0(t)$, the binary indicator of whether train $j$ passes through station $s$ becomes $S_{i,s,r_0(\\tilde{t}_{i,t} ), r_1(\\tilde{t}_{i,t}), r_2(\\tilde{t}_{i,t})}$, where $\\tilde{t}_{i,t} = t + w_{i,t}$. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "13b01edb",
   "metadata": {},
   "source": [
    "## Need to create 4 S functions\n",
    "\n",
    "get_S_r(i, s, r0, r1, r2,m) ---> [return a list {t, get_S_t(i, s, t)} corresponding to r0, r1, r2]\n",
    "get_S_t(i, s, t,m) ---> [return a Boolean]\n",
    "get_S_r_w0(i, s, r0, r1, r2,m) ---> [return a list {t, get_S_t_w0(i, s, t)} corresponding to r0, r1, r2]\n",
    "get_S_t_w0(i, s, t,m) ---> [return a Boolean]\n",
    "\n",
    "satisfying\n",
    "get_S_t(i, s, t - max(w(i,t)),m) = get_S_t_w0(i, s, t,m)\n",
    "get_S_r(i, s, r0(t - max(w(i,t)),m), r1(t - max(w(i,t))), r2(t - max(w(i,t)))) = get_S_r_w0(i, s, r0, r1, r2,m)\n",
    "\n",
    "\n",
    "When you evaluate get_S_r at time\n",
    "\n",
    "r0(t - w(i,t))\n",
    "r1(t - w(i,t))\n",
    "r2(t - w(i,t))\n",
    "\n",
    "It is the same as evaluating get_S_r_w0 at time\n",
    "\n",
    "r0(t)\n",
    "r1(t)\n",
    "r2(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cbf9d2d-e1d5-43f6-8def-1b49f50c062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling train type \n",
    "\n",
    "# Step 1: for each train i, find a non-Ntype tr_type (if any)\n",
    "train_type_map = (\n",
    "    effective_df\n",
    "    .loc[effective_df['tr_type'] != 'Ntype', ['i', 'tr_type']]\n",
    "    .drop_duplicates(subset=['i'])\n",
    "    .set_index('i')['tr_type']\n",
    ")\n",
    "\n",
    "# Step 2: replace Ntype using the mapping\n",
    "effective_df['tr_type'] = np.where(\n",
    "    effective_df['tr_type'] == 'Ntype',\n",
    "    effective_df['i'].map(train_type_map),\n",
    "    effective_df['tr_type']\n",
    ")\n",
    "\n",
    "# Optional: if some trains still have no type, keep them as 'Ntype'\n",
    "effective_df['tr_type'] = effective_df['tr_type'].fillna('Ntype')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96bf323b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T06:43:33.286443Z",
     "start_time": "2024-11-17T06:42:53.612943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_r_w_df shape: (10304572, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>m</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>w(i,t)</th>\n",
       "      <th>t-w(i,t)</th>\n",
       "      <th>r0(t - max(w(i,t)))</th>\n",
       "      <th>r1(t - max(w(i,t)))</th>\n",
       "      <th>r2(t - max(w(i,t)))</th>\n",
       "      <th>tr_type</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Micro_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-53372</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>IC</td>\n",
       "      <td>367064.0</td>\n",
       "      <td>2023-04-01 00:02:29+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-53372</td>\n",
       "      <td>1357</td>\n",
       "      <td>0</td>\n",
       "      <td>passing</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>IC</td>\n",
       "      <td>367064.0</td>\n",
       "      <td>2023-04-01 00:02:29+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-85230</td>\n",
       "      <td>1196</td>\n",
       "      <td>0</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>401061.0</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-85230</td>\n",
       "      <td>1781</td>\n",
       "      <td>0</td>\n",
       "      <td>passing</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>401061.0</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-53372</td>\n",
       "      <td>1048</td>\n",
       "      <td>1</td>\n",
       "      <td>passing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>IC</td>\n",
       "      <td>360432.0</td>\n",
       "      <td>2023-04-01 00:08:45+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304567</th>\n",
       "      <td>-69328</td>\n",
       "      <td>1048</td>\n",
       "      <td>26208</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>-79</td>\n",
       "      <td>26209</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>IC</td>\n",
       "      <td>362041.0</td>\n",
       "      <td>2023-06-30 23:59:58+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304568</th>\n",
       "      <td>-26402</td>\n",
       "      <td>1058</td>\n",
       "      <td>26208</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>26208</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>IC</td>\n",
       "      <td>501502.0</td>\n",
       "      <td>2023-06-30 23:59:43+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304569</th>\n",
       "      <td>-57208</td>\n",
       "      <td>553</td>\n",
       "      <td>26208</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>26208</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>IC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304570</th>\n",
       "      <td>-89150</td>\n",
       "      <td>1047</td>\n",
       "      <td>26208</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>583</td>\n",
       "      <td>26207</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>IC</td>\n",
       "      <td>104162.0</td>\n",
       "      <td>2023-06-30 23:59:15+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304571</th>\n",
       "      <td>-43900</td>\n",
       "      <td>221</td>\n",
       "      <td>26208</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>26208</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>IC</td>\n",
       "      <td>360201.0</td>\n",
       "      <td>2023-06-30 23:59:35+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10304572 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              i     s      t        m  r0  r1  r2  w(i,t)  t-w(i,t)  \\\n",
       "0        -53372   219      0     stop   0   6   4       8         0   \n",
       "1        -53372  1357      0  passing   0   6   4     -32         1   \n",
       "2        -85230  1196      0     stop   0   6   4     147         0   \n",
       "3        -85230  1781      0  passing   0   6   4     127         0   \n",
       "4        -53372  1048      1  passing   1   6   4     -18         2   \n",
       "...         ...   ...    ...      ...  ..  ..  ..     ...       ...   \n",
       "10304567 -69328  1048  26208     stop   0   6   7     -79     26209   \n",
       "10304568 -26402  1058  26208     stop   0   6   7      15     26208   \n",
       "10304569 -57208   553  26208     stop   0   6   7      67     26208   \n",
       "10304570 -89150  1047  26208     stop   0   6   7     583     26207   \n",
       "10304571 -43900   221  26208     stop   0   6   7      98     26208   \n",
       "\n",
       "          r0(t - max(w(i,t)))  r1(t - max(w(i,t)))  r2(t - max(w(i,t)))  \\\n",
       "0                           0                    6                    4   \n",
       "1                           1                    6                    4   \n",
       "2                           0                    6                    4   \n",
       "3                           0                    6                    4   \n",
       "4                           2                    6                    4   \n",
       "...                       ...                  ...                  ...   \n",
       "10304567                    1                    6                    7   \n",
       "10304568                    0                    6                    7   \n",
       "10304569                    0                    6                    7   \n",
       "10304570                  287                    5                    6   \n",
       "10304571                    0                    6                    7   \n",
       "\n",
       "         tr_type    Signal                Micro_time  \n",
       "0             IC  367064.0 2023-04-01 00:02:29+02:00  \n",
       "1             IC  367064.0 2023-04-01 00:02:29+02:00  \n",
       "2              L  401061.0 2023-04-01 00:03:07+02:00  \n",
       "3              L  401061.0 2023-04-01 00:03:07+02:00  \n",
       "4             IC  360432.0 2023-04-01 00:08:45+02:00  \n",
       "...          ...       ...                       ...  \n",
       "10304567      IC  362041.0 2023-06-30 23:59:58+02:00  \n",
       "10304568      IC  501502.0 2023-06-30 23:59:43+02:00  \n",
       "10304569      IC       NaN                       NaT  \n",
       "10304570      IC  104162.0 2023-06-30 23:59:15+02:00  \n",
       "10304571      IC  360201.0 2023-06-30 23:59:35+02:00  \n",
       "\n",
       "[10304572 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions create_formatted_data_frame_for_S_function creates a formatted dataframe from our effective_df\n",
    "#  generates external local file FUNCTION_S_R_W0_FILE_PATH in the working directory, \n",
    "# which will be used for the function get_S_r,get_S_t, get_S_r_w0,get_S_t_w0\n",
    "################################################################################\n",
    "\n",
    "def create_formatted_data_frame_for_S_function():\n",
    "    \"\"\"\n",
    "    Creates formatted data frames from the `effective_df` DataFrame for use in function S.\n",
    "    \n",
    "    1. **s_r_w_df**:\n",
    "       - Groups `effective_df` by columns (`'i'`, `'s'`, `'t'`, `'m'`, `'r0'`, `'r1'`, `'r2'`) and computes the maximum of `'w(i,t)'` for each group.\n",
    "       - Calculates the adjusted time (`'t-w(i,t)'`) by subtracting the floor division of `'w(i,t)'` by 5-minute blocks (converted to minutes) from `'t'`.\n",
    "       - Extracts the components (`'r0'`, `'r1'`, `'r2'`) for the adjusted time (`'t-w(i,t)'`) using the previously defined functions \n",
    "       `get_r0`, `get_r1`, and `get_r2`.\n",
    "       - Saves the result to a Parquet file in the working directory specified by `FUNCTION_S_R_W0_FILE_PATH`.\n",
    "    \n",
    "    Returns:\n",
    "    - s_r_w_df: DataFrame with the maximum values of `'w(i,t)'` and adjusted time components.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = effective_df.copy()\n",
    "    df['formatted_point_macro_time'] = pd.to_datetime(df['formatted_point_macro_time'])\n",
    "    \n",
    "    # Sort by train, station, time, and m_org so IN comes before OUT\n",
    "    df.sort_values(by=['i','s','formatted_point_macro_time','m_org'], \n",
    "                   ascending=[True, True, True, True], inplace=True)\n",
    "    \n",
    "    # Add flags\n",
    "    df['has_in']  = df['m_org'].eq('in')\n",
    "    df['has_out'] = df['m_org'].eq('out')\n",
    "\n",
    "    # Initialize 'm' as stop\n",
    "    df['m'] = 'stop'\n",
    "\n",
    "    # Identify passing rows: IN immediately followed by OUT with nearly same time\n",
    "    df['next_m_org'] = df.groupby(['i','s'])['m_org'].shift(-1)\n",
    "    df['next_time']  = df.groupby(['i','s'])['formatted_point_macro_time'].shift(-1)\n",
    "    \n",
    "    # Time difference in seconds\n",
    "    df['time_diff_sec'] = (df['next_time'] - df['formatted_point_macro_time']).dt.total_seconds().fillna(9999)\n",
    "    \n",
    "    # Passing condition: IN followed by OUT within 2 seconds\n",
    "    passing_mask = (df['m_org']=='in') & (df['next_m_org']=='out') & (df['time_diff_sec']<2)\n",
    "    \n",
    "    # Mark both rows as passing\n",
    "    df.loc[passing_mask, 'm'] = 'passing'\n",
    "    df.loc[passing_mask.shift(1, fill_value=False), 'm'] = 'passing'  # previous row? optional\n",
    "    \n",
    "    # Drop helper columns\n",
    "    df.drop(columns=['has_in','has_out','next_m_org','next_time','time_diff_sec'], inplace=True)\n",
    "\n",
    "\n",
    "    # ===== BUILD THE Signal COLUMN =====\n",
    "    # def pick_signal(g):\n",
    "    #     \"\"\"Return signal value based on rules.\"\"\"\n",
    "    #     in_vals = g.loc[g['m_org']=='in', ['point_micro_fromptrefsymbolicnam', 'point_micro_time']].dropna()\n",
    "    #     out_vals = g.loc[g['m_org']=='out', ['point_micro_fromptrefsymbolicnam', 'point_micro_time']].dropna()\n",
    "\n",
    "    #     if len(in_vals) > 0:\n",
    "    #         return pd.Series(in_vals.iloc[0].values, index=['Signal', 'Micro_time'])  # rule 1\n",
    "    #     elif len(out_vals) > 0:\n",
    "    #         return pd.Series(out_vals.iloc[0].values, index=['Signal', 'Micro_time'])  # rule 2\n",
    "    #     else:\n",
    "    #         return pd.Series([np.nan, np.nan], index=['Signal', 'Micro_time'])  # rule 3\n",
    "            \n",
    "    # signal_df = df.groupby(['i','s','t']).apply(pick_signal).reset_index()\n",
    "\n",
    "\n",
    "    def pick_signal(df):\n",
    "        \"\"\"\n",
    "        Return a DataFrame with one row per group (i, s, t), choosing:\n",
    "        - the first 'in' row if exists\n",
    "        - otherwise the first 'out' row\n",
    "        Adds columns 'Signal' and 'Micro_time'.\n",
    "        \"\"\"\n",
    "        # Assign priority: 'in' = 1, 'out' = 2\n",
    "        df = df.copy()\n",
    "        df['priority'] = df['m_org'].map({'in': 1, 'out': 2})\n",
    "    \n",
    "        # Sort by group and priority\n",
    "        df_sorted = df.sort_values(['i', 's', 't', 'priority'])\n",
    "    \n",
    "        # Take the first row per group\n",
    "        first_rows = df_sorted.groupby(['i', 's', 't'], as_index=False).first()\n",
    "    \n",
    "        # Select and rename columns\n",
    "        result = first_rows[['i', 's', 't', 'tr_type', 'point_micro_fromptrefsymbolicnam', 'point_micro_time']].rename(\n",
    "            columns={'point_micro_fromptrefsymbolicnam': 'Signal', 'point_micro_time': 'Micro_time'}\n",
    "        )\n",
    "    \n",
    "        return result\n",
    "            \n",
    "    signal_df = pick_signal(df)\n",
    "    \n",
    "    # Now you can proceed to build s_r_w_df, grouping and adjusting times as before\n",
    "    s_r_w_df = df.groupby(['i','s','t','m','r0','r1','r2'])['w(i,t)'].max().reset_index()\n",
    "    \n",
    "    s_r_w_df['t-w(i,t)'] = s_r_w_df['t'] - (s_r_w_df['w(i,t)']//(60*5)).astype(T_DATATYPE)\n",
    "    s_r_w_df['r0(t - max(w(i,t)))'] = get_r0(s_r_w_df['t-w(i,t)'])\n",
    "    s_r_w_df['r1(t - max(w(i,t)))'] = get_r1(s_r_w_df['t-w(i,t)'])\n",
    "    s_r_w_df['r2(t - max(w(i,t)))'] = get_r2(s_r_w_df['t-w(i,t)'])\n",
    "    s_r_w_df['w(i,t)'] = s_r_w_df['w(i,t)'].fillna(0).astype(int)\n",
    "\n",
    "    # ===== MERGE Signal INTO s_r_w_df =====\n",
    "    s_r_w_df = s_r_w_df.merge(signal_df, on=['i','s','t'], how='left')\n",
    "    # s_r_w_df = s_r_w_df.merge(time_df, on=['i','s'], how='left')\n",
    "    \n",
    "    s_r_w_df.sort_values('t', inplace=True)\n",
    "    s_r_w_df.reset_index(drop=True, inplace=True)\n",
    "    s_r_w_df.to_parquet(FUNCTION_S_R_W0_FILE_PATH, index=False)\n",
    "    \n",
    "    print(\"s_r_w_df shape:\", s_r_w_df.shape)\n",
    "    return s_r_w_df\n",
    "    \n",
    "create_formatted_data_frame_for_S_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ef3d7",
   "metadata": {},
   "source": [
    "## Function S in the EFFECTIVE data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7cfc538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:20:27.204335Z",
     "start_time": "2025-02-16T09:20:26.279942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 219, 1357, 1196, ...,  156, 1936, 1831])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Call the read_function_data function to read parquet file FUNCTION_S_R_W0_FILE_PATH \n",
    "# we have created earlier in the working directory via the function create_formatted_data_frame_for_S_function, \n",
    "# to fill data for the dataframes s_r_w_df, which will be used by our 4 different s functions\n",
    "################################################################################\n",
    "s_r_w_df = read_function_data(FUNCTION_S_R_W0_FILE_PATH)\n",
    "# s_r_w_df.head(6)\n",
    "\n",
    "global S_set_stations \n",
    "\n",
    "S_set_stations =  s_r_w_df['s'].unique()\n",
    "print(len(S_set_stations))\n",
    "S_set_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eafd8eb-a7fc-4a70-8c7a-ee1ea11fee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['IC', 'L', 'CHART', 'PERS', 'ICE', 'TGV', 'THAL', 'EURST', 'ICT',\n",
       "       'TECH', 'EXT', 'P', 'INT', 'BUS', 'GRP'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_type =  s_r_w_df['tr_type'].unique()\n",
    "print(len(train_type))\n",
    "train_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e5dae",
   "metadata": {},
   "source": [
    "### a_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b16ae0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:20:31.281286Z",
     "start_time": "2025-02-16T09:20:29.932627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_it_df = read_function_data(EFFECTIVE_DF_A_IT_FILE_PATH)\n",
    "a_it_df.columns = a_it_df.columns.astype(int)\n",
    "\n",
    "a_it_w0_df = read_function_data(EFFECTIVE_DF_A_IT_W0_FILE_PATH)\n",
    "a_it_w0_df.columns = a_it_w0_df.columns.astype(int)\n",
    "\n",
    "\n",
    "def get_a_it(i, t=None, row=None):\n",
    "    \"\"\"\n",
    "    Check if train 'i' is active at time 't'. If 't' is not provided, return all times 't' where train 'i' is active.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column (train)\n",
    "    - t: time 't' (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - If 't' is provided: True (1) if train is active at time 't', 0 otherwise.\n",
    "    - If 't' is not provided: A list or Series of times 't' where train 'i' is active.\n",
    "    \"\"\"\n",
    "    if row is not None:\n",
    "        i = row[i]\n",
    "        t = row[t]\n",
    "        return a_it_df[i].iloc[t]\n",
    "        \n",
    "    else:\n",
    "        if t is not None:\n",
    "            return a_it_df[i].loc[t]\n",
    "        else:\n",
    "            return a_it_df.index[a_it_df[i] == 1].tolist()\n",
    "    \n",
    "\n",
    "def get_a_it_w0(i, t=None):\n",
    "    \"\"\"\n",
    "    Check if train 'i' is active at adjusted time 't-w(i,t)'. If 't' is not provided, return all times 't' where train 'i' is active.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column (train)\n",
    "    - t: adjusted time 't' (optional)\n",
    "    \n",
    "    Returns:\n",
    "    - If 't' is provided: True (1) if train is active at the adjusted time 't-w(i,t)', 0 otherwise.\n",
    "    - If 't' is not provided: A list or Series of times 't' where train 'i' is active at the adjusted time.\n",
    "    \"\"\"\n",
    "    #if t is not None:\n",
    "    #return a_it_w0_df[i].loc[t]\n",
    "    #else:\n",
    "    return a_it_w0_df.index[a_it_w0_df[i] == 1].tolist()\n",
    "    \n",
    "    \n",
    "    #active_times_i =get_a_it_w0_without_m()\n",
    "    #active_times_j = a_it_w0_df.index[a_it_w0_df[j] == 1].tolist()   \n",
    "    #return set(active_times_i.union(active_times_j))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## These must satisfy get_a_it(i, t - max(w(i,t)),m) = get_a_it_w0(i, t,m)\n",
    "def get_a_it_with_m(i, t, m):\n",
    "    \"\"\"\n",
    "    Check if train 'i' is active at time 't' on mode 'm'.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column  (train)\n",
    "    - t: time 't'\n",
    "    - m: Value for 'm' column \n",
    "    \n",
    "    Returns:\n",
    "    - True (1) if the combination is present, 0 otherwise\n",
    "    \"\"\"\n",
    "    i_match = s_r_w_df['i'].values == i\n",
    "    t_match = s_r_w_df['t'].values == t\n",
    "    m_match = s_r_w_df['m'].values == m\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & t_match & m_match\n",
    "    \n",
    "    return 1 if np.any(combined_match) else 0\n",
    "\n",
    "def get_a_it_w0_with_m(i, t, m):\n",
    "    \"\"\"\n",
    "    Check if train 'i' is active at adjusted time 't-w(i,t)'  on mode 'm'.\n",
    "    \n",
    "    Parameters:\n",
    "    - i: Value for 'i' column  (train)\n",
    "    - t: adjusted time 't'\n",
    "    - m: Value for 'm' column \n",
    "    \n",
    "    Returns:\n",
    "    - True (1) if the combination is present, 0 otherwise\n",
    "    \"\"\"\n",
    "    i_match = s_r_w_df['i'].values == i\n",
    "    t_match = s_r_w_df['t-w(i,t)'].values == t\n",
    "    m_match = s_r_w_df['m'].values == m\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & t_match & m_match\n",
    "    \n",
    "    return 1 if np.any(combined_match) else 0\n",
    "\n",
    "print(get_a_it(-91842, 5))\n",
    "get_a_it_with_m(-91842, 0,'passing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8b121f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:55:37.580462Z",
     "start_time": "2024-11-21T10:55:37.020035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(978, 1)\n",
      "(978, 1)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions `get_S_t`, takes   train ,  station ,  time 't', mode 'm' as input \n",
    "# verifies the s_r_w_df if the combination is present \n",
    "# and returns a boolean if  train ,  passes thru station  at  time 't' \n",
    "################################################################################\n",
    "\n",
    "def get_S_t(i, s, t, m, s_r_w_df):\n",
    "    \"\"\"\n",
    "    Check if the combination of values (i, s, t,m) is present in the s_r_w_df DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column  (train)\n",
    "    - s: Value for 's' column  (station)\n",
    "    - t: time 't'\n",
    "    - m: Value for 'm' column \n",
    "    - s_r_w_df: DataFrame to check for presence\n",
    "\n",
    "    Returns:\n",
    "    - True (1) if the combination is present, 0 otherwise\n",
    "    \"\"\"\n",
    "    # Convert the relevant columns to NumPy arrays for efficient operations and compare\n",
    "    i_match = s_r_w_df['i'].values == i\n",
    "    s_match = s_r_w_df['s'].values == s\n",
    "    t_match = s_r_w_df['t'].values == t\n",
    "    m_match = s_r_w_df['m'].values == m\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & s_match & t_match & m_match\n",
    "    \n",
    "    return 1 if np.any(combined_match) else 0\n",
    "\n",
    "value_to_check = (-99992, 1010,978,'stop')\n",
    "print(get_S_t(*value_to_check, s_r_w_df))\n",
    "\n",
    "value_to_check = (-99992, 1011,978,'in')\n",
    "print(get_S_t(*value_to_check, s_r_w_df))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# The following functions `get_S_r`, takes  train ,  station  , minute 'r0', day 'r1', month 'r2',mode 'm', as input \n",
    "# It verifies in the 's_r_w_df' data frame if the combination is present it returns a list {t, get_S_t(i, s, t)} \n",
    "# corresponding to r0, r1, r2 \n",
    "###############################################################################\n",
    "\n",
    "def get_S_r(i, s, r0, r1, r2, m, s_r_w_df):\n",
    "    \"\"\"\n",
    "    Check if the combination of values (i, s, m, r0, r1, r2) is present in the s_r_w_df DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column  (train)\n",
    "    - s: Value for 's' column  (station)\n",
    "    - r0: Value for 'r0' column  (minute)\n",
    "    - r1: Value for 'r1' column  (day)\n",
    "    - r2: Value for 'r2' column  (month)\n",
    "    - m: Value for 'm' column\n",
    "    - s_r_w_df: DataFrame to check for presence\n",
    "\n",
    "    Returns:\n",
    "    - return a list {t, get_S_t(i, s, t)} corresponding to r0, r1, r2\n",
    "    \"\"\"\n",
    "    # Convert the relevant columns to NumPy arrays for efficient operations and compare\n",
    "    i_match = s_r_w_df['i'].values == i\n",
    "    s_match = s_r_w_df['s'].values == s\n",
    "    r0_match = s_r_w_df['r0'].values == r0\n",
    "    r1_match = s_r_w_df['r1'].values == r1\n",
    "    r2_match = s_r_w_df['r2'].values == r2\n",
    "    m_match = s_r_w_df['m'].values == m\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & s_match & r0_match & r1_match & r2_match & m_match\n",
    "    combined_time = r0_match & r1_match & r2_match \n",
    "    \n",
    "    values_list = s_r_w_df['t'].values[combined_time].tolist()\n",
    "\n",
    "    if len(s_r_w_df['t'].values[combined_time].tolist()) > 0: \n",
    "\n",
    "        out_list = values_list[0]\n",
    "        S = 1\n",
    "    else: \n",
    "        \n",
    "        out_list = []\n",
    "        S = 0\n",
    "        \n",
    "    return out_list, S\n",
    "\n",
    "value_to_check = (-99992, 1010, 114, 2,4,'stop')\n",
    "print(get_S_r(*value_to_check, s_r_w_df))\n",
    "\n",
    "value_to_check = (-99992, 1011,114, 2,4,'passing')\n",
    "print(get_S_r(*value_to_check, s_r_w_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502bc5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:55:41.370891Z",
     "start_time": "2024-11-21T10:55:37.989590Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following functions `get_S_t`, takes  train , station  and adjusted time (`'t-w(i,t)'`) as 't',mode 'm', as input\n",
    "# verifies the s_r_w_df if the combination is present in 'i', 's_vec', 't-w(i-t)'\n",
    "# and returns a boolean array of 1s and 0s\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def get_S_t_w0(i_values, s_values, t_values, m, s_r_w_df, status):\n",
    "    \n",
    "    \"\"\"\n",
    "    Optimized version of get_S_t_w0 that returns arrays of 0s and 1s for each 't' value\n",
    "    with 'i' values as columns in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - i_values: Array of 'i' values.\n",
    "    - s_values: Array of 's' values.\n",
    "    - t_values: Array of 't' values.\n",
    "    - m: Value for 'm' column.\n",
    "    - s_r_w_df: DataFrame to check for presence.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with 't' as index, 'i' as columns, and arrays of 0s and 1s as values.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the given 'm' value\n",
    "    filtered_df = s_r_w_df[s_r_w_df['m'] == m]\n",
    "\n",
    "    if type(t_values) == int and type(i_values) == int:\n",
    "\n",
    "        # Create a mask for the conditions that do not depend on s\n",
    "        i_match = s_r_w_df['i'].values == i_values\n",
    "        # t_match = s_r_w_df['t-w(i,t)'].values == t_values\n",
    "        t_match = s_r_w_df['t'].values == t_values\n",
    "        m_match = s_r_w_df['m'].values == m\n",
    "        \n",
    "        combined_mask = i_match & t_match & m_match\n",
    "        \n",
    "        # Filter the dataframe based on the combined mask\n",
    "        filtered_df = s_r_w_df[combined_mask]\n",
    "    \n",
    "        # Check for the presence of each s value in the filtered dataframe\n",
    "        s_present = np.isin(s_values, filtered_df['s'].values)\n",
    "    \n",
    "        # Convert boolean array to int (1 for True, 0 for False)\n",
    "        OUT = s_present.astype(int)\n",
    "\n",
    "    elif type(t_values) == int and type(i_values) != int:\n",
    "\n",
    "       # Create an empty DataFrame with 't' as the index and 'i' values as columns\n",
    "        results_df = pd.DataFrame(index=t_values, columns=i_values)\n",
    "    \n",
    "        # Initialize with empty lists that will store arrays for each 't' and 'i'\n",
    "        for col in results_df.columns:\n",
    "            results_df[col] = results_df.index.map(lambda _: np.zeros(len(s_values), dtype=np.int8))\n",
    "    \n",
    "        # # Group the filtered DataFrame by 'i' and 't-w(i,t)' to avoid looping\n",
    "        # grouped = filtered_df.groupby(['i', 't-w(i,t)'])\n",
    "\n",
    "        # Group the filtered DataFrame by 'i' and 't' to avoid looping\n",
    "        grouped = filtered_df.groupby(['i', 't'])\n",
    "        \n",
    "        # Iterate over groups and fill the results DataFrame\n",
    "        for (i, t), group in grouped:\n",
    "            if t in t_values:\n",
    "                # Initialize an array of zeros with the same length as s_values\n",
    "                present_s = np.zeros(len(s_values), dtype=np.int8)\n",
    "                \n",
    "                # Get the 's' values from the group\n",
    "                s_in_group = group['s'].values\n",
    "                \n",
    "                # Find which s_values are present in this group and update present_s\n",
    "                present_s[np.isin(s_values, s_in_group)] = 1\n",
    "                \n",
    "                # Update the corresponding column in the results DataFrame for the given 't' and 'i'\n",
    "                results_df.at[t, i] = present_s\n",
    "\n",
    "        OUT = results_df\n",
    "    \n",
    "    elif type(t_values) != int and type(i_values) == int:\n",
    "\n",
    "       # Create an empty DataFrame with 't' as the index and 'i' values as columns\n",
    "        results_df = pd.DataFrame(index=t_values, columns=i_values)\n",
    "    \n",
    "        # Initialize with empty lists that will store arrays for each 't' and 'i'\n",
    "        for col in results_df.columns:\n",
    "            results_df[col] = results_df.index.map(lambda _: np.zeros(len(s_values), dtype=np.int8))\n",
    "    \n",
    "        # # Group the filtered DataFrame by 'i' and 't-w(i,t)' to avoid looping\n",
    "        # grouped = filtered_df.groupby(['i', 't-w(i,t)'])\n",
    "\n",
    "        # Group the filtered DataFrame by 'i' and 't' to avoid looping\n",
    "        grouped = filtered_df.groupby(['i', 't'])\n",
    "    \n",
    "        # Iterate over groups and fill the results DataFrame\n",
    "        for (i, t), group in grouped:\n",
    "            if i in i_values:\n",
    "                # Initialize an array of zeros with the same length as s_values\n",
    "                present_s = np.zeros(len(s_values), dtype=np.int8)\n",
    "                \n",
    "                # Get the 's' values from the group\n",
    "                s_in_group = group['s'].values\n",
    "                \n",
    "                # Find which s_values are present in this group and update present_s\n",
    "                present_s[np.isin(s_values, s_in_group)] = 1\n",
    "                \n",
    "                # Update the corresponding column in the results DataFrame for the given 't' and 'i'\n",
    "                results_df.at[t, i] = present_s\n",
    "\n",
    "        OUT = results_df\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Create maps from values to matrix indices\n",
    "        t_index = {t: idx for idx, t in enumerate(t_values)}\n",
    "        i_index = {i: idx for idx, i in enumerate(i_values)}\n",
    "        s_index = {s: idx for idx, s in enumerate(s_values)}\n",
    "        \n",
    "        # Build 3D result array (T  I  S)\n",
    "        result = np.zeros((len(t_values), len(i_values), len(s_values)), dtype=np.int8)\n",
    "        \n",
    "        # Convert t,i,s to index arrays (vectorized)\n",
    "        if status == 'delay':\n",
    "            ti = filtered_df['t'].map(t_index)\n",
    "        else:\n",
    "            ti = filtered_df['t-w(i,t)'].map(t_index)\n",
    "        ii = filtered_df['i'].map(i_index)\n",
    "        si = filtered_df['s'].map(s_index)\n",
    "        \n",
    "        # Drop rows where t or i are not in valid ranges\n",
    "        valid = ti.notna() & ii.notna() & si.notna()\n",
    "        ti = ti[valid].astype(int)\n",
    "        ii = ii[valid].astype(int)\n",
    "        si = si[valid].astype(int)\n",
    "        \n",
    "        # Vectorized filling (no loops!)\n",
    "        result[ti, ii, si] = 1\n",
    "        \n",
    "        # Optional: convert to your DataFrame form\n",
    "        results_df = pd.DataFrame(\n",
    "            {i: list(result[:, i_index[i], :]) for i in i_values},\n",
    "            index=t_values\n",
    "        )\n",
    "\n",
    "        OUT = results_df\n",
    "        \n",
    "    return OUT\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# The following function is a helper function to call the 'get_S_t_w0_optimized' function \n",
    "################################################################################ \n",
    "\n",
    "def get_S_t_w0_optimized_helper(i_values, status):\n",
    "    \n",
    "    # t_values = range(s_r_w_df['t-w(i,t)'].min(), s_r_w_df['t-w(i,t)'].max())\n",
    "    t_values = range(s_r_w_df['t'].min(), s_r_w_df['t'].max())\n",
    "    m_value = \"stop\"\n",
    "    results_stop = get_S_t_w0(i_values, S_set_stations, t_values, m_value, s_r_w_df, status)\n",
    "\n",
    "    m_value = \"passing\"\n",
    "    results_passing = get_S_t_w0(i_values, S_set_stations, t_values, m_value, s_r_w_df, status)\n",
    "    \n",
    "    return results_stop,results_passing\n",
    "    \n",
    "\n",
    "################################################################################\n",
    "# The following functions `get_S_r_w0`, takes   train ,  station  and  \n",
    "# adjusted minute 'r0(t - max(w(i,t)))', adjusted day 'r1(t - max(w(i,t)))', adjusted month 'r0(t - max(w(i,t)))', \n",
    "# as (r0, r1, and r2), mode 'm', as input\n",
    "# verifies s_r_w_df if the combination is is present in 'i', 's', 'r0(t - max(w(i,t)))','r1(t - max(w(i,t)))','r2(t - max(w(i,t)))'\n",
    "# and returns a list {t, get_S_t_w0(i, s, t)} corresponding to r0, r1, r2 \n",
    "###############################################################################\n",
    "\n",
    "def get_S_r_w0(i, s, r0, r1, r2,m, s_r_w_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if the combination of values (i, s, r0, r1, r2) is present in the s_r_w_df DataFrame columns \n",
    "    i, s, adjusted minute r0(t - max(w(i,t)))', adjusted day 'r1(t - max(w(i,t)))', \n",
    "    adjusted month 'r2(t - max(w(i,t)))'\n",
    "\n",
    "    Parameters:\n",
    "    - i: Value for 'i' column  (train)\n",
    "    - s: Value for 's' column  (station)\n",
    "    - r0: Value for adjusted 'r0' column  (minute)\n",
    "    - r1: Value for adjusted 'r1' column  (day)\n",
    "    - r2: Value for adjusted 'r2' column  (month)\n",
    "    - m: Value for 'm' column\n",
    "    - s_r_w_df: DataFrame to check for presence\n",
    "\n",
    "    Returns:\n",
    "    - return a list {t, get_S_t_w0(i, s, t)} corresponding to r0, r1, r2\n",
    "    \"\"\"\n",
    "    # Convert the relevant columns to NumPy arrays for efficient operations and compare\n",
    "    i_match = s_r_w_df['i'].values == i\n",
    "    s_match = s_r_w_df['s'].values == s\n",
    "    r0_match = s_r_w_df['r0(t - max(w(i,t)))'].values == r0\n",
    "    r1_match = s_r_w_df['r1(t - max(w(i,t)))'].values == r1\n",
    "    r2_match = s_r_w_df['r2(t - max(w(i,t)))'].values == r2\n",
    "    m_match = s_r_w_df['m'].values == m\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & s_match & r0_match & r1_match & r2_match & m_match\n",
    "    combined_time = r0_match & r1_match & r2_match \n",
    "    \n",
    "    values_list = s_r_w_df['t-w(i,t)'].values[combined_time].tolist()\n",
    "\n",
    "    if len(s_r_w_df['t-w(i,t)'].values[combined_time].tolist()) > 0: \n",
    "\n",
    "        out_list = values_list[0]\n",
    "        S = 1\n",
    "    else: \n",
    "        \n",
    "        out_list = []\n",
    "        S = 0\n",
    "        \n",
    "    return out_list, S\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d51ff53",
   "metadata": {},
   "source": [
    "### Construct G functions:\n",
    "$$\n",
    "\\left\\{\\begin{array}{ll}\n",
    "G_{i,j,t,q}^-(W) & = \n",
    "\\begin{cases}\n",
    "    \\displaystyle \\sum_{s \\in \\mathcal{S}} \\sum_{\\ell_i = 1}^{\\tau} \\sum_{\\ell_j = 1}^{\\tau}  S_{i,s,0}^{\\boldsymbol{r}(t-\\ell_i)}(w_{i,t-\\ell_i}) S_{j,s,0}^{\\boldsymbol{r}(t-\\ell_j)}(w_{i,t-\\ell_j}), & \\mbox{ if } q = 0 \\\\[0.5cm]\n",
    "    \\displaystyle \\sum_{s \\in \\mathcal{S}} \\sum_{\\ell_i = 1}^{\\tau} \\sum_{\\ell_j = 1}^{\\tau}  S_{i,s,1}^{\\boldsymbol{r}(t-\\ell_i)}(w_{i,t-\\ell_i}) S_{j,s,1}^{\\boldsymbol{r}(t-\\ell_j)}(w_{i,t-\\ell_j}), & \\mbox{ if } q = 1 \\\\[0.5cm]  \n",
    "    \\displaystyle \\sum_{s \\in \\mathcal{S}} \\sum_{\\ell_i = 1}^{\\tau} \\sum_{\\ell_j = 1}^{\\tau}  \\left[S_{i,s,0}^{\\boldsymbol{r}(t-\\ell_i)}(w_{i,t-\\ell_i}) S_{j,s,1}^{\\boldsymbol{r}(t-\\ell_j)}(w_{i,t-\\ell_j}) + S_{i,s,1}^{\\boldsymbol{r}(t-\\ell_i)}(w_{i,t-\\ell_i}) S_{j,s,0}^{\\boldsymbol{r}(t-\\ell_j)}(w_{i,t-\\ell_j})\\right], & \\mbox{ if } q = 2 \\\\[0.5cm]  \n",
    "\\end{cases}  \\\\[2.0cm]\n",
    "G_{i,j,t,q}^+(W) & \\displaystyle = \\sum_{s \\in \\mathcal{S}} \\sum_{\\ell_i = 1}^{\\tau} \\sum_{\\ell_j = 1}^{\\tau}   S_{i,s, m}^{\\boldsymbol{r}(t+\\ell_i)}(w_{i,t}) S_{j,s, m}^{\\boldsymbol{r}(t+\\ell_j)}(w_{j,t}).  \n",
    "\\end{array}\\right.\n",
    "$$\n",
    "Here $G_{i,j,t}^-$ and $G_{i,j,t}^+$ encodes the degree of space-time proximity between trains $i$ and $j$, based on past and future encounters (resource sharing), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c7871",
   "metadata": {},
   "source": [
    "Based on this characterization of pairwise resourse sharing and potential interference between each pair of trains, the neighborshood list is defined as $\\mathcal{E}_{i,t} = \\{j \\in \\mathcal{N} ~:~ \\tilde{G}_{i,j,t}^c = 1\\}$. We define the whole neighborshood structure as $\\mathcal{E}_t = \\{(i, j) \\in \\mathbb{N}^2 ~:~ j \\in \\mathcal{E}_{i,t}, i \\in \\mathcal{N}\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbbde99d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:55:42.482552Z",
     "start_time": "2024-11-21T10:55:42.470556Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "#\n",
    "# The following function is the common function for Gplus and Gminus\n",
    "# i, S_set_stations, time_i, m\n",
    "# j, S_set_stations, time_i, m\n",
    "# \n",
    "#\n",
    "##########################################################################################   \n",
    "\n",
    "def get_G_minus_optimized(i, j, t, , h, S_dictionary):\n",
    "    \n",
    "    \"\"\"\n",
    "    - i (int): Train identifier.\n",
    "    - j : Delay-causing trains 'j' for a given train 'i'.\n",
    "    - t : Time.\n",
    "    -  : Time window.\n",
    "    - h : Mode indicator (0, 1, or 2).\n",
    "    - op : Operation to perform on time ('plus' or 'minus').\n",
    "    - S_dictionary : dictionary to store previously fetched output for a set of input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Bind dictionary locally for speed\n",
    "    Sd = S_dictionary\n",
    "\n",
    "    # Precompute time offsets\n",
    "    time_range = range(t, t - , -1)\n",
    "\n",
    "    result = 0\n",
    "\n",
    "    if h == 0 or h == 1:\n",
    "\n",
    "        m = \"stop\" if h == 0 else \"passing\"\n",
    "\n",
    "        # Precompute (i, time, m) and (j, time, m)\n",
    "        keys_i = [(i, ti, m) for ti in time_range]\n",
    "        keys_j = [(j, tj, m) for tj in time_range]\n",
    "\n",
    "        # Pre-fetch all vectors\n",
    "        vec_i = [Sd[k] for k in keys_i]\n",
    "        vec_j = [Sd[k] for k in keys_j]\n",
    "\n",
    "        # Small   tiny double loop = fastest option\n",
    "        for vi in vec_i:\n",
    "            for vj in vec_j:\n",
    "                result += np.dot(vi, vj)\n",
    "\n",
    "    else:\n",
    "        # h == 2\n",
    "        keys_i_stop = [(i, ti, \"stop\") for ti in time_range]\n",
    "        keys_i_pass = [(i, ti, \"passing\") for ti in time_range]\n",
    "        keys_j_stop = [(j, tj, \"stop\") for tj in time_range]\n",
    "        keys_j_pass = [(j, tj, \"passing\") for tj in time_range]\n",
    "\n",
    "        i_stop = [Sd[k] for k in keys_i_stop]\n",
    "        i_pass = [Sd[k] for k in keys_i_pass]\n",
    "        j_stop = [Sd[k] for k in keys_j_stop]\n",
    "        j_pass = [Sd[k] for k in keys_j_pass]\n",
    "\n",
    "        for is0, ip0 in zip(i_stop, i_pass):\n",
    "            for js0, jp0 in zip(j_stop, j_pass):\n",
    "                result += np.dot(is0, jp0) + np.dot(ip0, js0)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_G_minus_helper_optimized(i, j, t, delay_dictionary,):\n",
    "   \n",
    "    m0_minus = get_G_minus_optimized(i, j, t, ,0,delay_dictionary)\n",
    "    m1_minus = get_G_minus_optimized(i, j, t, ,1,delay_dictionary)\n",
    "    m2_minus = get_G_minus_optimized(i, j, t, ,2,delay_dictionary)\n",
    "        \n",
    "    return m0_minus,m1_minus,m2_minus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "522cff4c-ccc5-4411-a264-62e1ff19d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "#\n",
    "# The following function is the common function for Gplus and Gminus\n",
    "# i, S_set_stations, time_i, m\n",
    "# j, S_set_stations, time_i, m\n",
    "# \n",
    "#\n",
    "##########################################################################################   \n",
    "\n",
    "def get_G_plus_optimized(i, j, t1, t2, , h, S_dictionary):\n",
    "    \n",
    "    \"\"\"\n",
    "    - i (int): Train identifier.\n",
    "    - j : Delay-causing trains 'j' for a given train 'i'.\n",
    "    - t : Time.\n",
    "    -  : Time window.\n",
    "    - h : Mode indicator (0, 1, or 2).\n",
    "    - op : Operation to perform on time ('plus' or 'minus').\n",
    "    - S_dictionary : dictionary to store previously fetched output for a set of input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Bind dictionary locally for speed\n",
    "    Sd = S_dictionary\n",
    "\n",
    "    # Precompute time offsets\n",
    "    time_range_i = range(t1, t1 + )\n",
    "    time_range_j = range(t2, t2 + )\n",
    "\n",
    "    result = 0\n",
    "\n",
    "    if h == 0 or h == 1:\n",
    "\n",
    "        m = \"stop\" if h == 0 else \"passing\"\n",
    "\n",
    "        # Precompute (i, time, m) and (j, time, m) \n",
    "        keys_i = [(i, ti, m) for ti in time_range_i]\n",
    "        keys_j = [(j, tj, m) for tj in time_range_j]\n",
    "\n",
    "        # Pre-fetch all vectors\n",
    "        vec_i = [Sd[k] for k in keys_i]\n",
    "        vec_j = [Sd[k] for k in keys_j]\n",
    "\n",
    "        # Small   tiny double loop = fastest option\n",
    "        for vi in vec_i:\n",
    "            for vj in vec_j:\n",
    "                result += np.dot(vi, vj)\n",
    "\n",
    "    else:\n",
    "        # h == 2\n",
    "        keys_i_stop = [(i, ti, \"stop\") for ti in time_range_i]\n",
    "        keys_i_pass = [(i, ti, \"passing\") for ti in time_range_i]\n",
    "        keys_j_stop = [(j, tj, \"stop\") for tj in time_range_j]\n",
    "        keys_j_pass = [(j, tj, \"passing\") for tj in time_range_j]\n",
    "\n",
    "        i_stop = [Sd[k] for k in keys_i_stop]\n",
    "        i_pass = [Sd[k] for k in keys_i_pass]\n",
    "        j_stop = [Sd[k] for k in keys_j_stop]\n",
    "        j_pass = [Sd[k] for k in keys_j_pass]\n",
    "\n",
    "        for is0, ip0 in zip(i_stop, i_pass):\n",
    "            for js0, jp0 in zip(j_stop, j_pass):\n",
    "                result += np.dot(is0, jp0) + np.dot(ip0, js0)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_G_plus_helper_optimized(i, j, ti, tj,schedule_dictionary,):\n",
    "\n",
    "    m0_plus = get_G_plus_optimized(i, j, ti, tj, ,0,schedule_dictionary)\n",
    "    m1_plus = get_G_plus_optimized(i, j, ti, tj, ,1,schedule_dictionary)\n",
    "    m2_plus = get_G_plus_optimized(i, j, ti, tj, ,2,schedule_dictionary)\n",
    "        \n",
    "    return m0_plus,m1_plus,m2_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "561e5074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T02:26:20.235731Z",
     "start_time": "2024-11-18T02:26:00.981200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed t 100\n",
      "\n",
      " Calling G plus  0\n",
      "result =  0\n",
      "\n",
      " Calling G plus  1\n",
      "result =  0\n",
      "\n",
      " Calling G plus  2\n",
      "result =  0\n",
      "\n",
      " Calling G plus  0\n",
      "result =  0\n",
      "\n",
      " Calling G plus  1\n",
      "result =  0\n",
      "\n",
      " Calling G plus  2\n",
      "result =  0\n",
      "\n",
      " Calling G minus  0\n",
      "result =  0\n",
      "\n",
      " Calling G minus  1\n",
      "result =  0\n",
      "\n",
      " Calling G minus  2\n",
      "result =  0\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#\n",
    "# The following function is the common function for Gplus and Gminus\n",
    "# Call the get_S_t_w0 function for every combination of \n",
    "# i, S_set_stations, time_i, m\n",
    "# j, S_set_stations, time_i, m\n",
    "# store the result retrived for every input by keeping the corresponding combination of input \n",
    "# (i, time_i, m)   (j, time_j, m) as key \n",
    "# and output of get_S_t_w0 as value in delay_dictionary\n",
    "#\n",
    "##########################################################################################   \n",
    "\n",
    "def get_G(i, j, t, , h, op, S_dictionary):\n",
    "    \n",
    "    \"\"\"\n",
    "    - i (int): Train identifier.\n",
    "    - j : Delay-causing trains 'j' for a given train 'i'.\n",
    "    - t : Time.\n",
    "    -  : Time window.\n",
    "    - h : Mode indicator (0, 1, or 2).\n",
    "    - op : Operation to perform on time ('plus' or 'minus').\n",
    "    - S_dictionary : dictionary to store previously fetched output for a set of input.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply_op(t, li, op):\n",
    "        return t + li - 1 if op == 'plus' else t - li\n",
    "        # return t + li if op == 'plus' else t - li\n",
    "        \n",
    "    result = 0\n",
    "    time_range = np.arange(1,  + 1)\n",
    "    \n",
    "    # Compute adjusted times for all li and lj\n",
    "    times_i = apply_op(t, time_range, op)\n",
    "    times_j = times_i\n",
    "\n",
    "    if h == 0 or h == 1:\n",
    "        m = \"stop\" if h == 0 else \"passing\"\n",
    "        \n",
    "        ## Call the get_S_t_w0 function for every combination of i, S_set_stations, time_i, m and store in the dictionary\n",
    "        for time_i in times_i:\n",
    "            time_i = int(time_i)\n",
    "            key_i = (i, time_i, m)\n",
    "            if key_i not in S_dictionary:\n",
    "                S_dictionary[key_i] = get_S_t_w0(i, S_set_stations, time_i, m, s_r_w_df)\n",
    "            delay_i = S_dictionary[key_i]\n",
    "            \n",
    "            ## Call the get_S_t_w0 function for every combination of j, S_set_stations, time_j, m and store in the dictionary\n",
    "            for time_j in times_j:\n",
    "                time_j = int(time_j)\n",
    "                key_j = (j, time_j, m)\n",
    "                if key_j not in S_dictionary:\n",
    "                    S_dictionary[key_j] = get_S_t_w0(j, S_set_stations, time_j, m, s_r_w_df)\n",
    "                delay_j = S_dictionary[key_j]\n",
    "\n",
    "                # Multiply the vectors element-wise and sum the result\n",
    "                product_sum = np.dot(delay_i, delay_j)\n",
    "                if(product_sum!=0):\n",
    "                    print(f\"T {op} li and t {op} lj\", i, j, time_i, time_j, product_sum)\n",
    "                    result += product_sum\n",
    "               \n",
    "    else:\n",
    "        m = \"stop\"\n",
    "        n = \"passing\"\n",
    "        \n",
    "        for time_i in times_i:\n",
    "            time_i = int(time_i)\n",
    "            i_m = (i, time_i, m)\n",
    "            i_n = (i, time_i, n)\n",
    "                \n",
    "            # since we have already stored all the combinations in dictionary we dont call\n",
    "            # get_S_t_w0 again instead, fetch the result from the delay_dictionary\n",
    "            delay_i0 = S_dictionary[i_m]\n",
    "            delay_i1 = S_dictionary[i_n]\n",
    "            \n",
    "            for time_j in times_j:\n",
    "                time_j = int(time_j)\n",
    "                j_m = (j, time_j, m)\n",
    "                j_n = (j, time_j, n)\n",
    "                \n",
    "                delay_j1 = S_dictionary[j_n]\n",
    "                delay_j0 = S_dictionary[j_m]\n",
    "                \n",
    "                # Multiply the vectors element-wise and sum the result\n",
    "                product_sum = np.dot(delay_i0, delay_j1)\n",
    "                result += product_sum\n",
    "\n",
    "                product_sum1 = np.dot(delay_i1, delay_j0)\n",
    "                result += product_sum1\n",
    "                    \n",
    "    return result\n",
    "\n",
    "# Example usage of get_G:\n",
    "## Note : for testing purpose i have used different 't' for Gplus and Gminus, usually the same 't' will be passed\n",
    "# Dictionary to store intermediate results\n",
    "delay_dict = {}\n",
    "i= -9001\n",
    "j = -9002\n",
    "t = 100\n",
    "\n",
    "print(\"passed t\", t)\n",
    " = 3  # Example value for \n",
    "\n",
    "m = 0\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t, ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 1\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t,  ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 2\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t,  ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "\n",
    "i= -9001\n",
    "j = -9002\n",
    "t = 100\n",
    " = 3  # Example value for \n",
    "\n",
    "m = 0\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t, ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 1\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t,  ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 2\n",
    "print(\"\\n Calling G plus \",m)\n",
    "result = get_G(i, j, t,  ,m,\"plus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 0\n",
    "print(\"\\n Calling G minus \",m)\n",
    "result = get_G(i, j, t, ,m,\"minus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 1\n",
    "print(\"\\n Calling G minus \",m)\n",
    "result = get_G(i, j, t, ,m,\"minus\",delay_dict)\n",
    "print(\"result = \",result)\n",
    "\n",
    "m = 2\n",
    "print(\"\\n Calling G minus \",m)\n",
    "result = get_G(i, j, t, ,m,\"minus\",delay_dict)\n",
    "print(\"result = \",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e33820",
   "metadata": {},
   "source": [
    "# Explore and check the correctness of juftif data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd1f30e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:12:12.826236Z",
     "start_time": "2024-11-29T11:12:11.689150Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['messageID', 'messageTimestamp', 'tableType', 'justificationID',\n",
      "       'departuredate', 'trainnumber', 'circulationType', 'automatic',\n",
      "       'locationptcarid', 'detectiontimestamp', 'ptrefid',\n",
      "       'delayjustifiedbyreason', 'secondaryReasonID',\n",
      "       'causingTraindepartureDate', 'causingtrainnumber',\n",
      "       'causingTraincirculationType', 'signalCausingTrainptrefID',\n",
      "       'locationCausingTrainptcarID', 'category', 'rubric'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageTimestamp</th>\n",
       "      <th>tableType</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>departuredate</th>\n",
       "      <th>trainnumber</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>automatic</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>detectiontimestamp</th>\n",
       "      <th>ptrefid</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>secondaryReasonID</th>\n",
       "      <th>causingTraindepartureDate</th>\n",
       "      <th>causingtrainnumber</th>\n",
       "      <th>causingTraincirculationType</th>\n",
       "      <th>signalCausingTrainptrefID</th>\n",
       "      <th>locationCausingTrainptcarID</th>\n",
       "      <th>category</th>\n",
       "      <th>rubric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d4a62373-fc4c-4c06-992b-e5d25e502580</td>\n",
       "      <td>2023-04-19T23:52:32.043+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>e0c0d24a-c4af-4b96-8a6d-d7030d48904c</td>\n",
       "      <td>2023/4/19</td>\n",
       "      <td>-16346</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>1720</td>\n",
       "      <td>2023-04-19T23:23:16+02:00</td>\n",
       "      <td>102091.0</td>\n",
       "      <td>919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9f5a20a0-926f-4647-bfc9-0d73872be50f</td>\n",
       "      <td>2023-04-04T17:40:49.819+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>1fa72c40-e718-49bd-ae39-bcc1de4ef70a</td>\n",
       "      <td>2023/4/4</td>\n",
       "      <td>-63975</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1271</td>\n",
       "      <td>2023-04-04T17:03:49+02:00</td>\n",
       "      <td>517092.0</td>\n",
       "      <td>4724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1439.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              messageID               messageTimestamp  \\\n",
       "0  d4a62373-fc4c-4c06-992b-e5d25e502580  2023-04-19T23:52:32.043+02:00   \n",
       "1  9f5a20a0-926f-4647-bfc9-0d73872be50f  2023-04-04T17:40:49.819+02:00   \n",
       "\n",
       "              tableType                       justificationID departuredate  \\\n",
       "0  primaryJustification  e0c0d24a-c4af-4b96-8a6d-d7030d48904c     2023/4/19   \n",
       "1  primaryJustification  1fa72c40-e718-49bd-ae39-bcc1de4ef70a      2023/4/4   \n",
       "\n",
       "   trainnumber circulationType  automatic  locationptcarid  \\\n",
       "0       -16346           EMPTY      False             1720   \n",
       "1       -63975      COMMERCIAL      False             1271   \n",
       "\n",
       "          detectiontimestamp   ptrefid  delayjustifiedbyreason  \\\n",
       "0  2023-04-19T23:23:16+02:00  102091.0                     919   \n",
       "1  2023-04-04T17:03:49+02:00  517092.0                    4724   \n",
       "\n",
       "   secondaryReasonID causingTraindepartureDate  causingtrainnumber  \\\n",
       "0                NaN                       NaN                 NaN   \n",
       "1                NaN                       NaN                 NaN   \n",
       "\n",
       "  causingTraincirculationType  signalCausingTrainptrefID  \\\n",
       "0                         NaN                        NaN   \n",
       "1                         NaN                        NaN   \n",
       "\n",
       "   locationCausingTrainptcarID  category  rubric  \n",
       "0                          NaN     175.0  1439.0  \n",
       "1                          NaN     175.0  1439.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# justif_df_org = pd.read_csv(JUSTIF_DATA_FILE_PATH,low_memory=False, sep=';')\n",
    "justif_df_org = pd.read_csv(JUSTIF_DATA_FILE_PATH,low_memory=False)\n",
    "\n",
    "# Print the list of columns in the JUSTIF data\n",
    "print(justif_df_org.columns)\n",
    "\n",
    "# Print the first two rows in the JUSTIF data\n",
    "justif_df_org.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1bf13be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:12:57.377262Z",
     "start_time": "2024-11-29T11:12:53.769369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageTimestamp</th>\n",
       "      <th>tableType</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>departuredate</th>\n",
       "      <th>trainnumber</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>automatic</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>detectiontimestamp</th>\n",
       "      <th>ptrefid</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>secondaryReasonID</th>\n",
       "      <th>causingTraindepartureDate</th>\n",
       "      <th>causingtrainnumber</th>\n",
       "      <th>causingTraincirculationType</th>\n",
       "      <th>signalCausingTrainptrefID</th>\n",
       "      <th>locationCausingTrainptcarID</th>\n",
       "      <th>category</th>\n",
       "      <th>rubric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>455e2081-7334-48c1-8348-c904b449ea66</td>\n",
       "      <td>2023-04-01 00:14:55.672000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>d77bc687-6b2a-449b-8b53-14986bc3afd0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1195</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "      <td>401061.0</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293273</th>\n",
       "      <td>8bf42954-bc4d-497f-bbc6-a2d478a80494</td>\n",
       "      <td>2023-04-01 00:37:42.250000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>ab92dc6d-5728-43f3-9f0d-1b6585d39577</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>208</td>\n",
       "      <td>2023-04-01 00:15:35+02:00</td>\n",
       "      <td>402951.0</td>\n",
       "      <td>133</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-86432.0</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   messageID                 messageTimestamp  \\\n",
       "66268   455e2081-7334-48c1-8348-c904b449ea66 2023-04-01 00:14:55.672000+02:00   \n",
       "293273  8bf42954-bc4d-497f-bbc6-a2d478a80494 2023-04-01 00:37:42.250000+02:00   \n",
       "\n",
       "                     tableType                       justificationID  \\\n",
       "66268     primaryJustification  d77bc687-6b2a-449b-8b53-14986bc3afd0   \n",
       "293273  secondaryJustification  ab92dc6d-5728-43f3-9f0d-1b6585d39577   \n",
       "\n",
       "       departuredate  trainnumber circulationType  automatic  locationptcarid  \\\n",
       "66268       2023/4/1       -85230      COMMERCIAL      False             1195   \n",
       "293273      2023/4/1       -85230      COMMERCIAL      False              208   \n",
       "\n",
       "              detectiontimestamp   ptrefid  delayjustifiedbyreason  \\\n",
       "66268  2023-04-01 00:03:07+02:00  401061.0                     189   \n",
       "293273 2023-04-01 00:15:35+02:00  402951.0                     133   \n",
       "\n",
       "        secondaryReasonID causingTraindepartureDate  causingtrainnumber  \\\n",
       "66268                 NaN                       NaN                 NaN   \n",
       "293273             1137.0                  2023/4/1            -86432.0   \n",
       "\n",
       "       causingTraincirculationType  signalCausingTrainptrefID  \\\n",
       "66268                          NaN                        NaN   \n",
       "293273                  COMMERCIAL                        NaN   \n",
       "\n",
       "        locationCausingTrainptcarID  category  rubric  \n",
       "66268                           NaN     160.0  1320.0  \n",
       "293273                          NaN       NaN     NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Function to do inital prepocessing of justif data\n",
    "# Convert 'detectiontimestamp',messageTimestamp to datetime formatting \n",
    "# Convert 'trainnumber',locationptcarid to int\n",
    "# Sorting the converted dataframe in ascending order of detectiontimestamp\n",
    "################################################################################\n",
    "\n",
    "def preprocess_justif(temp_df):\n",
    "    \n",
    "    '''\n",
    "    Function to preprocess and clean the justif data\n",
    "    '''\n",
    "    # Convert 'detectiontimestamp',messageTimestamp to datetime format\n",
    "    temp_df['detectiontimestamp'] = pd.to_datetime(temp_df['detectiontimestamp'])\n",
    "    temp_df['messageTimestamp'] = pd.to_datetime(temp_df['messageTimestamp'])\n",
    "    \n",
    "    # Convert 'tr_bk_number' and 'point_ptcarid' to integer format\n",
    "    temp_df['trainnumber'] = temp_df['trainnumber'].astype(int)\n",
    "    temp_df['locationptcarid'] = temp_df['locationptcarid'].astype(int)\n",
    "    \n",
    "    temp_df = temp_df.sort_values(by='detectiontimestamp')\n",
    "    return temp_df\n",
    "\n",
    "justif_df_org= preprocess_justif(justif_df_org)\n",
    "justif_df_org.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d3c98c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:12:58.351558Z",
     "start_time": "2024-11-29T11:12:58.273288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-04-01 00:00:00+0200', tz='UTC+02:00')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# Function to Extract strting time of our data from the column detectiontimestamp in justif data\n",
    "#  The function Sets the global variable 'justif_start_timestamp' to the starting timestamp extracted from the DataFrame\n",
    "\n",
    "# 'detectiontimestamp' is the times when the delay has happened \n",
    "################################################################################\n",
    "\n",
    "def extract_start_timestamp_from_justif(df,time_column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts the starting timestamp from the specified column in the DataFrame.\n",
    "    The starting timestamp is set as a global variable 'start_timestamp' for\n",
    "    accessibility from anywhere after calling this function..\n",
    "\n",
    "    Args:\n",
    "    - df: pandas DataFrame containing the timestamps.\n",
    "    - time_column: str, the name of the column containing timestamps in ISO 8601 format.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Timestamp: The starting timestamp extracted from the DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the time_column to datetime if not done earlier\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[time_column]):\n",
    "        df[time_column] = pd.to_datetime(df[time_column])\n",
    "\n",
    "    # Sort the DataFrame by the 'timestamp' column\n",
    "    df_sorted = df.sort_values(by=time_column)\n",
    "\n",
    "    # Get the date part of the first timestamp\n",
    "    first_day = df_sorted[time_column].iloc[0].normalize()\n",
    "\n",
    "    #Set the global variable 'start_timestamp' to the starting timestamp extracted from the DataFrame\n",
    "    global justif_start_timestamp\n",
    "    justif_start_timestamp = first_day + pd.Timedelta(hours=0)\n",
    "\n",
    "    return justif_start_timestamp\n",
    "\n",
    "\n",
    "extract_start_timestamp_from_justif(justif_df_org,'detectiontimestamp')\n",
    "justif_start_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd9f8c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T11:13:52.541417Z",
     "start_time": "2024-11-29T11:13:52.505802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageTimestamp</th>\n",
       "      <th>tableType</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>departuredate</th>\n",
       "      <th>trainnumber</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>automatic</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>detectiontimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>secondaryReasonID</th>\n",
       "      <th>causingTraindepartureDate</th>\n",
       "      <th>causingtrainnumber</th>\n",
       "      <th>causingTraincirculationType</th>\n",
       "      <th>signalCausingTrainptrefID</th>\n",
       "      <th>locationCausingTrainptcarID</th>\n",
       "      <th>category</th>\n",
       "      <th>rubric</th>\n",
       "      <th>t_5min_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>455e2081-7334-48c1-8348-c904b449ea66</td>\n",
       "      <td>2023-04-01 00:14:55.672000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>d77bc687-6b2a-449b-8b53-14986bc3afd0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1195</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293273</th>\n",
       "      <td>8bf42954-bc4d-497f-bbc6-a2d478a80494</td>\n",
       "      <td>2023-04-01 00:37:42.250000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>ab92dc6d-5728-43f3-9f0d-1b6585d39577</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>208</td>\n",
       "      <td>2023-04-01 00:15:35+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-86432.0</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46482</th>\n",
       "      <td>03518c8b-9b06-46ba-91cc-33c9c8347216</td>\n",
       "      <td>2023-04-01 00:40:53.161000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-20942</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>1271</td>\n",
       "      <td>2023-04-01 00:21:30+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263343</th>\n",
       "      <td>847ef063-1f6d-4d98-8c79-0537afa03314</td>\n",
       "      <td>2023-04-01 00:31:55.193000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>8c6a3d61-10e7-4f84-8409-3c6023c010ce</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-50429</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>272</td>\n",
       "      <td>2023-04-01 00:26:14+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-50429.0</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>f0008cf8-9ff2-4429-a17d-34fbb5dabcce</td>\n",
       "      <td>2023-04-01 00:34:50.514000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>030a0e2d-3e84-43c1-b720-6e95b575da5c</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-37031</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>197</td>\n",
       "      <td>2023-04-01 00:28:38+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   messageID                 messageTimestamp  \\\n",
       "66268   455e2081-7334-48c1-8348-c904b449ea66 2023-04-01 00:14:55.672000+02:00   \n",
       "293273  8bf42954-bc4d-497f-bbc6-a2d478a80494 2023-04-01 00:37:42.250000+02:00   \n",
       "46482   03518c8b-9b06-46ba-91cc-33c9c8347216 2023-04-01 00:40:53.161000+02:00   \n",
       "263343  847ef063-1f6d-4d98-8c79-0537afa03314 2023-04-01 00:31:55.193000+02:00   \n",
       "40953   f0008cf8-9ff2-4429-a17d-34fbb5dabcce 2023-04-01 00:34:50.514000+02:00   \n",
       "\n",
       "                     tableType                       justificationID  \\\n",
       "66268     primaryJustification  d77bc687-6b2a-449b-8b53-14986bc3afd0   \n",
       "293273  secondaryJustification  ab92dc6d-5728-43f3-9f0d-1b6585d39577   \n",
       "46482     primaryJustification  503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2   \n",
       "263343  secondaryJustification  8c6a3d61-10e7-4f84-8409-3c6023c010ce   \n",
       "40953     primaryJustification  030a0e2d-3e84-43c1-b720-6e95b575da5c   \n",
       "\n",
       "       departuredate  trainnumber circulationType  automatic  locationptcarid  \\\n",
       "66268       2023/4/1       -85230      COMMERCIAL      False             1195   \n",
       "293273      2023/4/1       -85230      COMMERCIAL      False              208   \n",
       "46482       2023/4/1       -20942           EMPTY      False             1271   \n",
       "263343      2023/4/1       -50429           EMPTY      False              272   \n",
       "40953       2023/4/1       -37031      COMMERCIAL      False              197   \n",
       "\n",
       "              detectiontimestamp  ...  delayjustifiedbyreason  \\\n",
       "66268  2023-04-01 00:03:07+02:00  ...                     189   \n",
       "293273 2023-04-01 00:15:35+02:00  ...                     133   \n",
       "46482  2023-04-01 00:21:30+02:00  ...                     388   \n",
       "263343 2023-04-01 00:26:14+02:00  ...                     112   \n",
       "40953  2023-04-01 00:28:38+02:00  ...                     173   \n",
       "\n",
       "        secondaryReasonID  causingTraindepartureDate causingtrainnumber  \\\n",
       "66268                 NaN                        NaN                NaN   \n",
       "293273             1137.0                   2023/4/1           -86432.0   \n",
       "46482                 NaN                        NaN                NaN   \n",
       "263343             1135.0                   2023/4/1           -50429.0   \n",
       "40953                 NaN                        NaN                NaN   \n",
       "\n",
       "        causingTraincirculationType signalCausingTrainptrefID  \\\n",
       "66268                           NaN                       NaN   \n",
       "293273                   COMMERCIAL                       NaN   \n",
       "46482                           NaN                       NaN   \n",
       "263343                   COMMERCIAL                       NaN   \n",
       "40953                           NaN                       NaN   \n",
       "\n",
       "        locationCausingTrainptcarID  category  rubric  t_5min_detection  \n",
       "66268                           NaN     160.0  1320.0                 0  \n",
       "293273                          NaN       NaN     NaN                 3  \n",
       "46482                           NaN     175.0  1439.0                 4  \n",
       "263343                          NaN       NaN     NaN                 5  \n",
       "40953                           NaN     160.0  1320.0                 5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function takes timestamp column as input  and returns 't' (in blocks of 5 minutes) \n",
    "# by removing seconds and timezone. For ex. we can pass the columns 'messageTimestamp' \n",
    "# and 'detectiontimestamp' in the justif data, as input to the function.\n",
    "#\n",
    "# Note: \n",
    "#\n",
    "# 'messageTimestamp' is the times in which the message has been received\n",
    "# 'detectiontimestamp' is the times when the delay has happened\n",
    "################################################################################\n",
    "\n",
    "# justif_df_org['t_5min_message'] = Append_t(justif_df_org['messageTimestamp'])\n",
    "# justif_df_org['t_5min_detection'] = Append_t(justif_df_org['detectiontimestamp'])\n",
    "\n",
    "diff_in_minutes_justif= ((justif_df_org['detectiontimestamp'] - justif_start_timestamp).dt.total_seconds() / 60).round(2)\n",
    "\n",
    "# Divide the difference by 5 to get the running number in minutes\n",
    "justif_df_org['t_5min_detection'] = (diff_in_minutes_justif// MINUTE).astype(T_DATATYPE) \n",
    "\n",
    "justif_df_org.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270e199",
   "metadata": {},
   "source": [
    "## Prepare timestamp column for delay in the JUSTIF data set\n",
    "\n",
    "We define $r_0(t)$, $r_1(t)$, and $r_2(t)$ as the respective time of the day (in minutes), the day of the week (from one to seven) and month of the year (from one to seven), corresponding to data time $t$. We introduce the notation $\\boldsymbol{r}(t) = (r_0(t), r_1(t), r_2(t))$.\n",
    "\n",
    "The following code is to create $r_0(t)$ in blocks of 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "406f97d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:47:02.083135Z",
     "start_time": "2024-08-18T10:47:01.952045Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to create r0, r1 and r2 by removing seconds and timezone from the  \n",
    "# columns 'messageTimestamp' and 'detectiontimestamp' in the justif data\n",
    "#\n",
    "# Note: \n",
    "# 'messageTimestamp' is the times in which the message has been received\n",
    "# 'detectiontimestamp' is the times when the delay has happened\n",
    "################################################################################\n",
    "\n",
    "r0, r1, r2 = Append_r0_r1_r2(justif_df_org, 'messageTimestamp')\n",
    "justif_df_org['r0_5min_message'] = r0\n",
    "justif_df_org['r1_5min_message'] = r1\n",
    "justif_df_org['r2_5min_message'] = r2\n",
    "\n",
    "r0,r1,r2 = Append_r0_r1_r2(justif_df_org,'detectiontimestamp')\n",
    "justif_df_org['r0_5min_detection'] = r0\n",
    "justif_df_org['r1_5min_detection'] = r1\n",
    "justif_df_org['r2_5min_detection'] = r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aecc6ed5-384e-4624-b484-003c40629366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageTimestamp</th>\n",
       "      <th>tableType</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>departuredate</th>\n",
       "      <th>trainnumber</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>automatic</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>detectiontimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>locationCausingTrainptcarID</th>\n",
       "      <th>category</th>\n",
       "      <th>rubric</th>\n",
       "      <th>t_5min_detection</th>\n",
       "      <th>r0_5min_message</th>\n",
       "      <th>r1_5min_message</th>\n",
       "      <th>r2_5min_message</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>455e2081-7334-48c1-8348-c904b449ea66</td>\n",
       "      <td>2023-04-01 00:14:55.672000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>d77bc687-6b2a-449b-8b53-14986bc3afd0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1195</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293273</th>\n",
       "      <td>8bf42954-bc4d-497f-bbc6-a2d478a80494</td>\n",
       "      <td>2023-04-01 00:37:42.250000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>ab92dc6d-5728-43f3-9f0d-1b6585d39577</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>208</td>\n",
       "      <td>2023-04-01 00:15:35+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46482</th>\n",
       "      <td>03518c8b-9b06-46ba-91cc-33c9c8347216</td>\n",
       "      <td>2023-04-01 00:40:53.161000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-20942</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>1271</td>\n",
       "      <td>2023-04-01 00:21:30+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263343</th>\n",
       "      <td>847ef063-1f6d-4d98-8c79-0537afa03314</td>\n",
       "      <td>2023-04-01 00:31:55.193000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>8c6a3d61-10e7-4f84-8409-3c6023c010ce</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-50429</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>272</td>\n",
       "      <td>2023-04-01 00:26:14+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>f0008cf8-9ff2-4429-a17d-34fbb5dabcce</td>\n",
       "      <td>2023-04-01 00:34:50.514000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>030a0e2d-3e84-43c1-b720-6e95b575da5c</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-37031</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>197</td>\n",
       "      <td>2023-04-01 00:28:38+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55063</th>\n",
       "      <td>72615eaa-bcd0-4670-baa6-611790933d9c</td>\n",
       "      <td>2023-06-30 07:28:21.380000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>22cff58d-93c3-4994-bd98-63a68f94340c</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>119</td>\n",
       "      <td>2023-06-30 06:45:04+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>26001</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50805</th>\n",
       "      <td>8ffe94a6-a77b-4042-99f6-a49df1cb1b3a</td>\n",
       "      <td>2023-06-30 07:04:08.910000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>9b48a5f2-2fe3-4bac-9303-767a1d2448b7</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-33890</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>456</td>\n",
       "      <td>2023-06-30 06:59:29+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>26003</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55047</th>\n",
       "      <td>8e17fa8c-1fe5-40ea-8481-38426ea545d0</td>\n",
       "      <td>2023-06-30 08:45:56.740000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>fbef1bdf-1449-46e1-82e9-e0db6069a938</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>638</td>\n",
       "      <td>2023-06-30 08:33:21+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>26022</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>444deb94-38de-4d9e-9b10-204f556bea89</td>\n",
       "      <td>2023-06-30 09:48:43.854000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>54e51c10-dab2-45f9-aaf1-474ba4043123</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1246</td>\n",
       "      <td>2023-06-30 08:56:52+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>26027</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27512</th>\n",
       "      <td>89e22309-0f8c-45d7-8ea5-310b2926c144</td>\n",
       "      <td>2023-06-30 10:25:18.028000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>ad138d05-38a3-43f0-9b89-335d80e5eff4</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>801</td>\n",
       "      <td>2023-06-30 09:58:51+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>26039</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295402 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   messageID                 messageTimestamp  \\\n",
       "66268   455e2081-7334-48c1-8348-c904b449ea66 2023-04-01 00:14:55.672000+02:00   \n",
       "293273  8bf42954-bc4d-497f-bbc6-a2d478a80494 2023-04-01 00:37:42.250000+02:00   \n",
       "46482   03518c8b-9b06-46ba-91cc-33c9c8347216 2023-04-01 00:40:53.161000+02:00   \n",
       "263343  847ef063-1f6d-4d98-8c79-0537afa03314 2023-04-01 00:31:55.193000+02:00   \n",
       "40953   f0008cf8-9ff2-4429-a17d-34fbb5dabcce 2023-04-01 00:34:50.514000+02:00   \n",
       "...                                      ...                              ...   \n",
       "55063   72615eaa-bcd0-4670-baa6-611790933d9c 2023-06-30 07:28:21.380000+02:00   \n",
       "50805   8ffe94a6-a77b-4042-99f6-a49df1cb1b3a 2023-06-30 07:04:08.910000+02:00   \n",
       "55047   8e17fa8c-1fe5-40ea-8481-38426ea545d0 2023-06-30 08:45:56.740000+02:00   \n",
       "13769   444deb94-38de-4d9e-9b10-204f556bea89 2023-06-30 09:48:43.854000+02:00   \n",
       "27512   89e22309-0f8c-45d7-8ea5-310b2926c144 2023-06-30 10:25:18.028000+02:00   \n",
       "\n",
       "                     tableType                       justificationID  \\\n",
       "66268     primaryJustification  d77bc687-6b2a-449b-8b53-14986bc3afd0   \n",
       "293273  secondaryJustification  ab92dc6d-5728-43f3-9f0d-1b6585d39577   \n",
       "46482     primaryJustification  503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2   \n",
       "263343  secondaryJustification  8c6a3d61-10e7-4f84-8409-3c6023c010ce   \n",
       "40953     primaryJustification  030a0e2d-3e84-43c1-b720-6e95b575da5c   \n",
       "...                        ...                                   ...   \n",
       "55063     primaryJustification  22cff58d-93c3-4994-bd98-63a68f94340c   \n",
       "50805     primaryJustification  9b48a5f2-2fe3-4bac-9303-767a1d2448b7   \n",
       "55047     primaryJustification  fbef1bdf-1449-46e1-82e9-e0db6069a938   \n",
       "13769     primaryJustification  54e51c10-dab2-45f9-aaf1-474ba4043123   \n",
       "27512     primaryJustification  ad138d05-38a3-43f0-9b89-335d80e5eff4   \n",
       "\n",
       "       departuredate  trainnumber circulationType  automatic  locationptcarid  \\\n",
       "66268       2023/4/1       -85230      COMMERCIAL      False             1195   \n",
       "293273      2023/4/1       -85230      COMMERCIAL      False              208   \n",
       "46482       2023/4/1       -20942           EMPTY      False             1271   \n",
       "263343      2023/4/1       -50429           EMPTY      False              272   \n",
       "40953       2023/4/1       -37031      COMMERCIAL      False              197   \n",
       "...              ...          ...             ...        ...              ...   \n",
       "55063      2023/6/29       -46584      COMMERCIAL      False              119   \n",
       "50805      2023/6/29       -33890      COMMERCIAL      False              456   \n",
       "55047      2023/6/29       -46584      COMMERCIAL      False              638   \n",
       "13769      2023/6/29       -46584      COMMERCIAL      False             1246   \n",
       "27512      2023/6/29       -46584      COMMERCIAL      False              801   \n",
       "\n",
       "              detectiontimestamp  ...  locationCausingTrainptcarID  category  \\\n",
       "66268  2023-04-01 00:03:07+02:00  ...                          NaN     160.0   \n",
       "293273 2023-04-01 00:15:35+02:00  ...                          NaN       NaN   \n",
       "46482  2023-04-01 00:21:30+02:00  ...                          NaN     175.0   \n",
       "263343 2023-04-01 00:26:14+02:00  ...                          NaN       NaN   \n",
       "40953  2023-04-01 00:28:38+02:00  ...                          NaN     160.0   \n",
       "...                          ...  ...                          ...       ...   \n",
       "55063  2023-06-30 06:45:04+02:00  ...                          NaN     172.0   \n",
       "50805  2023-06-30 06:59:29+02:00  ...                          NaN     175.0   \n",
       "55047  2023-06-30 08:33:21+02:00  ...                          NaN     175.0   \n",
       "13769  2023-06-30 08:56:52+02:00  ...                          NaN     161.0   \n",
       "27512  2023-06-30 09:58:51+02:00  ...                          NaN     172.0   \n",
       "\n",
       "        rubric t_5min_detection  r0_5min_message r1_5min_message  \\\n",
       "66268   1320.0                0                2               6   \n",
       "293273     NaN                3                7               6   \n",
       "46482   1439.0                4                8               6   \n",
       "263343     NaN                5                6               6   \n",
       "40953   1320.0                5                6               6   \n",
       "...        ...              ...              ...             ...   \n",
       "55063   1416.0            26001               89               5   \n",
       "50805   1439.0            26003               84               5   \n",
       "55047   1437.0            26022              105               5   \n",
       "13769   1338.0            26027              117               5   \n",
       "27512   1416.0            26039              125               5   \n",
       "\n",
       "        r2_5min_message  r0_5min_detection  r1_5min_detection  \\\n",
       "66268                 4                  0                  6   \n",
       "293273                4                  3                  6   \n",
       "46482                 4                  4                  6   \n",
       "263343                4                  5                  6   \n",
       "40953                 4                  5                  6   \n",
       "...                 ...                ...                ...   \n",
       "55063                 6                 81                  5   \n",
       "50805                 6                 83                  5   \n",
       "55047                 6                102                  5   \n",
       "13769                 6                107                  5   \n",
       "27512                 6                119                  5   \n",
       "\n",
       "        r2_5min_detection  \n",
       "66268                   4  \n",
       "293273                  4  \n",
       "46482                   4  \n",
       "263343                  4  \n",
       "40953                   4  \n",
       "...                   ...  \n",
       "55063                   6  \n",
       "50805                   6  \n",
       "55047                   6  \n",
       "13769                   6  \n",
       "27512                   6  \n",
       "\n",
       "[295402 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justif_df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70e6d0f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:47:14.536694Z",
     "start_time": "2024-08-18T10:47:03.563846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messageID</th>\n",
       "      <th>messageTimestamp</th>\n",
       "      <th>tableType</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>departuredate</th>\n",
       "      <th>trainnumber</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>automatic</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>detectiontimestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>rubric</th>\n",
       "      <th>t_5min_detection</th>\n",
       "      <th>r0_5min_message</th>\n",
       "      <th>r1_5min_message</th>\n",
       "      <th>r2_5min_message</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "      <th>r0_hhmm_5min_message</th>\n",
       "      <th>r0_hhmm_5min_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>455e2081-7334-48c1-8348-c904b449ea66</td>\n",
       "      <td>2023-04-01 00:14:55.672000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>d77bc687-6b2a-449b-8b53-14986bc3afd0</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1195</td>\n",
       "      <td>2023-04-01 00:03:07+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:15</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293273</th>\n",
       "      <td>8bf42954-bc4d-497f-bbc6-a2d478a80494</td>\n",
       "      <td>2023-04-01 00:37:42.250000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>ab92dc6d-5728-43f3-9f0d-1b6585d39577</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-85230</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>208</td>\n",
       "      <td>2023-04-01 00:15:35+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:40</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46482</th>\n",
       "      <td>03518c8b-9b06-46ba-91cc-33c9c8347216</td>\n",
       "      <td>2023-04-01 00:40:53.161000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-20942</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>1271</td>\n",
       "      <td>2023-04-01 00:21:30+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:40</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263343</th>\n",
       "      <td>847ef063-1f6d-4d98-8c79-0537afa03314</td>\n",
       "      <td>2023-04-01 00:31:55.193000+02:00</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>8c6a3d61-10e7-4f84-8409-3c6023c010ce</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-50429</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>False</td>\n",
       "      <td>272</td>\n",
       "      <td>2023-04-01 00:26:14+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:30</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>f0008cf8-9ff2-4429-a17d-34fbb5dabcce</td>\n",
       "      <td>2023-04-01 00:34:50.514000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>030a0e2d-3e84-43c1-b720-6e95b575da5c</td>\n",
       "      <td>2023/4/1</td>\n",
       "      <td>-37031</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>197</td>\n",
       "      <td>2023-04-01 00:28:38+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:35</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55063</th>\n",
       "      <td>72615eaa-bcd0-4670-baa6-611790933d9c</td>\n",
       "      <td>2023-06-30 07:28:21.380000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>22cff58d-93c3-4994-bd98-63a68f94340c</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>119</td>\n",
       "      <td>2023-06-30 06:45:04+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>26001</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>07:30</td>\n",
       "      <td>06:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50805</th>\n",
       "      <td>8ffe94a6-a77b-4042-99f6-a49df1cb1b3a</td>\n",
       "      <td>2023-06-30 07:04:08.910000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>9b48a5f2-2fe3-4bac-9303-767a1d2448b7</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-33890</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>456</td>\n",
       "      <td>2023-06-30 06:59:29+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>26003</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>07:05</td>\n",
       "      <td>07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55047</th>\n",
       "      <td>8e17fa8c-1fe5-40ea-8481-38426ea545d0</td>\n",
       "      <td>2023-06-30 08:45:56.740000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>fbef1bdf-1449-46e1-82e9-e0db6069a938</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>638</td>\n",
       "      <td>2023-06-30 08:33:21+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>26022</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>08:45</td>\n",
       "      <td>08:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>444deb94-38de-4d9e-9b10-204f556bea89</td>\n",
       "      <td>2023-06-30 09:48:43.854000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>54e51c10-dab2-45f9-aaf1-474ba4043123</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1246</td>\n",
       "      <td>2023-06-30 08:56:52+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>26027</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>09:50</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27512</th>\n",
       "      <td>89e22309-0f8c-45d7-8ea5-310b2926c144</td>\n",
       "      <td>2023-06-30 10:25:18.028000+02:00</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>ad138d05-38a3-43f0-9b89-335d80e5eff4</td>\n",
       "      <td>2023/6/29</td>\n",
       "      <td>-46584</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>False</td>\n",
       "      <td>801</td>\n",
       "      <td>2023-06-30 09:58:51+02:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>26039</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10:25</td>\n",
       "      <td>10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295402 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   messageID                 messageTimestamp  \\\n",
       "66268   455e2081-7334-48c1-8348-c904b449ea66 2023-04-01 00:14:55.672000+02:00   \n",
       "293273  8bf42954-bc4d-497f-bbc6-a2d478a80494 2023-04-01 00:37:42.250000+02:00   \n",
       "46482   03518c8b-9b06-46ba-91cc-33c9c8347216 2023-04-01 00:40:53.161000+02:00   \n",
       "263343  847ef063-1f6d-4d98-8c79-0537afa03314 2023-04-01 00:31:55.193000+02:00   \n",
       "40953   f0008cf8-9ff2-4429-a17d-34fbb5dabcce 2023-04-01 00:34:50.514000+02:00   \n",
       "...                                      ...                              ...   \n",
       "55063   72615eaa-bcd0-4670-baa6-611790933d9c 2023-06-30 07:28:21.380000+02:00   \n",
       "50805   8ffe94a6-a77b-4042-99f6-a49df1cb1b3a 2023-06-30 07:04:08.910000+02:00   \n",
       "55047   8e17fa8c-1fe5-40ea-8481-38426ea545d0 2023-06-30 08:45:56.740000+02:00   \n",
       "13769   444deb94-38de-4d9e-9b10-204f556bea89 2023-06-30 09:48:43.854000+02:00   \n",
       "27512   89e22309-0f8c-45d7-8ea5-310b2926c144 2023-06-30 10:25:18.028000+02:00   \n",
       "\n",
       "                     tableType                       justificationID  \\\n",
       "66268     primaryJustification  d77bc687-6b2a-449b-8b53-14986bc3afd0   \n",
       "293273  secondaryJustification  ab92dc6d-5728-43f3-9f0d-1b6585d39577   \n",
       "46482     primaryJustification  503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2   \n",
       "263343  secondaryJustification  8c6a3d61-10e7-4f84-8409-3c6023c010ce   \n",
       "40953     primaryJustification  030a0e2d-3e84-43c1-b720-6e95b575da5c   \n",
       "...                        ...                                   ...   \n",
       "55063     primaryJustification  22cff58d-93c3-4994-bd98-63a68f94340c   \n",
       "50805     primaryJustification  9b48a5f2-2fe3-4bac-9303-767a1d2448b7   \n",
       "55047     primaryJustification  fbef1bdf-1449-46e1-82e9-e0db6069a938   \n",
       "13769     primaryJustification  54e51c10-dab2-45f9-aaf1-474ba4043123   \n",
       "27512     primaryJustification  ad138d05-38a3-43f0-9b89-335d80e5eff4   \n",
       "\n",
       "       departuredate  trainnumber circulationType  automatic  locationptcarid  \\\n",
       "66268       2023/4/1       -85230      COMMERCIAL      False             1195   \n",
       "293273      2023/4/1       -85230      COMMERCIAL      False              208   \n",
       "46482       2023/4/1       -20942           EMPTY      False             1271   \n",
       "263343      2023/4/1       -50429           EMPTY      False              272   \n",
       "40953       2023/4/1       -37031      COMMERCIAL      False              197   \n",
       "...              ...          ...             ...        ...              ...   \n",
       "55063      2023/6/29       -46584      COMMERCIAL      False              119   \n",
       "50805      2023/6/29       -33890      COMMERCIAL      False              456   \n",
       "55047      2023/6/29       -46584      COMMERCIAL      False              638   \n",
       "13769      2023/6/29       -46584      COMMERCIAL      False             1246   \n",
       "27512      2023/6/29       -46584      COMMERCIAL      False              801   \n",
       "\n",
       "              detectiontimestamp  ...  rubric  t_5min_detection  \\\n",
       "66268  2023-04-01 00:03:07+02:00  ...  1320.0                 0   \n",
       "293273 2023-04-01 00:15:35+02:00  ...     NaN                 3   \n",
       "46482  2023-04-01 00:21:30+02:00  ...  1439.0                 4   \n",
       "263343 2023-04-01 00:26:14+02:00  ...     NaN                 5   \n",
       "40953  2023-04-01 00:28:38+02:00  ...  1320.0                 5   \n",
       "...                          ...  ...     ...               ...   \n",
       "55063  2023-06-30 06:45:04+02:00  ...  1416.0             26001   \n",
       "50805  2023-06-30 06:59:29+02:00  ...  1439.0             26003   \n",
       "55047  2023-06-30 08:33:21+02:00  ...  1437.0             26022   \n",
       "13769  2023-06-30 08:56:52+02:00  ...  1338.0             26027   \n",
       "27512  2023-06-30 09:58:51+02:00  ...  1416.0             26039   \n",
       "\n",
       "        r0_5min_message r1_5min_message  r2_5min_message r0_5min_detection  \\\n",
       "66268                 2               6                4                 0   \n",
       "293273                7               6                4                 3   \n",
       "46482                 8               6                4                 4   \n",
       "263343                6               6                4                 5   \n",
       "40953                 6               6                4                 5   \n",
       "...                 ...             ...              ...               ...   \n",
       "55063                89               5                6                81   \n",
       "50805                84               5                6                83   \n",
       "55047               105               5                6               102   \n",
       "13769               117               5                6               107   \n",
       "27512               125               5                6               119   \n",
       "\n",
       "        r1_5min_detection  r2_5min_detection  r0_hhmm_5min_message  \\\n",
       "66268                   6                  4                 00:15   \n",
       "293273                  6                  4                 00:40   \n",
       "46482                   6                  4                 00:40   \n",
       "263343                  6                  4                 00:30   \n",
       "40953                   6                  4                 00:35   \n",
       "...                   ...                ...                   ...   \n",
       "55063                   5                  6                 07:30   \n",
       "50805                   5                  6                 07:05   \n",
       "55047                   5                  6                 08:45   \n",
       "13769                   5                  6                 09:50   \n",
       "27512                   5                  6                 10:25   \n",
       "\n",
       "        r0_hhmm_5min_detection  \n",
       "66268                    00:05  \n",
       "293273                   00:15  \n",
       "46482                    00:20  \n",
       "263343                   00:25  \n",
       "40953                    00:30  \n",
       "...                        ...  \n",
       "55063                    06:45  \n",
       "50805                    07:00  \n",
       "55047                    08:35  \n",
       "13769                    08:55  \n",
       "27512                    10:00  \n",
       "\n",
       "[295402 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function adds a new column to df by converting the timestamps (column time_col) \n",
    "# into the format hh:mm (column new_time_col)\n",
    "################################################################################\n",
    "\n",
    "def Append_r0_hhmm(df, time_col, new_time_col):\n",
    "    \n",
    "    \"\"\"   \n",
    "    Input Args:\n",
    "    - df: pandas DataFrame containing the timestamps.\n",
    "    - time_column: the name of the column containing timestamps in ISO 8601 format.\n",
    "    - new_col: the name of the column that this function is going to append to df\n",
    "\n",
    "    Output Returns:\n",
    "    - A pandas DataFrame contructed from df, with an additional column 'simplified_t' containing hh:mm.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the time_column to datetime if not done earlier\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[time_col]):\n",
    "        df[time_column] = pd.to_datetime(df[time_col])\n",
    "    \n",
    "    # Function to adjust individual timestamps\n",
    "    def adjust_timestamp(ts):\n",
    "        if ts.hour == 24 and ts.minute == 0:\n",
    "            # Extract date and increment by one day\n",
    "            new_date = ts + pd.Timedelta(days=1)\n",
    "            # Replace '24:00' with '00:00' of the next day\n",
    "            new_ts = new_date.replace(hour=0, minute=0, second=0)\n",
    "            return new_ts\n",
    "        return ts\n",
    "\n",
    "    # Apply the adjustment function\n",
    "    df[new_time_col] = df[time_col].apply(adjust_timestamp)\n",
    "\n",
    "    # Round to the nearest 5 minutes\n",
    "    df[new_time_col] = df[new_time_col].dt.round(TIME_FREQUENCY)\n",
    "\n",
    "    # Format to keep only date, hour, and minute or hour and minute\n",
    "    df[new_time_col] = df[new_time_col].dt.strftime(TIME_FORMAT)\n",
    "    \n",
    "    return df\n",
    "\n",
    "Append_r0_hhmm(justif_df_org, 'messageTimestamp','r0_hhmm_5min_message')\n",
    "Append_r0_hhmm(justif_df_org, 'detectiontimestamp','r0_hhmm_5min_detection')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1c073",
   "metadata": {},
   "source": [
    "## Create a reduced Data Frame containing only the necessary columns for the primary and secondary delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "502f0dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:47:14.944595Z",
     "start_time": "2024-08-18T10:47:14.539702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(295402, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>c</th>\n",
       "      <th>r0_hhmm_5min_detection</th>\n",
       "      <th>r0_5min_message</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_message</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_message</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "      <th>t</th>\n",
       "      <th>locationptcarid</th>\n",
       "      <th>justificationID</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>tableType</th>\n",
       "      <th>circulationType</th>\n",
       "      <th>i_extended</th>\n",
       "      <th>j_extended</th>\n",
       "      <th>delayjustifiedbyreason_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66268</th>\n",
       "      <td>-85230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1195</td>\n",
       "      <td>d77bc687-6b2a-449b-8b53-14986bc3afd0</td>\n",
       "      <td>189</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>-85230_COMMERCIAL</td>\n",
       "      <td>nan_COMMERCIAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293273</th>\n",
       "      <td>-85230</td>\n",
       "      <td>-86432.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>00:15</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>ab92dc6d-5728-43f3-9f0d-1b6585d39577</td>\n",
       "      <td>133</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>-85230_COMMERCIAL</td>\n",
       "      <td>-86432.0_COMMERCIAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46482</th>\n",
       "      <td>-20942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:20</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1271</td>\n",
       "      <td>503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2</td>\n",
       "      <td>388</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>-20942_EMPTY</td>\n",
       "      <td>nan_EMPTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263343</th>\n",
       "      <td>-50429</td>\n",
       "      <td>-50429.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>00:25</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>272</td>\n",
       "      <td>8c6a3d61-10e7-4f84-8409-3c6023c010ce</td>\n",
       "      <td>112</td>\n",
       "      <td>secondaryJustification</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>-50429_EMPTY</td>\n",
       "      <td>-50429.0_EMPTY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40953</th>\n",
       "      <td>-37031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>197</td>\n",
       "      <td>030a0e2d-3e84-43c1-b720-6e95b575da5c</td>\n",
       "      <td>173</td>\n",
       "      <td>primaryJustification</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>-37031_COMMERCIAL</td>\n",
       "      <td>nan_COMMERCIAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            i        j       c r0_hhmm_5min_detection  r0_5min_message  \\\n",
       "66268  -85230      NaN     NaN                  00:05                2   \n",
       "293273 -85230 -86432.0  1137.0                  00:15                7   \n",
       "46482  -20942      NaN     NaN                  00:20                8   \n",
       "263343 -50429 -50429.0  1135.0                  00:25                6   \n",
       "40953  -37031      NaN     NaN                  00:30                6   \n",
       "\n",
       "        r0_5min_detection  r1_5min_message  r1_5min_detection  \\\n",
       "66268                   0                6                  6   \n",
       "293273                  3                6                  6   \n",
       "46482                   4                6                  6   \n",
       "263343                  5                6                  6   \n",
       "40953                   5                6                  6   \n",
       "\n",
       "        r2_5min_message  r2_5min_detection  t  locationptcarid  \\\n",
       "66268                 4                  4  0             1195   \n",
       "293273                4                  4  3              208   \n",
       "46482                 4                  4  4             1271   \n",
       "263343                4                  4  5              272   \n",
       "40953                 4                  4  5              197   \n",
       "\n",
       "                             justificationID  delayjustifiedbyreason  \\\n",
       "66268   d77bc687-6b2a-449b-8b53-14986bc3afd0                     189   \n",
       "293273  ab92dc6d-5728-43f3-9f0d-1b6585d39577                     133   \n",
       "46482   503ac7f2-a332-4fd1-9cd1-1fc94f7d66d2                     388   \n",
       "263343  8c6a3d61-10e7-4f84-8409-3c6023c010ce                     112   \n",
       "40953   030a0e2d-3e84-43c1-b720-6e95b575da5c                     173   \n",
       "\n",
       "                     tableType circulationType         i_extended  \\\n",
       "66268     primaryJustification      COMMERCIAL  -85230_COMMERCIAL   \n",
       "293273  secondaryJustification      COMMERCIAL  -85230_COMMERCIAL   \n",
       "46482     primaryJustification           EMPTY       -20942_EMPTY   \n",
       "263343  secondaryJustification           EMPTY       -50429_EMPTY   \n",
       "40953     primaryJustification      COMMERCIAL  -37031_COMMERCIAL   \n",
       "\n",
       "                 j_extended  delayjustifiedbyreason_min  \n",
       "66268        nan_COMMERCIAL                           0  \n",
       "293273  -86432.0_COMMERCIAL                           0  \n",
       "46482             nan_EMPTY                           1  \n",
       "263343       -50429.0_EMPTY                           0  \n",
       "40953        nan_COMMERCIAL                           0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function creates a reduced Data Frame containing only the necessary \n",
    "# columns for the primary and secondary delay\n",
    "#\n",
    "# Note: \n",
    "#\n",
    "# we report both r_5min_message and r_5min_detection. However, the \n",
    "# statistical analysis will be based exclusively on r_5min_detection\n",
    "################################################################################\n",
    "\n",
    "def extract_needed_delay_cols():\n",
    "    \n",
    "    columns_to_keep = ['trainnumber', 'causingtrainnumber', 'secondaryReasonID', 'r0_hhmm_5min_detection',\n",
    "                       'r0_5min_message','r0_5min_detection', 'r1_5min_message','r1_5min_detection', 'r2_5min_message',\n",
    "                       'r2_5min_detection', \n",
    "                       't_5min_detection','locationptcarid', 'justificationID', 'delayjustifiedbyreason', \n",
    "                       'tableType','circulationType']\n",
    "\n",
    "    # Select only the desired columns for our primary and secondary delay data\n",
    "    justif_df = justif_df_org.copy()\n",
    "    justif_df = justif_df.loc[:, columns_to_keep]\n",
    "    \n",
    "    ## Rename the cols to suitable for our model\n",
    "    justif_df.rename(columns={'trainnumber': 'i', 'causingtrainnumber': 'j', 'secondaryReasonID': 'c', 't_5min_detection': 't'}, inplace=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    combining circulationType and trainnumber and create 2 columns i_extended and j_extended, \n",
    "    to address the issue train number and causing train number same .\n",
    "    \"\"\"\n",
    "    \n",
    "    justif_df['i_extended'] = justif_df['i'].astype(str) +\"_\"+ justif_df['circulationType']\n",
    "    justif_df['j_extended'] = justif_df['j'].astype(str) +\"_\"+ justif_df['circulationType']\n",
    "    \n",
    "    justif_df['delayjustifiedbyreason_min'] = ((justif_df['delayjustifiedbyreason'] ) / (60*MINUTE)).astype(int)\n",
    "    \n",
    "    print(justif_df.shape)\n",
    "    justif_df.head(2)\n",
    "    \n",
    "    return justif_df\n",
    "\n",
    "# New reduced Data Frame\n",
    "justif_df = extract_needed_delay_cols()\n",
    "\n",
    "justif_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a789ed7",
   "metadata": {},
   "source": [
    "### Extract primary delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a43d4e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:47:24.813658Z",
     "start_time": "2024-08-18T10:47:24.566551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name:  C:\\data\\Data_for_primary_delay_5min.parquet\n",
      "\n",
      " (226791, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99992</td>\n",
       "      <td>978</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-99992</td>\n",
       "      <td>13085</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2176</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2178</td>\n",
       "      <td>162</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99991</td>\n",
       "      <td>15954</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i      t  r0_5min_detection  r1_5min_detection  r2_5min_detection  \\\n",
       "0 -99992    978                114                  2                  4   \n",
       "1 -99992  13085                125                  2                  5   \n",
       "2 -99991   2176                160                  6                  4   \n",
       "3 -99991   2178                162                  6                  4   \n",
       "4 -99991  15954                114                  5                  5   \n",
       "\n",
       "   delayjustifiedbyreason  \n",
       "0                    9048  \n",
       "1                   12423  \n",
       "2                     651  \n",
       "3                     201  \n",
       "4                     127  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function generates an external local file in the working directory, \n",
    "# containing only the primary delay\n",
    "################################################################################\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "def prepare_primary_delay_df():\n",
    "    \"\"\"\n",
    "    Extract rows from justif df where tableType is primaryJustification.\n",
    "    \"\"\"\n",
    "    temp_df = justif_df[justif_df['tableType']=='primaryJustification']\n",
    "    \n",
    "    #sort data by 't' and reset index and save the delay data to the file\n",
    "    temp_df.sort_values(by='t', inplace=True)\n",
    "    \n",
    "    grouped = temp_df.groupby(['i', 't', 'r0_5min_detection', 'r1_5min_detection', 'r2_5min_detection'])['delayjustifiedbyreason'].max().reset_index()\n",
    "    \n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "    grouped.to_parquet(PRIMARY_DELAY_FILE_PATH, index=False)\n",
    "    return grouped\n",
    "    \n",
    "pri_delay_df = prepare_primary_delay_df()\n",
    "\n",
    "print(\"File name: \", PRIMARY_DELAY_FILE_PATH)\n",
    "\n",
    "print(\"\\n\", pri_delay_df.shape)\n",
    "pri_delay_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e94b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T12:24:33.862939Z",
     "start_time": "2024-02-29T12:24:33.850871Z"
    }
   },
   "source": [
    "### Extract secondary delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eccff67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:47:26.287353Z",
     "start_time": "2024-08-18T10:47:26.205120Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42771, 19)\n",
      "File name:  C:\\data\\Data_for_secondary_delay_5min.parquet\n",
      "\n",
      " (41229, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-85230</td>\n",
       "      <td>-86432</td>\n",
       "      <td>3</td>\n",
       "      <td>1137</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-69328</td>\n",
       "      <td>-29553</td>\n",
       "      <td>8</td>\n",
       "      <td>1137</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i       j  t     c  delayjustifiedbyreason  r0_5min_detection  \\\n",
       "0 -85230  -86432  3  1137                     133                  3   \n",
       "1 -69328  -29553  8  1137                     282                  8   \n",
       "\n",
       "   r1_5min_detection  r2_5min_detection  \n",
       "0                  6                  4  \n",
       "1                  6                  4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function generates an external local file in the working directory, \n",
    "# containing only the raw data of secondary delay\n",
    "################################################################################\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def prepare_sec_delay_df():\n",
    "    \"\"\"\n",
    "    Extract rows from justif df where tableType is secondaryJustification.\n",
    "    \"\"\"\n",
    "    sec_delay_df = justif_df[justif_df['tableType']=='secondaryJustification']\n",
    "\n",
    "    #Converting float value of column 'j', column 'c' to int\n",
    "    sec_delay_df['c'] = pd.to_numeric(sec_delay_df['c'], errors='coerce').astype('Int64')\n",
    "    sec_delay_df['j']  = pd.to_numeric(sec_delay_df['j'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    print(sec_delay_df.shape)\n",
    "    ## We drop the rows that has same delay causing trains 'j' and 'i'\n",
    "    sec_delay_df = sec_delay_df[sec_delay_df['i'] != sec_delay_df['j']]\n",
    "    \n",
    "    ## We only need these columns\n",
    "    sec_delay_df = sec_delay_df[['i', 'j', 't', 'c','delayjustifiedbyreason',\n",
    "                                 'r0_5min_detection','r1_5min_detection','r2_5min_detection']]\n",
    "    sec_delay_df.drop_duplicates(inplace=True)\n",
    "    sec_delay_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #save the raw secondary delay data to the file\n",
    "    sec_delay_df.to_parquet(SECONDARY_DELAY_FILE_PATH, index=False)\n",
    "    \n",
    "    return sec_delay_df\n",
    "    \n",
    "\n",
    "sec_delay_df = prepare_sec_delay_df()\n",
    "print(\"File name: \", SECONDARY_DELAY_FILE_PATH)\n",
    "print(\"\\n\",sec_delay_df.shape)\n",
    "sec_delay_df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b857289c-c42a-491e-bc7d-a2ad9a1ebe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-85230</td>\n",
       "      <td>-86432</td>\n",
       "      <td>3</td>\n",
       "      <td>1137</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-69328</td>\n",
       "      <td>-29553</td>\n",
       "      <td>8</td>\n",
       "      <td>1137</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-50429</td>\n",
       "      <td>-33673</td>\n",
       "      <td>9</td>\n",
       "      <td>1134</td>\n",
       "      <td>154</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-24885</td>\n",
       "      <td>-66586</td>\n",
       "      <td>11</td>\n",
       "      <td>1137</td>\n",
       "      <td>184</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17800</td>\n",
       "      <td>-19814</td>\n",
       "      <td>12</td>\n",
       "      <td>1137</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41224</th>\n",
       "      <td>-86289</td>\n",
       "      <td>-51298</td>\n",
       "      <td>8636</td>\n",
       "      <td>1137</td>\n",
       "      <td>126</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41225</th>\n",
       "      <td>-26325</td>\n",
       "      <td>-19172</td>\n",
       "      <td>8637</td>\n",
       "      <td>1137</td>\n",
       "      <td>126</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41226</th>\n",
       "      <td>-26325</td>\n",
       "      <td>-47506</td>\n",
       "      <td>8637</td>\n",
       "      <td>1134</td>\n",
       "      <td>92</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41227</th>\n",
       "      <td>-47290</td>\n",
       "      <td>-26325</td>\n",
       "      <td>8638</td>\n",
       "      <td>1137</td>\n",
       "      <td>452</td>\n",
       "      <td>286</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41228</th>\n",
       "      <td>-26325</td>\n",
       "      <td>-47506</td>\n",
       "      <td>8638</td>\n",
       "      <td>1134</td>\n",
       "      <td>315</td>\n",
       "      <td>286</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41229 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           i       j     t     c  delayjustifiedbyreason  r0_5min_detection  \\\n",
       "0     -85230  -86432     3  1137                     133                  3   \n",
       "1     -69328  -29553     8  1137                     282                  8   \n",
       "2     -50429  -33673     9  1134                     154                  9   \n",
       "3     -24885  -66586    11  1137                     184                 11   \n",
       "4     -17800  -19814    12  1137                     400                 12   \n",
       "...      ...     ...   ...   ...                     ...                ...   \n",
       "41224 -86289  -51298  8636  1137                     126                284   \n",
       "41225 -26325  -19172  8637  1137                     126                285   \n",
       "41226 -26325  -47506  8637  1134                      92                285   \n",
       "41227 -47290  -26325  8638  1137                     452                286   \n",
       "41228 -26325  -47506  8638  1134                     315                286   \n",
       "\n",
       "       r1_5min_detection  r2_5min_detection  \n",
       "0                      6                  4  \n",
       "1                      6                  4  \n",
       "2                      6                  4  \n",
       "3                      6                  4  \n",
       "4                      6                  4  \n",
       "...                  ...                ...  \n",
       "41224                  7                  4  \n",
       "41225                  7                  4  \n",
       "41226                  7                  4  \n",
       "41227                  7                  4  \n",
       "41228                  7                  4  \n",
       "\n",
       "[41229 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_delay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe95c4a",
   "metadata": {},
   "source": [
    "### Mark empty / freight trains on primary/secondary delay df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58f74d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:49:51.726413Z",
     "start_time": "2024-08-18T10:47:34.590134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>c</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "      <th>i_empty</th>\n",
       "      <th>i_traingroup</th>\n",
       "      <th>j_empty</th>\n",
       "      <th>j_traingroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-85230</td>\n",
       "      <td>-86432</td>\n",
       "      <td>3</td>\n",
       "      <td>1137</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-69328</td>\n",
       "      <td>-29553</td>\n",
       "      <td>8</td>\n",
       "      <td>1137</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i       j  t     c  delayjustifiedbyreason  r0_5min_detection  \\\n",
       "0 -85230  -86432  3  1137                     133                  3   \n",
       "1 -69328  -29553  8  1137                     282                  8   \n",
       "\n",
       "   r1_5min_detection  r2_5min_detection    i_empty i_traingroup j_empty  \\\n",
       "0                  6                  4  Not Empty    PASSENGER    None   \n",
       "1                  6                  4      Empty    PASSENGER   Empty   \n",
       "\n",
       "  j_traingroup  \n",
       "0         None  \n",
       "1    PASSENGER  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions get_tr_traingroup_empty_status, get_empty_freight_trains uses DA_it_df  \n",
    "# takes 'i' from pri_delay_df finds  traingroup of 'i' and empty or non empty status of 'i' \n",
    "# creates new columns in pri_delay_df namely i_traingroup, i_empty\n",
    "# (or)\n",
    "#  takes 'i','j' from sec_delay_df finds traingroup of 'i' 'j', and empty or non empty status of 'i' and 'j'\n",
    "# creates new columns in sec_delay_df namely i_traingroup, j_traingroup,i_empty,j_empty\n",
    "################################################################################\n",
    "\n",
    "DA_it_df = read_function_data(EFFECTIVE_DF_DA_IT_W_FREIGHT_FILE_PATH)\n",
    "DA_it_df['tr_isempty_encoded'] = DA_it_df['tr_isempty'].replace({0: 'Not Empty', 1: 'Empty'})\n",
    "\n",
    "def get_tr_traingroup_empty_status(row, col_name, col_to_extract):\n",
    "    \n",
    "    # Filter DA_it_df based on the conditions\n",
    "    matching_rows = DA_it_df.loc[\n",
    "        (DA_it_df['i'] == row[col_name]) & \n",
    "        (row['t'] >= DA_it_df['start_t']) & \n",
    "        (row['t'] <= DA_it_df['end_t']), \n",
    "        col_to_extract\n",
    "    ]\n",
    "    \n",
    "    # Check if there's any matching row\n",
    "    if not matching_rows.empty:\n",
    "        return matching_rows.values[0]\n",
    "    else:\n",
    "        # Return None or an empty Series if no match is found\n",
    "        return None\n",
    "    \n",
    "     \n",
    "def get_empty_freight_trains(new_df):\n",
    "    # Apply the function to each row in new_df for the 'i' column, 'j' column\n",
    "    new_df['i_empty'] = new_df.apply(lambda row: get_tr_traingroup_empty_status(row, 'i','tr_isempty_encoded'), axis=1)\n",
    "    new_df['i_traingroup'] = new_df.apply(lambda row: get_tr_traingroup_empty_status(row, 'i', 'tr_traingroup'), axis=1)\n",
    "    \n",
    "    if 'j' in new_df.columns:\n",
    "        new_df['j_empty'] = new_df.apply(lambda row: get_tr_traingroup_empty_status(row, 'j','tr_isempty_encoded'), axis=1)\n",
    "        new_df['j_traingroup'] = new_df.apply(lambda row: get_tr_traingroup_empty_status(row, 'j','tr_traingroup'), axis=1)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "pri_delay_df= get_empty_freight_trains(pri_delay_df)\n",
    "\n",
    "sec_delay_df= get_empty_freight_trains(sec_delay_df)\n",
    "sec_delay_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5740f84e-c078-4230-804a-9afe5a9c9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "      <th>r0_5min_detection</th>\n",
       "      <th>r1_5min_detection</th>\n",
       "      <th>r2_5min_detection</th>\n",
       "      <th>delayjustifiedbyreason</th>\n",
       "      <th>i_empty</th>\n",
       "      <th>i_traingroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-99992</td>\n",
       "      <td>978</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9048</td>\n",
       "      <td>Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-99992</td>\n",
       "      <td>13085</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12423</td>\n",
       "      <td>Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2176</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>651</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>FREIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99991</td>\n",
       "      <td>2178</td>\n",
       "      <td>162</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>FREIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99991</td>\n",
       "      <td>15954</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>FREIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226786</th>\n",
       "      <td>-17</td>\n",
       "      <td>22950</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>158</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226787</th>\n",
       "      <td>-17</td>\n",
       "      <td>23244</td>\n",
       "      <td>204</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226788</th>\n",
       "      <td>-17</td>\n",
       "      <td>24966</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226789</th>\n",
       "      <td>-17</td>\n",
       "      <td>25255</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226790</th>\n",
       "      <td>-17</td>\n",
       "      <td>25831</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>PASSENGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226791 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            i      t  r0_5min_detection  r1_5min_detection  r2_5min_detection  \\\n",
       "0      -99992    978                114                  2                  4   \n",
       "1      -99992  13085                125                  2                  5   \n",
       "2      -99991   2176                160                  6                  4   \n",
       "3      -99991   2178                162                  6                  4   \n",
       "4      -99991  15954                114                  5                  5   \n",
       "...       ...    ...                ...                ...                ...   \n",
       "226786    -17  22950                198                  1                  6   \n",
       "226787    -17  23244                204                  2                  6   \n",
       "226788    -17  24966                198                  1                  6   \n",
       "226789    -17  25255                199                  2                  6   \n",
       "226790    -17  25831                199                  4                  6   \n",
       "\n",
       "        delayjustifiedbyreason    i_empty i_traingroup  \n",
       "0                         9048      Empty    PASSENGER  \n",
       "1                        12423      Empty    PASSENGER  \n",
       "2                          651  Not Empty      FREIGHT  \n",
       "3                          201  Not Empty      FREIGHT  \n",
       "4                          127  Not Empty      FREIGHT  \n",
       "...                        ...        ...          ...  \n",
       "226786                     158  Not Empty    PASSENGER  \n",
       "226787                      61  Not Empty    PASSENGER  \n",
       "226788                      92  Not Empty    PASSENGER  \n",
       "226789                     129  Not Empty    PASSENGER  \n",
       "226790                     108  Not Empty    PASSENGER  \n",
       "\n",
       "[226791 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_delay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f56a8",
   "metadata": {},
   "source": [
    "#### Sec delay summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2830d078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:50:33.956860Z",
     "start_time": "2024-08-18T10:50:33.894953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>i_traingroup</th>\n",
       "      <th>j_traingroup</th>\n",
       "      <th>i_empty</th>\n",
       "      <th>j_empty</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train Group Combinations</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train Group Combinations</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train Group Combinations</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train Group Combinations</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Empty Status Combinations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Empty</td>\n",
       "      <td>Empty</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Empty Status Combinations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Empty</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>4704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Empty Status Combinations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>Empty</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Empty Status Combinations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>27603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i_traingroup_Counts</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i_traingroup_Counts</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>j_traingroup_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>j_traingroup_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FREIGHT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i_empty_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i_empty_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Empty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>j_empty_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Empty</td>\n",
       "      <td>32335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>j_empty_Counts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Empty</td>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Category i_traingroup j_traingroup    i_empty    j_empty  \\\n",
       "0    Train Group Combinations      FREIGHT      FREIGHT        NaN        NaN   \n",
       "1    Train Group Combinations      FREIGHT    PASSENGER        NaN        NaN   \n",
       "2    Train Group Combinations    PASSENGER      FREIGHT        NaN        NaN   \n",
       "3    Train Group Combinations    PASSENGER    PASSENGER        NaN        NaN   \n",
       "4   Empty Status Combinations          NaN          NaN      Empty      Empty   \n",
       "5   Empty Status Combinations          NaN          NaN      Empty  Not Empty   \n",
       "6   Empty Status Combinations          NaN          NaN  Not Empty      Empty   \n",
       "7   Empty Status Combinations          NaN          NaN  Not Empty  Not Empty   \n",
       "8         i_traingroup_Counts    PASSENGER          NaN        NaN        NaN   \n",
       "9         i_traingroup_Counts      FREIGHT          NaN        NaN        NaN   \n",
       "10        j_traingroup_Counts          NaN    PASSENGER        NaN        NaN   \n",
       "11        j_traingroup_Counts          NaN      FREIGHT        NaN        NaN   \n",
       "12             i_empty_Counts          NaN          NaN  Not Empty        NaN   \n",
       "13             i_empty_Counts          NaN          NaN      Empty        NaN   \n",
       "14             j_empty_Counts          NaN          NaN        NaN  Not Empty   \n",
       "15             j_empty_Counts          NaN          NaN        NaN      Empty   \n",
       "\n",
       "    count  \n",
       "0    2190  \n",
       "1    6050  \n",
       "2    2378  \n",
       "3   24859  \n",
       "4     918  \n",
       "5    4704  \n",
       "6    2252  \n",
       "7   27603  \n",
       "8   32210  \n",
       "9    8975  \n",
       "10  30938  \n",
       "11   4573  \n",
       "12  34771  \n",
       "13   6414  \n",
       "14  32335  \n",
       "15   3176  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function extracts the summary statistics of \n",
    "## freight and passenger trains in 'i' and 'j' columns\n",
    "## empty and nonempty trains in the 'i' and 'j' columns\n",
    "## writes the summary to a local csv file in  working directory\n",
    "################################################################################\n",
    "\n",
    "def get_statistics_for_sec_delay_df(new_df):\n",
    "    \n",
    "    # 1. Train Group Combinations\n",
    "    train_group_counts = new_df.groupby(['i_traingroup', 'j_traingroup']).size().reset_index(name='count')\n",
    "    train_group_counts['Category'] = 'Train Group Combinations'\n",
    "    train_group_counts['i_empty'] = pd.NA\n",
    "    train_group_counts['j_empty'] = pd.NA\n",
    "\n",
    "    # 2. Empty Status Combinations\n",
    "    empty_status_counts = new_df.groupby(['i_empty', 'j_empty']).size().reset_index(name='count')\n",
    "    empty_status_counts['Category'] = 'Empty Status Combinations'\n",
    "    empty_status_counts['i_traingroup'] = pd.NA\n",
    "    empty_status_counts['j_traingroup'] = pd.NA\n",
    "\n",
    "    # 3. Individual Value Counts for `i_traingroup`, `j_traingroup`, `i_empty`, `j_empty`\n",
    "    i_traingroup_counts = new_df['i_traingroup'].value_counts().reset_index(name='count')\n",
    "    i_traingroup_counts.columns = ['i_traingroup', 'count']\n",
    "    i_traingroup_counts['Category'] = 'i_traingroup_Counts'\n",
    "    i_traingroup_counts['j_traingroup'] = pd.NA\n",
    "    i_traingroup_counts['i_empty'] = pd.NA\n",
    "    i_traingroup_counts['j_empty'] = pd.NA\n",
    "\n",
    "    j_traingroup_counts = new_df['j_traingroup'].value_counts().reset_index(name='count')\n",
    "    j_traingroup_counts.columns = ['j_traingroup', 'count']\n",
    "    j_traingroup_counts['Category'] = 'j_traingroup_Counts'\n",
    "    j_traingroup_counts['i_traingroup'] = pd.NA\n",
    "    j_traingroup_counts['i_empty'] = pd.NA\n",
    "    j_traingroup_counts['j_empty'] = pd.NA\n",
    "\n",
    "    i_empty_counts = new_df['i_empty'].value_counts().reset_index(name='count')\n",
    "    i_empty_counts.columns = ['i_empty', 'count']\n",
    "    i_empty_counts['Category'] = 'i_empty_Counts'\n",
    "    i_empty_counts['i_traingroup'] =pd.NA\n",
    "    i_empty_counts['j_traingroup'] = pd.NA\n",
    "    i_empty_counts['j_empty'] = pd.NA\n",
    "\n",
    "    j_empty_counts = new_df['j_empty'].value_counts().reset_index(name='count')\n",
    "    j_empty_counts.columns = ['j_empty', 'count']\n",
    "    j_empty_counts['Category'] = 'j_empty_Counts'\n",
    "    j_empty_counts['i_traingroup'] = pd.NA\n",
    "    j_empty_counts['j_traingroup'] = pd.NA\n",
    "    \n",
    "    j_empty_counts['i_empty'] = pd.NA\n",
    "\n",
    "    # 4. Combine all into a single DataFrame\n",
    "    combined_df = pd.concat([\n",
    "        train_group_counts,\n",
    "        empty_status_counts,\n",
    "        i_traingroup_counts,\n",
    "        j_traingroup_counts,\n",
    "        i_empty_counts,\n",
    "        j_empty_counts\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    # Reorder columns to match the desired output\n",
    "    combined_df = combined_df[['Category', 'i_traingroup', 'j_traingroup', 'i_empty', 'j_empty', 'count']]\n",
    "    \n",
    "    file_name = os.path.join(DATA_DIR, 'sec_delay_train_statistics_' + TIME_FREQUENCY + '.csv')\n",
    "    combined_df.to_csv(file_name, index=False)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "combined_df = get_statistics_for_sec_delay_df(sec_delay_df)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef4eb3",
   "metadata": {},
   "source": [
    "#### Data cleaning for primary/secondary delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22dc42a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:48:56.502090Z",
     "start_time": "2024-09-08T12:48:56.369198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pri_df shape before dropping Empty and frieght trains\n",
      "(226791, 8)\n",
      "(150588, 6)\n"
     ]
    }
   ],
   "source": [
    "## We perform data cleaning over our pri_delay_df\n",
    "## We drop all frieght trains and empty trains \n",
    "# and store cleaned pri_delay_df to the parquet file \n",
    "# in the working directory PRIMARY_DELAY_CLEANED_FILE_PATH , \n",
    "# we overwrite our pri_delay_df with the cleaned version that only passenger and non empty trains\n",
    "\n",
    "def clean_and_store_pri_delay(pri_delay_df):\n",
    "    print(\"Pri_df shape before dropping Empty and frieght trains\")\n",
    "    print(pri_delay_df.shape)\n",
    "    pri_delay_df = pri_delay_df[(pri_delay_df['i_traingroup'] == 'PASSENGER') \n",
    "                               & (pri_delay_df['i_empty'] == 'Not Empty')]\n",
    "\n",
    "    # Columns to convert\n",
    "    pri_delay_df['delayjustifiedbyreason'] = pri_delay_df['delayjustifiedbyreason'].fillna(0).astype(int)\n",
    "            \n",
    "    grouped = pri_delay_df.groupby(['i', 't', 'r0_5min_detection', 'r1_5min_detection', 'r2_5min_detection'])['delayjustifiedbyreason'].max().reset_index()\n",
    "    \n",
    "    grouped.sort_values(by='t', inplace=True)\n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    grouped.to_parquet(PRIMARY_DELAY_CLEANED_FILE_PATH, index=False)\n",
    "    print(grouped.shape)\n",
    "\n",
    "    \n",
    "clean_and_store_pri_delay(pri_delay_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cca6365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T10:51:52.206993Z",
     "start_time": "2024-08-18T10:51:51.889060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sec_df shape before dropping Empty and frieght trains\n",
      "(41229, 12)\n",
      "(19034, 8)\n"
     ]
    }
   ],
   "source": [
    "## We perform data cleaning over our sec_delay_df\n",
    "## We drop all frieght trains and empty trains \n",
    "# and store cleaned sec_delay_df to the parquet file \n",
    "# in the working directory SECONDARY_DELAY_CLEANED_FILE_PATH , \n",
    "# we overwrite our sec_delay_df with the cleaned version that only passenger and non empty trains\n",
    "\n",
    "def clean_and_store_sec_delay(sec_delay_df):\n",
    "    print(\"Sec_df shape before dropping Empty and frieght trains\")\n",
    "    print(sec_delay_df.shape)\n",
    "    sec_delay_df = sec_delay_df[(sec_delay_df['i_traingroup'] == 'PASSENGER') \n",
    "                               & (sec_delay_df['i_empty'] == 'Not Empty') \n",
    "                               & (sec_delay_df['j_traingroup'] == 'PASSENGER') \n",
    "                               & (sec_delay_df['j_empty'] == 'Not Empty')]\n",
    "\n",
    "    # Columns to convert\n",
    "    sec_delay_df['delayjustifiedbyreason'] = sec_delay_df['delayjustifiedbyreason'].fillna(0).astype(int)\n",
    "    \n",
    "    grouped = sec_delay_df.groupby(['i', 'j','t', 'c', 'r0_5min_detection', 'r1_5min_detection', 'r2_5min_detection'])['delayjustifiedbyreason'].max().reset_index()\n",
    "    \n",
    "    grouped.sort_values(by='t', inplace=True)\n",
    "    grouped.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    grouped.to_parquet(SECONDARY_DELAY_CLEANED_FILE_PATH, index=False)\n",
    "    print(grouped.shape)\n",
    "\n",
    "    \n",
    "clean_and_store_sec_delay(sec_delay_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbee5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:53:13.100516Z",
     "start_time": "2024-09-08T12:53:13.096664Z"
    }
   },
   "source": [
    "### Load the cleaning primary/secondary delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c3bcf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:28:33.941999Z",
     "start_time": "2025-02-16T09:28:33.904926Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Call the read_function_data function to read parquet file \n",
    "# in the working directory PRIMARY_DELAY_FILE_PATH,SECONDARY_DELAY_CLEANED_FILE_PATH \n",
    "# we have created earlier via the function prepare_primary_delay_df, clean_and_store_sec_delay\n",
    "################################################################################\n",
    "\n",
    "pri_delay_df = read_function_data(PRIMARY_DELAY_CLEANED_FILE_PATH)\n",
    "# sec_delay_df = read_function_data(SECONDARY_DELAY_CLEANED_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6887357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:28:41.889390Z",
     "start_time": "2025-02-16T09:28:41.873051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19034, 3)\n",
      "(18960, 3)\n"
     ]
    }
   ],
   "source": [
    "sec_delay_df = read_function_data(SECONDARY_DELAY_CLEANED_FILE_PATH)\n",
    "sec_delay_df\n",
    "\n",
    "new_df = sec_delay_df[['i', 'j','t']].copy()\n",
    "    \n",
    "print(new_df.shape)\n",
    "new_df.drop_duplicates(inplace=True)\n",
    "print(new_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a32bba",
   "metadata": {},
   "source": [
    "## Construction of the delay varialbe $w_{i,t}$\n",
    "\n",
    "We define as $y_{i,t}$ the primary delay of train $i$ at time $t$. This is not taken as an endogenous variable of the model, but as a known quantity at time $t-\\ell$. In fact, our goal is to be able to predict the cascade of delays caused by primary delays, leading to the total delay of train $i$ at time $t$. We also define as $D_{i}$ as the departure time of tray $i$ and let $R_{i}(t) = \\{h \\in \\mathbb{N} ~:~ t \\leq h \\leq D_{i} \\}$. The total delay of train $i$ at time $t$ is obtained as follows:\n",
    "$$\n",
    "w_{i,t} = \\begin{cases}\n",
    "    \\underbrace{\\sum_{h \\in R_{i}(t)} y_{i,h}}_{\\text{primary delay}} + \\underbrace{\\sum_{c \\in \\mathcal{C}} \\sum_{h \\in R_{i}(t)} \\sum_{j \\in \\mathcal{E}_{i,t}} w_{i,j,h}^c}_{\\text{secondary delay}} - \\underbrace{\\sum_{h \\in R_{i}(t)} b_{i,h}}_{\\text{recovery}}, & \\text{ if } t \\geq D_i\\\\[1.2cm]\n",
    "    0 & \\text{ otherwise }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{E}_{i,t}$ is the list of trains that are neighbours of train $i$ at time $t$. This notion of neighborhood is defined based on the idea of possible infrastructure and resource sharing by each pair of trains. To this end, let $r_0(t)$, $r_1(t)$, and $r_2(t)$ be the respective time of the day (in minutes), the day of the week (from one to seven) and month of the year (from one to seven), corresponding to data time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d119aa86-70c9-4268-a041-cf4a43ce4328",
   "metadata": {},
   "source": [
    "### Variable $y_{i,t}$: Primary delay component of $w_{i,t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f0dfe0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:28:44.969586Z",
     "start_time": "2025-02-16T09:28:44.963510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "## The following function extracts the primary delay in seconds from pri_delay_df\n",
    "## for the train 'i' at time 't'\n",
    "################################################################################\n",
    "\n",
    "def get_y(i, t, delay_df):\n",
    "    \"\"\"\n",
    "    Check primary delay for a given train 'i' at the time 't'.\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - t : Time of interest \n",
    "    - delay_df (pd.DataFrame): DataFrame containing delay information with columns 'i', 't', and 'delayjustifiedbyreason'.\n",
    "\n",
    "    Returns:\n",
    "    - int: delay in seconds if the delayjustifiedbyreason exists, otherwise returns 0.\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame based on the given train identifier and time\n",
    "    i_match = delay_df['i'].values == i\n",
    "    t_match = delay_df['t'].values == t\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation & Find indices where the combined condition is True\n",
    "    combined_match = i_match & t_match\n",
    "    matched_indices = np.where(combined_match)[0]\n",
    "    \n",
    "    # Check if the filtered DataFrame is not empty\n",
    "    if len(matched_indices) > 0:\n",
    "        # Retrieve the delayjustifiedbyreason and return 1 if it's not zero, otherwise return 0\n",
    "        delay_value = delay_df['delayjustifiedbyreason'].values[matched_indices[0]]\n",
    "        return delay_value if delay_value != 0 else 0\n",
    "    else:\n",
    "        # Handle case where no matching rows are found\n",
    "        return 0\n",
    "\n",
    "\n",
    "print(get_y(pri_delay_df.iloc[3]['i'],pri_delay_df.iloc[3]['t'],pri_delay_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7276971-ddf8-42f8-a4ef-9ea50f55a340",
   "metadata": {},
   "source": [
    "### Variable $y_{i,t}$: calculate the following term:\n",
    "$$\n",
    "\\underbrace{\\sum_{h \\in R_{i}(t)} y_{i,h}}_{\\text{primary delay}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcee96a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:29:07.638424Z",
     "start_time": "2025-02-16T09:29:07.630417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i -15617\n",
      "t 75\n",
      "D_i 74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function calculate the total primary delay term (the summation above)\n",
    "################################################################################\n",
    "\n",
    "def get_primary_delay(i, t, D_i, delay_df=pri_delay_df):\n",
    "    \"\"\"\n",
    "    Calculate the sum of primary delays (y_values) for a given train 'i' over the time range [t, D_i].\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - t : Lower bound of the time range.\n",
    "    - D_i : Train Departure time.\n",
    "    - delay_df (pd.DataFrame):  DataFrame containing information about train primary delays.\n",
    "\n",
    "    Returns:\n",
    "    - int: The sum of primary delays for train 'i' from time 't' to 'D_i'.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = 0\n",
    "    for h in range(D_i,t):\n",
    "        y_value = get_y(i, h, delay_df)\n",
    "\n",
    "        # Add the y_value to the result\n",
    "        result += y_value\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# Calculate the calculate_primary_delay\n",
    "i = sec_delay_df.iloc[3]['i']\n",
    "t = sec_delay_df.iloc[3]['t']\n",
    "print(\"i\",i)\n",
    "print(\"t\",t)\n",
    "D_i = int(get_D_it(i, t))\n",
    "print(\"D_i\",D_i)\n",
    "get_primary_delay(i, t, D_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3482a8",
   "metadata": {},
   "source": [
    "### Variable $w_{i,j,t}^c$: Secondary delay component of $w_{i,t}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a17de0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:29:08.953718Z",
     "start_time": "2025-02-16T09:29:08.945008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function returns delay in seconds train j has caused a \n",
    "# secondary delay of type c to train i at time t\n",
    "################################################################################\n",
    "\n",
    "def get_w_ijtc(i,j,t,c,temp_df=sec_delay_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Check secondary delay for a given train 'i' by train 'j' at the time t  due to reason 'c'.\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - j : delay causing trains 'j' for a given train 'i'.\n",
    "    - t : time.\n",
    "    - c : delay reason c\n",
    "     Returns:\n",
    "    - int: delay in seconds if the delayjustifiedbyreason exists, otherwise returns 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    i_match = temp_df['i'].values == i\n",
    "    j_match = temp_df['j'].values == j\n",
    "    t_match = temp_df['t'].values == t\n",
    "    c_match = temp_df['c'].values == c\n",
    "    \n",
    "    # Combine the conditions using element-wise 'AND' operation & Find indices where the combined condition is True\n",
    "    combined_match = i_match & j_match & t_match & c_match\n",
    "    matched_indices = np.where(combined_match)[0]\n",
    "    \n",
    "    # Check if the filtered DataFrame is not empty\n",
    "    if len(matched_indices) > 0:\n",
    "        delay_value = temp_df['delayjustifiedbyreason'].values[matched_indices[0]]\n",
    "        return delay_value if delay_value != 0 else 0\n",
    "    else:\n",
    "        # Handle case where no matching rows are found\n",
    "        return 0\n",
    "\n",
    "print(get_w_ijtc(sec_delay_df.iloc[3]['i'],\n",
    "                 sec_delay_df.iloc[3]['j'],\n",
    "                 sec_delay_df.iloc[3]['t'],\n",
    "                 sec_delay_df.iloc[3]['c'],\n",
    "                 sec_delay_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87643b0f",
   "metadata": {},
   "source": [
    "#### Filling the EndogenousData class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df498c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:29:16.448111Z",
     "start_time": "2025-02-16T09:29:10.885068Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19034, 4)\n",
      "(19034, 4)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following fuction uses cleaned sec_delay_df to provide values to the columns i, j, c, 't', in the class EndogenousData\n",
    "# and uses function_w(i,j,t,c,temp_df=sec_delay_df) to provide values to the column w_{i,j,t}^c in the class EndogenousData\n",
    "################################################################################\n",
    "\n",
    "def fill_endogenousData_class():\n",
    "    # Create a new DataFrame with the necessary columns\n",
    "    new_df = sec_delay_df[['i', 'j', 't', 'c']].copy()\n",
    "    \n",
    "    print(new_df.shape)\n",
    "    new_df.drop_duplicates(inplace=True)\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(new_df.shape)\n",
    "    # Apply function_w to each row in the new DataFrame\n",
    "    new_df['w_{i,j,t}^c'] = new_df.apply(lambda row: get_w_ijtc(row['i'], row['j'], row['t'], row['c']), axis=1)\n",
    "\n",
    "    # Initialize the EndogenousData class with the new DataFrame\n",
    "    return EndogenousData(new_df)\n",
    "\n",
    "\n",
    "# Example of how to use the class\n",
    "endogenous_data = fill_endogenousData_class()\n",
    "temp = endogenous_data.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873da2d",
   "metadata": {},
   "source": [
    "#### To construct the secondary delay term of $w_{i,t}$ we need to define the set $\\mathcal{C}$, as appearing in the following summation:\n",
    "$$\n",
    "\\underbrace{\\sum_{c \\in \\mathcal{C}} \\sum_{h \\in R_{i}(t)} \\sum_{j \\in \\mathcal{E}_{i,t}} w_{i,j,h}^c}_{\\text{secondary delay}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e6df68f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:40:26.801687Z",
     "start_time": "2025-02-16T07:40:26.797225Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following function returns the set of delay reasons C\n",
    "################################################################################\n",
    "\n",
    "def get_C_it(i, w_ijtc):\n",
    "    \"\"\"\n",
    "    Get all delay reason 'c' for a given train 'i' from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - w_ijtc (pd.DataFrame): DataFrame containing information about train secondary delays.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of delay reason 'c' for the given train 'i' at time 't'.\n",
    "    \"\"\"\n",
    "    # Step 1: Check if 'i' & c column matches the given value using NumPy array\n",
    "    i_match = w_ijtc['i'].values == i\n",
    "    c_not_null = ~w_ijtc['c'].isnull().values  # Exclude rows where 'c' is NaN\n",
    "\n",
    "    # Step 2: Combine the two conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & c_not_null\n",
    "\n",
    "    # Step 3: extract 'c' values from the DataFrame\n",
    "    delay_array = w_ijtc['c'].values[combined_match]    \n",
    "    return np.unique(delay_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723b93e",
   "metadata": {},
   "source": [
    "#### To construct the secondary delay term of $w_{i,t}$ we need to define the set $\\mathcal{E}_{i,t}$, as appearing in the following summation:\n",
    "$$\n",
    "\\underbrace{\\sum_{c \\in \\mathcal{C}} \\sum_{h \\in R_{i}(t)} \\sum_{j \\in \\mathcal{E}_{i,t}} w_{i,j,h}^c}_{\\text{secondary delay}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97f1d7e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:40:32.416080Z",
     "start_time": "2025-02-16T07:40:32.395181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-92102 -65352 -15782 -13745  -2373]\n",
      "[-13745, -15782, -65352, -92102, -2373]\n",
      "[-13745]\n",
      "[-13745]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following functions calculates the global neighborhoods (network)\n",
    "#def get_E_i_t(i,t,w_ijtc): # All the train j that where producing a secondary delay to i at time 't'\n",
    "#def get_E_i_r0(i, r0(t), w_ijtc): # All the train j that where producing a secondary delay to i at all privious days at time r0(t)\n",
    "#def get_E_i_r1(i, r1(t), w_ijtc): # All the train j that where producing a secondary delay to i at day r1(t)\n",
    "#def get_E_i_r2(i, r2(t), w_ijtc): # All the train j that where producing a secondary delay to i in month r2(t)\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "# The following function returns All the train j that where producing a secondary delay to i at all previous minute at r0(t)\n",
    "################################################################################\n",
    "\n",
    "def get_E_i_r0(i, r0, w_ijtc):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all causing secondary delay causing trains 'j' for a given train 'i' at all previous days at minute r0(t)\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - r0 (timestamp): minute(t).\n",
    "    - w_ijtc (pd.DataFrame): DataFrame containing information about train secondary delays.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of delay causing trains 'j' for the given train 'i' at minute 'r0'.\n",
    "    \"\"\"\n",
    "    # Step 1: Check if 'i' , 'r0'  column matches the given value using NumPy array\n",
    "    i_match = w_ijtc['i'].values == i\n",
    "    r0_match = w_ijtc['r0_5min_detection'].values == r0\n",
    "    j_not_null = ~w_ijtc['j'].isnull().values  # Exclude rows where 'j' is NaN\n",
    "\n",
    "    # Step 2: Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & r0_match & j_not_null\n",
    "\n",
    "    # Step 3: extract 'j' values from the DataFrame\n",
    "    causing_trains_list = w_ijtc['j'].values[combined_match].tolist()\n",
    "\n",
    "    # Convert the list to a set to remove duplicate values (if any)\n",
    "    causing_trains_set = set(causing_trains_list)\n",
    "\n",
    "    # Return the set of causing trains for the given train 'i'\n",
    "    return list(causing_trains_set)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# The following function returns All the train j that where producing a secondary delay to i at day r1(t)\n",
    "################################################################################\n",
    "def get_E_i_r1(i, r1, w_ijtc):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all secondary delay causing trains 'j' for a given train 'i' at all previous days at day r1\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - r1 (timestamp): day(t)\n",
    "    - w_ijtc (pd.DataFrame): DataFrame containing information about train secondary delays.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of delay causing trains 'j' for the given train 'i' at 'r1'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Check if 'i' , 'r1'  column matches the given value using NumPy array\n",
    "    i_match = w_ijtc['i'].values == i\n",
    "    r1_match = w_ijtc['r1_5min_detection'].values == r1\n",
    "    j_not_null = ~w_ijtc['j'].isnull().values  # Exclude rows where 'j' is NaN\n",
    "\n",
    "    # Step 2: Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & r1_match & j_not_null\n",
    "\n",
    "    # Step 3: extract 'j' values from the DataFrame\n",
    "    causing_trains_list = w_ijtc['j'].values[combined_match].tolist()\n",
    "\n",
    "    # Convert the list to a set to remove duplicate values (if any)\n",
    "    causing_trains_set = set(causing_trains_list)\n",
    "\n",
    "    # Return the set of causing trains for the given train 'i'\n",
    "    return list(causing_trains_set)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# The following function returns All the train j that where producing a secondary delay to i in month r2(t)\n",
    "################################################################################\n",
    "def get_E_i_r2(i, r2, w_ijtc):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all secondary delay causing trains 'j' for a given train 'i' in month r2(t)\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - r2 (timestamp): month(t)\n",
    "    - w_ijtc (pd.DataFrame): DataFrame containing information about train secondary delays.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of delay causing trains 'j' for the given train 'i' at 'r2'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Check if 'i' , 'r2'  column matches the given value using NumPy array\n",
    "    i_match = w_ijtc['i'].values == i\n",
    "    r2_match = w_ijtc['r2_5min_detection'].values == r2\n",
    "    j_not_null = ~w_ijtc['j'].isnull().values  # Exclude rows where 'j' is NaN\n",
    "\n",
    "    # Step 2: Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & r2_match & j_not_null\n",
    "\n",
    "    # Step 3: extract 'j' values from the DataFrame\n",
    "    causing_trains_list = w_ijtc['j'].values[combined_match].tolist()\n",
    "\n",
    "    # Convert the list to a set to remove duplicate values (if any)\n",
    "    causing_trains_set = set(causing_trains_list)\n",
    "\n",
    "    # Return the set of causing trains for the given train 'i'\n",
    "    return list(causing_trains_set)\n",
    "\n",
    "################################################################################\n",
    "# The following function returns the set E_{i}\n",
    "################################################################################\n",
    "\n",
    "def get_E_i(i,  w_ijtc):\n",
    "\n",
    "    \"\"\"\n",
    "    Get all secondary delay causing trains 'j' for a given train 'i'  from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - w_ijtc (pd.DataFrame): DataFrame containing information about train secondary delays.\n",
    "\n",
    "    Returns:\n",
    "    - set: Set of delay causing trains 'j' for the given train 'i'.\n",
    "    \"\"\"\n",
    "    # Step 1: Check if 'i'  column matches the given value using NumPy array\n",
    "    i_match = w_ijtc['i'].values == i\n",
    "    j_not_null = ~w_ijtc['j'].isnull().values  # Exclude rows where 'j' is NaN\n",
    "\n",
    "    # Step 2: Combine the conditions using element-wise 'AND' operation\n",
    "    combined_match = i_match & j_not_null\n",
    "\n",
    "    # Step 3: extract 'j' values from the DataFrame\n",
    "    causing_trains_array = w_ijtc['j'].values[combined_match]\n",
    "    \n",
    "    return np.unique(causing_trains_array)\n",
    "\n",
    "\n",
    "causing_train_list_t = get_E_i(sec_delay_df.iloc[0]['i'], sec_delay_df)\n",
    "print(causing_train_list_t)\n",
    "\n",
    "causing_train_list_r2 = get_E_i_r2(sec_delay_df.iloc[0]['i'],sec_delay_df.iloc[0]['r2_5min_detection'], sec_delay_df)\n",
    "print(causing_train_list_r2)\n",
    "\n",
    "causing_train_list_r1 = get_E_i_r1(sec_delay_df.iloc[0]['i'],sec_delay_df.iloc[0]['r1_5min_detection'], sec_delay_df)\n",
    "print(causing_train_list_r1)\n",
    "\n",
    "causing_train_list_r0 = get_E_i_r0(sec_delay_df.iloc[0]['i'],sec_delay_df.iloc[1]['r0_5min_detection'], sec_delay_df)\n",
    "print(causing_train_list_r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6c9e5",
   "metadata": {},
   "source": [
    "#### Variable $w_{i,j,h}^c$: Calculate secondary delay term of the total delay $w_{i,t}$:\n",
    "$$\n",
    "\\underbrace{\\sum_{c \\in \\mathcal{C}} \\sum_{h \\in R_{i}(t)} \\sum_{j \\in \\mathcal{E}_{i,t}} w_{i,j,h}^c}_{\\text{secondary delay}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca822599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:40:34.091484Z",
     "start_time": "2025-02-16T07:40:34.041539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 74\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function calculate the secondary delay term (the summation above)\n",
    "################################################################################\n",
    "\n",
    "def get_secondary_delay_slow(i, t, D_i, endogenous_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    - i: Train identifier.\n",
    "    - t: time\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "\n",
    "    Returns:\n",
    "    - int: The sum of secondary delays for train 'i' from time 't' to 'D_i'.\n",
    "    \"\"\"\n",
    "    if(D_i<0):\n",
    "        return 0\n",
    "    else:\n",
    "        w_ijtc =  endogenous_data.filter_data(i=i)\n",
    "        E_i = get_E_i(i, w_ijtc)\n",
    "        #print(\"All causing trains:: \",E_i)\n",
    "\n",
    "        C = get_C_it(i, w_ijtc)\n",
    "        #print(\"All delay Reason:: \",C)\n",
    "\n",
    "        result = 0\n",
    "\n",
    "        # Iterate over sets C, R_i, and E_i\n",
    "        for c in C:\n",
    "            for h in range(D_i, t):\n",
    "                for j in E_i:\n",
    "                    # Retrieve the value of wc for the given c, i, j, and h\n",
    "                    # wc_result = function_w(i, j, h, c, sec_delay_df) # Please, replace with the EndogenousData\n",
    "\n",
    "                    # Filter the data for the given i, j, t, and c from the EndogenousData\n",
    "                    filtered_data = endogenous_data.filter_data(i=i, j=j, t=h, c=c)\n",
    "\n",
    "                    # Check if the filtered data is not empty and extract the value of w_{i,j,t}^c\n",
    "                    if not filtered_data.empty:\n",
    "                        wc_result = filtered_data['w_{i,j,t}^c'].iloc[0]\n",
    "                    else:\n",
    "                        wc_result = 0\n",
    "\n",
    "                    # Add the wc value to the result\n",
    "                    result += wc_result\n",
    "\n",
    "        return result\n",
    "\n",
    "# Assuming function_w, get_all_causing_trains_j, get_all_delay_type_c are defined\n",
    "# Calculate the calculate_secondary_delay\n",
    "i = sec_delay_df.iloc[3]['i']\n",
    "t = sec_delay_df.iloc[3]['t']\n",
    "\n",
    "D_i = int(get_D_it(i, t))\n",
    "print(t, D_i)\n",
    "\n",
    "result_triple_sum = get_secondary_delay_slow(i, t,D_i, endogenous_data)\n",
    "print(result_triple_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23aba460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:40:35.160350Z",
     "start_time": "2025-02-16T07:40:35.139246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 74\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function calculate the secondary delay term (the summation above)\n",
    "################################################################################\n",
    "def get_secondary_delay(i, t, D_i, endogenous_data):\n",
    "      \n",
    "    \"\"\"\n",
    "    - i: Train identifier.\n",
    "    - t: time\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "\n",
    "    Returns:\n",
    "    - int: The sum of secondary delays for train 'i' from time 't' to 'D_i'.\n",
    "    \"\"\"\n",
    "\n",
    "    data = endogenous_data.get_data()\n",
    "\n",
    "    # Filter the data based on the conditions for i, t, and D_i\n",
    "    # Select rows where 'i' matches input 'i', column 't' having value more than or equal to D_i and less than input 't'\n",
    "    w_ijtc = data[(data['i'] == i) & \n",
    "                  (data['t'] >= D_i) &\n",
    "                  (data['t'] < t)]\n",
    "\n",
    "    # Extract list of trains that are neighbours of train i  \n",
    "    E_i = get_E_i(i, w_ijtc)\n",
    "\n",
    "    # Extract list of reason that has caused delay to train i  \n",
    "    C = get_C_it(i, w_ijtc)\n",
    "\n",
    "    # Create a boolean mask to filter rows where 'j' is in E_i and 'c' is in C\n",
    "    mask = np.isin(w_ijtc['j'], E_i) & np.isin(w_ijtc['c'], C)\n",
    "\n",
    "    # Sum the 'w_{i,j,t}^c' values from the DataFrame based on the mask\n",
    "    return w_ijtc.loc[mask, 'w_{i,j,t}^c'].sum()\n",
    "\n",
    "\n",
    "# Calculate the calculate_secondary_delay\n",
    "i = sec_delay_df.iloc[2]['i']\n",
    "t = sec_delay_df.iloc[2]['t']\n",
    "\n",
    "D_i = get_D_it(i, t)\n",
    "print(t, D_i)\n",
    "result_triple_sum = get_secondary_delay(i, t,D_i, endogenous_data)\n",
    "print(result_triple_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af52ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:52:24.130844Z",
     "start_time": "2024-06-19T10:52:24.121805Z"
    }
   },
   "source": [
    "### Extract Total delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45823d70-b2b0-4bb3-8c9f-2e72cb976221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 5469\n",
      "100 : 5469\n",
      "200 : 5469\n",
      "300 : 5469\n",
      "400 : 5469\n",
      "500 : 5469\n",
      "600 : 5469\n",
      "700 : 5469\n",
      "800 : 5469\n",
      "900 : 5469\n",
      "1000 : 5469\n",
      "1100 : 5469\n",
      "1200 : 5469\n",
      "1300 : 5469\n",
      "1400 : 5469\n",
      "1500 : 5469\n",
      "1600 : 5469\n",
      "1700 : 5469\n",
      "1800 : 5469\n",
      "1900 : 5469\n",
      "2000 : 5469\n",
      "2100 : 5469\n",
      "2200 : 5469\n",
      "2300 : 5469\n",
      "2400 : 5469\n",
      "2500 : 5469\n",
      "2600 : 5469\n",
      "2700 : 5469\n",
      "2800 : 5469\n",
      "2900 : 5469\n",
      "3000 : 5469\n",
      "3100 : 5469\n",
      "3200 : 5469\n",
      "3300 : 5469\n",
      "3400 : 5469\n",
      "3500 : 5469\n",
      "3600 : 5469\n",
      "3700 : 5469\n",
      "3800 : 5469\n",
      "3900 : 5469\n",
      "4000 : 5469\n",
      "4100 : 5469\n",
      "4200 : 5469\n",
      "4300 : 5469\n",
      "4400 : 5469\n",
      "4500 : 5469\n",
      "4600 : 5469\n",
      "4700 : 5469\n",
      "4800 : 5469\n",
      "4900 : 5469\n",
      "5000 : 5469\n",
      "5100 : 5469\n",
      "5200 : 5469\n",
      "5300 : 5469\n",
      "5400 : 5469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-85230</th>\n",
       "      <th>-53372</th>\n",
       "      <th>-54740</th>\n",
       "      <th>-20520</th>\n",
       "      <th>-80988</th>\n",
       "      <th>-73561</th>\n",
       "      <th>-37218</th>\n",
       "      <th>-55385</th>\n",
       "      <th>-40482</th>\n",
       "      <th>-65603</th>\n",
       "      <th>...</th>\n",
       "      <th>-60388</th>\n",
       "      <th>-11433</th>\n",
       "      <th>-33079</th>\n",
       "      <th>-33410</th>\n",
       "      <th>-15225</th>\n",
       "      <th>-25821</th>\n",
       "      <th>-74114</th>\n",
       "      <th>-14982</th>\n",
       "      <th>-77146</th>\n",
       "      <th>-15845</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26181</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26183</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26186</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows  5469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       -85230  -53372  -54740  -20520  -80988  -73561  -37218  -55385  -40482  \\\n",
       "26169       0       0       0       0       0       0       0       0       0   \n",
       "26170       0       0       0       0       0       0       0       0       0   \n",
       "26171       0       0       0       0       0       0       0       0       0   \n",
       "26172       0       0       0       0       0       0       0       0       0   \n",
       "26173       0       0       0       0       0       0       0       0       0   \n",
       "26174       0       0       0       0       0       0       0       0       0   \n",
       "26175       0       0       0       0       0       0       0       0       0   \n",
       "26176       0       0       0       0       0       0       0       0       0   \n",
       "26177       0       0       0       0       0       0       0       0       0   \n",
       "26178       0       0       0       0       0       0       0       0       0   \n",
       "26179       0       0       0       0       0       0       0       0       0   \n",
       "26180       0       0       0       0       0       0       0       0       0   \n",
       "26181       0       0       0       0       0       0       0       0       0   \n",
       "26182       0       0       0       0       0       0       0       0       0   \n",
       "26183       0       0       0       0       0       0       0       0       0   \n",
       "26184       0       0       0       0       0       0       0       0       0   \n",
       "26185       0       0       0       0       0       0       0       0       0   \n",
       "26186       0       0       0       0       0       0       0       0       0   \n",
       "26187       0       0       0       0       0       0       0       0       0   \n",
       "26188       0       0       0       0       0       0       0       0       0   \n",
       "26189       0       0       0       0       0       0       0       0       0   \n",
       "26190       0       0       0       0       0       0       0       0       0   \n",
       "26191       0       0       0       0       0       0       0       0       0   \n",
       "26192       0       0       0       0       0       0       0       0       0   \n",
       "26193       0       0       0       0       0       0       0       0       0   \n",
       "26194       0       0       0       0       0       0       0       0       0   \n",
       "26195       0       0       0       0       0       0       0       0       0   \n",
       "26196       0       0       0       0       0       0       0       0       0   \n",
       "26197       0       0       0       0       0       0       0       0       0   \n",
       "26198       0       0       0       0       0       0       0       0       0   \n",
       "26199       0       0       0       0       0       0       0       0       0   \n",
       "26200       0       0       0       0       0       0       0       0       0   \n",
       "26201       0       0       0       0       0       0       0       0       0   \n",
       "26202       0       0       0       0       0       0       0       0       0   \n",
       "26203       0       0       0       0       0       0       0       0       0   \n",
       "26204       0       0       0       0       0       0       0       0       0   \n",
       "26205       0       0       0       0       0       0       0       0       0   \n",
       "26206       0       0       0       0       0       0       0       0       0   \n",
       "26207       0       0       0       0       0       0       0       0       0   \n",
       "26208       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       -65603  ...  -60388  -11433  -33079  -33410  -15225  -25821  -74114  \\\n",
       "26169       0  ...       0       0       0       0       0       0       0   \n",
       "26170       0  ...       0       0       0       0       0       0       0   \n",
       "26171       0  ...       0       0       0       0       0       0       0   \n",
       "26172       0  ...       0       0       0       0       0       0       0   \n",
       "26173       0  ...       0       0       0       0       0       0       0   \n",
       "26174       0  ...       0       0       0       0       0       0       0   \n",
       "26175       0  ...       0       0       0       0       0       0       0   \n",
       "26176       0  ...       0       0       0       0       0       0       0   \n",
       "26177       0  ...       0       0       0       0       0       0       0   \n",
       "26178       0  ...       0       0       0       0       0       0       0   \n",
       "26179       0  ...       0       0       0       0       0       0       0   \n",
       "26180       0  ...       0       0       0       0       0       0       0   \n",
       "26181       0  ...       0       0       0       0       0       0       0   \n",
       "26182       0  ...       0       0       0       0       0       0       0   \n",
       "26183       0  ...       0       0       0       0       0       0       0   \n",
       "26184       0  ...       0       0       0       0       0       0       0   \n",
       "26185       0  ...       0       0       0       0       0       0       0   \n",
       "26186       0  ...       0       0       0       0       0       0       0   \n",
       "26187       0  ...       0       0       0       0       0       0       0   \n",
       "26188       0  ...       0       0       0       0       0       0       0   \n",
       "26189       0  ...       0       0       0       0       0       0       0   \n",
       "26190       0  ...       0       0       0       0       0       0       0   \n",
       "26191       0  ...       0       0       0       0       0       0       0   \n",
       "26192       0  ...       0       0       0       0       0       0       0   \n",
       "26193       0  ...       0       0       0       0       0       0       0   \n",
       "26194       0  ...       0       0       0       0       0       0       0   \n",
       "26195       0  ...       0       0       0       0       0       0       0   \n",
       "26196       0  ...       0       0       0       0       0       0       0   \n",
       "26197       0  ...       0       0       0       0       0       0       0   \n",
       "26198       0  ...       0       0       0       0       0       0       0   \n",
       "26199       0  ...       0       0       0       0       0       0       0   \n",
       "26200       0  ...       0       0       0       0       0       0       0   \n",
       "26201       0  ...       0       0       0       0       0       0       0   \n",
       "26202       0  ...       0       0       0       0       0       0       0   \n",
       "26203       0  ...       0       0       0       8       0       0       0   \n",
       "26204       0  ...       0       0       0      20       0       0       0   \n",
       "26205       0  ...       0       0       0     -28       0       0       0   \n",
       "26206       0  ...       0       0       0     -34       0       0       0   \n",
       "26207       0  ...       0       0       0     -61       0       0       0   \n",
       "26208       0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "       -14982  -77146  -15845  \n",
       "26169       0       0       0  \n",
       "26170       0       0       0  \n",
       "26171       0       0       0  \n",
       "26172       0       0       0  \n",
       "26173       0       0       0  \n",
       "26174       0       0       0  \n",
       "26175       0       0       0  \n",
       "26176       0       0       0  \n",
       "26177       0       0       0  \n",
       "26178       0       0       0  \n",
       "26179       0       0       0  \n",
       "26180       0       0       0  \n",
       "26181       0       0       0  \n",
       "26182       0       0       0  \n",
       "26183       0       0       0  \n",
       "26184       0       0       0  \n",
       "26185       0       0       0  \n",
       "26186       0       0       0  \n",
       "26187       0       0       0  \n",
       "26188       0       0       0  \n",
       "26189       0       0       0  \n",
       "26190       0       0       0  \n",
       "26191       0       0       0  \n",
       "26192       0       0       0  \n",
       "26193       0       0       0  \n",
       "26194       0       0       0  \n",
       "26195       0       0       0  \n",
       "26196       0       0       0  \n",
       "26197       0       0       0  \n",
       "26198       0       0       0  \n",
       "26199       0       0       0  \n",
       "26200       0       0       0  \n",
       "26201       0       0       0  \n",
       "26202       0       0       0  \n",
       "26203       0       0       0  \n",
       "26204       0       0       0  \n",
       "26205       0       0       0  \n",
       "26206       0       0       0  \n",
       "26207       0       0       0  \n",
       "26208       0       0       0  \n",
       "\n",
       "[40 rows x 5469 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_formatted_data_w_it_with_Dit(delay_df):\n",
    "    \"\"\"\n",
    "    Construct w_it_df with time index t (0..max_t) and train columns i.\n",
    "    Missing delay values are filled forward only within active times (a_it_df == 1).\n",
    "    \"\"\"\n",
    "    # Build full t range\n",
    "    max_t = delay_df['t'].max()\n",
    "    t = np.arange(0, max_t + 1)\n",
    "\n",
    "    # Unique train IDs\n",
    "    unique_i = delay_df['i'].unique()\n",
    "\n",
    "    # Initialize zero DataFrame (rows: t, columns: train IDs)\n",
    "    w_it_df = pd.DataFrame(0, index=t, columns=unique_i, dtype=int)\n",
    "\n",
    "    # Aggregate delays\n",
    "    delay_agg = delay_df.groupby(['t', 'i'])['w(i,t)'].mean().unstack(fill_value=0)\n",
    "\n",
    "    # Optionally round to nearest integer if you prefer cleaner values\n",
    "    delay_agg = delay_agg.round().astype(int)\n",
    "    \n",
    "    # Reindex to full t range and all trains\n",
    "    delay_agg = delay_agg.reindex(index=t, columns=unique_i, fill_value=0)\n",
    "\n",
    "    count = 0\n",
    "    # Fill within active intervals\n",
    "    for i in unique_i:\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print(count, \":\", unique_i.shape[0])\n",
    "        count += 1\n",
    "        \n",
    "        last_val = 0\n",
    "        for tt in t:\n",
    "            if a_it_df.loc[tt, i] == 1:  # Train is active\n",
    "                val = delay_agg.loc[tt, i]\n",
    "                if val == 0 and last_val != 0:\n",
    "                    # Fill with previous delay only within active period\n",
    "                    w_it_df.loc[tt, i] = last_val\n",
    "                else:\n",
    "                    w_it_df.loc[tt, i] = val\n",
    "                    if val != 0:\n",
    "                        last_val = val\n",
    "            else:\n",
    "                # Train inactive  reset delay memory\n",
    "                last_val = 0\n",
    "                w_it_df.loc[tt, i] = 0\n",
    "                \n",
    "    w_it_df.to_parquet(TOTAL_DELAY_FILE_PATH, index=False)\n",
    "    return w_it_df\n",
    "\n",
    "## Read the S_function file we have created earlier\n",
    "s_r_w_df = read_function_data(FUNCTION_S_R_W0_FILE_PATH)\n",
    "s_r_w_df\n",
    "\n",
    "w_it_df = create_formatted_data_w_it_with_Dit(s_r_w_df)\n",
    "w_it_df.tail(40)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38ff19c4-2637-48e3-8a49-df29fef4e651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26209, 5469)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_it_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adb529e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:43:22.217551Z",
     "start_time": "2025-02-16T07:43:21.745926Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following functions `function_w_i_t`, takes   train ,  time 't' , D_it, w_it_df as input \n",
    "# and returns the total delay w(i,t) \n",
    "################################################################################\n",
    "\n",
    "w_it_df = read_function_data(TOTAL_DELAY_FILE_PATH)\n",
    "w_it_df.columns = w_it_df.columns.astype(int)\n",
    "def get_wit_observed(i,t,D_it,row=None, delay_df=w_it_df):\n",
    "    \"\"\"\n",
    "    Find total delay for a given train 'i' at the time t.\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - t : time.\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "    \n",
    "     Returns:\n",
    "    - int : total delay at time t .\n",
    "    \"\"\"\n",
    "    \n",
    "    if row is not None:\n",
    "        i = row['i']\n",
    "        t = row['t']\n",
    "        D_it = row['D_it']\n",
    "    \n",
    "    if t >= D_it:\n",
    "        return delay_df[i].iloc[t-1]\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37a9e9",
   "metadata": {},
   "source": [
    "### calculate recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f7fa38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:43:27.588253Z",
     "start_time": "2025-02-16T07:43:27.579848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-76539 74 74\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'endogenous_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m D_i \u001b[38;5;241m=\u001b[39m get_D_it(i, t)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(i, t, D_i)\n\u001b[1;32m---> 35\u001b[0m get_recovery(i, t,D_i,endogenous_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'endogenous_data' is not defined"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function calculates the total recovery by subtracting \n",
    "# the primary_delay and secondary_delay from the w_it\n",
    "################################################################################\n",
    "\n",
    "def get_recovery(i, t,D_i,Endogenous_data):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate recovery for a given train 'i' at t .\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - t: timestamp\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "\n",
    "    Returns:\n",
    "    - int: total recovery\n",
    "    \"\"\"\n",
    "     \n",
    "    primary_delay_sum = get_primary_delay(i, t, D_i)\n",
    "    secondary_delay_sum = get_secondary_delay(i,t,D_i,Endogenous_data)\n",
    "    w_it = get_wit_observed(i,t,D_i)\n",
    "\n",
    "    print(\"w_it observed :: \",w_it)\n",
    "\n",
    "    recovery = w_it- (primary_delay_sum +secondary_delay_sum)\n",
    "    return recovery\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "i = sec_delay_df.iloc[2]['i']\n",
    "t = sec_delay_df.iloc[2]['t']\n",
    "D_i = get_D_it(i, t)\n",
    "print(i, t, D_i)\n",
    "get_recovery(i, t,D_i,endogenous_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8501d2af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T07:43:30.672779Z",
     "start_time": "2025-02-16T07:43:30.658464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 73\n",
      "w_it observed ::  238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(238)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# The following function calculates the total delay by adding \n",
    "# the primary_delay, secondary_delay and recovery\n",
    "################################################################################\n",
    "\n",
    "def get_wit_estimated(i, t, D_i, Endogenous_data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate recovery for a given train 'i' at t .\n",
    "\n",
    "    Parameters:\n",
    "    - i (int): Train identifier.\n",
    "    - t: timestamp\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "\n",
    "    Returns:\n",
    "    - int: total recovery\n",
    "    \"\"\"\n",
    "    \n",
    "    primary_delay_sum = get_primary_delay(i, t, D_i)\n",
    "    secondary_delay_sum = get_secondary_delay(i,t,D_i, Endogenous_data)\n",
    "    recovery = get_recovery(i, t, D_i,Endogenous_data)\n",
    "    \n",
    "    w_it = primary_delay_sum + secondary_delay_sum + recovery\n",
    "    \n",
    "    #print(\"w_it estimated :: \",w_it)\n",
    "    return w_it\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "i = sec_delay_df.iloc[1]['i']\n",
    "t = sec_delay_df.iloc[1]['t']\n",
    "\n",
    "D_i = get_D_it(i, t)\n",
    "print(t, D_i)\n",
    "get_wit_estimated(i,t,D_i, endogenous_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b78caa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Compute x_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61e983",
   "metadata": {},
   "source": [
    "$$\n",
    "x(j,t) = \\tilde{x}(w_{j,t}(W, Y, R), \\theta_{t,s}) = \\left\\{\\begin{array}{lll}\n",
    "     1 & \\displaystyle   \\quad \\text{if } w_{j,t}(W, Y, R) \\geq \\theta_{\\boldsymbol{r}(t)}   \\\\[0.5cm]\n",
    "     0 & \\quad \\text{otherwise } \n",
    "\\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1ded696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T01:27:24.807049Z",
     "start_time": "2024-11-20T01:27:24.797247Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following function is to fill the x_tilde for our regression input\n",
    "################################################################################\n",
    "\n",
    "def get_x_tilde(w_it, theta):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate get_x_tilde for a given 'w_it' and theta.\n",
    "\n",
    "    Parameters:\n",
    "    - w_it (int): Total delay of the train.\n",
    "    - theta: threshold\n",
    "\n",
    "    Returns:\n",
    "    - boolean : \n",
    "    \"\"\"\n",
    "\n",
    "    return 1 if w_it > theta else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e5a23",
   "metadata": {},
   "source": [
    "## Fill regression input for Endogenous data with all 't'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d965e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T09:12:49.858357Z",
     "start_time": "2024-09-05T09:12:49.855496Z"
    }
   },
   "source": [
    "### Fill G for regression all 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec0847ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:33:43.302562Z",
     "start_time": "2024-11-19T05:40:58.863722Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# The following uses the endogenous data and computes \n",
    "# 'gplus_0', 'gplus_1', 'gplus_2', 'gminus_0', 'gminus_1', 'gminus_2' get_S_t_w0_optimized_helper\n",
    "# store the result retrived for every input by keeping the corresponding combination of input \n",
    "# (i, time_i, m)   (j, time_j, m) as key \n",
    "# and output of get_S_t_w0 as value in delay_dictionary\n",
    "################################################################################ \n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Get the DataFrame with 'i' and 'j' columns\n",
    "df = endogenous_data.get_data()[['i', 'j']].drop_duplicates()\n",
    "\n",
    "# Convert to numpy array and sort by 'i'\n",
    "unique_pairs = df.to_numpy()\n",
    "unique_pairs = unique_pairs[unique_pairs[:, 0].argsort()]\n",
    "\n",
    "t_values = range(0, a_it_df.index.max())\n",
    "\n",
    "tw_mapping = {}\n",
    "\n",
    "for i, g in s_r_w_df.groupby(\"i\"):\n",
    "    # drop duplicates just in case\n",
    "    tw_mapping[i] = dict(zip(g[\"t\"].values, g[\"t-w(i,t)\"].values))\n",
    "\n",
    "            \n",
    "def generate_G_data(range_number, per_job):\n",
    "    ## setting the tau value\n",
    "     = 3\n",
    "    directory_path = r'C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33' \n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "    from datetime import datetime\n",
    "    columns = ['gplus_0', 'gplus_1', 'gplus_2', 'gminus_0', 'gminus_1', 'gminus_2']\n",
    "\n",
    "    # file_list = [\n",
    "    #     'G_values_batch_50_0_all_t.parquet',\n",
    "    #     'G_values_batch_50_3000_all_t.parquet',\n",
    "    #     'G_values_batch_50_6000_all_t.parquet',\n",
    "    #     'G_values_batch_50_9000_all_t.parquet',\n",
    "    #     'G_values_batch_50_12000_all_t.parquet'\n",
    "    # ]\n",
    "\n",
    "    batch_size = 50\n",
    "    file_name = 'G_values_batch_50_' + str(range_number) + '_all_t.parquet'\n",
    "    \n",
    "    # Process in batches of unique (i, j) pairs\n",
    "    for start in range(range_number, min(range_number + per_job, len(unique_pairs)), batch_size):# len(unique_pairs), batch_size):\n",
    "        print(\"Batch number ::\",start)\n",
    "\n",
    "        \n",
    "        # # Assign file name\n",
    "        # if 0 <= start <= 2999:\n",
    "        #     file_name = 'G_values_batch_50_0_all_t.parquet'\n",
    "        # elif 3000 <= start <= 5999:\n",
    "        #     file_name = 'G_values_batch_50_3000_all_t.parquet'\n",
    "        # elif 6000 <= start <= 8999:\n",
    "        #     file_name = 'G_values_batch_50_6000_all_t.parquet'\n",
    "        # elif 9000 <= start <= 11999:\n",
    "        #     file_name = 'G_values_batch_50_9000_all_t.parquet'\n",
    "        # else:\n",
    "        #     file_name = 'G_values_batch_50_12000_all_t.parquet'\n",
    "\n",
    "        # print(file_name)\n",
    "\n",
    "        file_path = os.path.join(directory_path, file_name) \n",
    "        print(\"Start time:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "        # Initialize the results list for the current batch\n",
    "        batch_results = []\n",
    "\n",
    "        # Select the batch of (i, j) pairs\n",
    "        batch_pairs = unique_pairs[start:start + batch_size]\n",
    "\n",
    "        # Extract i and j values\n",
    "        batch_i = np.unique(batch_pairs[:, 0])\n",
    "        corresponding_j = np.unique(batch_pairs[:, 1])\n",
    "\n",
    "        # print(\"Batch i values:\", batch_i)\n",
    "        # print(\"j values:\", corresponding_j)\n",
    "\n",
    "        # Get unique i values for this batch\n",
    "        i_values = np.unique(np.concatenate([batch_i, corresponding_j]))\n",
    "        # print(\"Unique i_j values for this batch:\", i_values)\n",
    "\n",
    "        # Get stop and passing results\n",
    "        print(\"Going to fill\")\n",
    "        delay_stop_1, delay_passing_1 = get_S_t_w0_optimized_helper(i_values, 'delay')\n",
    "        schedule_stop_1, schedule_passing_1 = get_S_t_w0_optimized_helper(i_values, 'schedule')\n",
    "\n",
    "        _plus_1 =  + 1 \n",
    "        min_t = a_it_df.index.min() - _plus_1\n",
    "        max_t = a_it_df.index.max() + _plus_1\n",
    "\n",
    "        # Initialize delay dictionary\n",
    "        delay_dictionary = {}\n",
    "\n",
    "        ## Wei modifies, use loc rather than iloc\n",
    "        def update_delay_dictionary(train_id):\n",
    "            for t in range(min_t, max_t):\n",
    "                if t in delay_stop_1[train_id].index:\n",
    "                    delay_dictionary[(train_id, t, \"stop\")] = delay_stop_1[train_id].loc[t]\n",
    "                    delay_dictionary[(train_id, t, \"passing\")] = delay_passing_1[train_id].loc[t]\n",
    "                else:\n",
    "                    delay_dictionary[(train_id, t, \"stop\")] = np.zeros(len(S_set_stations), dtype=np.int8)\n",
    "                    delay_dictionary[(train_id, t, \"passing\")] = np.zeros(len(S_set_stations), dtype=np.int8)\n",
    "\n",
    "\n",
    "        schedule_dictionary = {}\n",
    "\n",
    "        ## Wei modifies, use loc rather than iloc\n",
    "        def update_schedule_dictionary(train_id):\n",
    "            for t in range(min_t, max_t):\n",
    "                if t in schedule_stop_1[train_id].index:\n",
    "                    schedule_dictionary[(train_id, t, \"stop\")] = schedule_stop_1[train_id].loc[t]\n",
    "                    schedule_dictionary[(train_id, t, \"passing\")] = schedule_passing_1[train_id].loc[t]\n",
    "                else:\n",
    "                    schedule_dictionary[(train_id, t, \"stop\")] = np.zeros(len(S_set_stations), dtype=np.int8)\n",
    "                    schedule_dictionary[(train_id, t, \"passing\")] = np.zeros(len(S_set_stations), dtype=np.int8)\n",
    "\n",
    "        \n",
    "        # Calculate the total number of combinations\n",
    "        num_combinations = len(batch_pairs) * len(t_values)\n",
    "\n",
    "        # Preallocate DataFrame\n",
    "        temp = pd.DataFrame(index=range(num_combinations), columns=columns + ['i', 'j', 't'])\n",
    "\n",
    "        # Index counter\n",
    "        index_counter = 0\n",
    "\n",
    "        # Iterate over each combination of i and j in the batch\n",
    "        for i, j in batch_pairs:\n",
    "            # print(i,j, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            if i != j:\n",
    "                if (i, 0, \"stop\") not in delay_dictionary:\n",
    "                    update_delay_dictionary(i)\n",
    "                    update_schedule_dictionary(i)\n",
    "                if (j, 0, \"stop\") not in delay_dictionary:\n",
    "                    update_delay_dictionary(j)\n",
    "                    update_schedule_dictionary(j)\n",
    "\n",
    "                for t in t_values:\n",
    "                    # Compute results using get_G_helper_optimized\n",
    "                    m0_minus, m1_minus, m2_minus = get_G_minus_helper_optimized(i, j, t, delay_dictionary, )\n",
    "                    \n",
    "                    ti = tw_mapping[i].get(t, t)\n",
    "                    tj = tw_mapping[j].get(t, t)\n",
    "                    m0_plus, m1_plus, m2_plus = get_G_plus_helper_optimized(i, j, ti, tj, schedule_dictionary,)\n",
    "\n",
    "                    # Store results directly in preallocated DataFrame\n",
    "                    temp.iloc[index_counter] = [m0_plus, m1_plus, m2_plus, m0_minus, m1_minus, m2_minus,i, j, t,]\n",
    "                    index_counter += 1\n",
    "\n",
    "        # Remove empty rows if any (possible if index_counter < num_combinations)\n",
    "        temp = temp.head(index_counter)\n",
    "\n",
    "        #  Append directly to disk  don't read the old file\n",
    "        if not os.path.exists(file_path):\n",
    "            temp.to_parquet(file_path, index=False)\n",
    "        else:\n",
    "            temp.to_parquet(file_path, index=False, append=True, engine=\"fastparquet\")\n",
    "\n",
    "        #  Free up memory after each batch\n",
    "        del temp\n",
    "        import gc; gc.collect()\n",
    "\n",
    "        \n",
    "        # file_exists = os.path.isfile(file_path)\n",
    "        # if file_exists:\n",
    "        #     # Load existing data\n",
    "        #     existing_data = pd.read_parquet(file_path)\n",
    "        #     # Concatenate with new data\n",
    "        #     combined_data = pd.concat([existing_data, temp])\n",
    "        # else:\n",
    "        #     combined_data = temp\n",
    "\n",
    "        # # Save the combined data back to the Parquet file\n",
    "        # combined_data.to_parquet(file_path, index=False)\n",
    "        print(\"Batch number completed ::\",start)\n",
    "        \n",
    "# generate_G_data(1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8767e82f-ef6b-4803-9f5d-59955be026ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "per_job = 3000\n",
    "starts = range(0, len(unique_pairs), per_job)\n",
    "\n",
    "n_jobs = len(starts)\n",
    "Parallel(n_jobs, backend=\"loky\")(\n",
    "    delayed(generate_G_data)(s, per_job) for s in starts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7fdb248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:16:59.187684Z",
     "start_time": "2025-02-16T11:16:59.181478Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# In the above step, we extracted G column values for all i, j combinations.\n",
    "# In the below step, we extract all valid rows based on the G column values.\n",
    "# \n",
    "# Criteria to consider a row is valid or not:\n",
    "# - A row is considered valid if any of the G columns \n",
    "#   (gplus_0, gplus_1, gplus_2, gminus_0, gminus_1, gminus_2) has a value > 0.\n",
    "#\n",
    "# Process:\n",
    "# - Read the data\n",
    "# - Extract rows meeting the validity criteria.\n",
    "# - Combine all valid rows into a single DataFrame.\n",
    "# - Optionally save the resulting DataFrame to a file to the specified path).\n",
    "################################################################################\n",
    "\n",
    "def extract_valid_G_rows(directory_path=None, save_path = None):\n",
    "    \n",
    "    file_list = [\n",
    "        'G_values_batch_50_0_all_t.parquet',\n",
    "        'G_values_batch_50_3000_all_t.parquet',\n",
    "        'G_values_batch_50_6000_all_t.parquet',\n",
    "        'G_values_batch_50_9000_all_t.parquet',\n",
    "        'G_values_batch_50_12000_all_t.parquet'\n",
    "    ]\n",
    "    \n",
    "    temp_path = \"temp_valid.parquet\"\n",
    "    unique_pairs_G = pd.DataFrame()\n",
    "    \n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "\n",
    "    for file_name in file_list:  \n",
    "        final_df_valid = pd.DataFrame()\n",
    "        if directory_path is not None:\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory_path, file_name)        \n",
    "            print(file_path)\n",
    "\n",
    "            # Read the Parquet file from the specific directory\n",
    "            temp = pd.read_parquet(file_path, engine=\"fastparquet\")\n",
    "        \n",
    "        else:\n",
    "            temp = pd.read_parquet(file_name, engine=\"fastparquet\")\n",
    "            print(file_name)\n",
    "            \n",
    "        columns_to_check = ['gplus_0', 'gplus_1', 'gplus_2', 'gminus_0', 'gminus_1', 'gminus_2']\n",
    "\n",
    "        # Extract unique (i, j) pairs\n",
    "        pairs = temp[['i', 'j']].drop_duplicates()\n",
    "\n",
    "        # The following line is to check if any G column > 0, and consider it in neighborhood\n",
    "        ## Rerun this part\n",
    "        filtered_df = temp[temp[columns_to_check].gt(0).any(axis=1)]\n",
    "        \n",
    "        file_exists = os.path.isfile(temp_path)\n",
    "        if file_exists:\n",
    "            # Load existing data\n",
    "            final_df_valid = pd.read_parquet(temp_path)\n",
    "            # Concatenate the filtered DataFrame to final_df_valid\n",
    "            final_df_valid = pd.concat([final_df_valid, filtered_df], ignore_index=True)\n",
    "        else:\n",
    "            final_df_valid = filtered_df\n",
    "           \n",
    "        final_df_valid = final_df_valid.drop_duplicates()\n",
    "        final_df_valid.to_parquet(temp_path, index=False)\n",
    "   \n",
    "        \n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "   \n",
    "    if save_path is not None:\n",
    "        # Save the resulting DataFrame to a Parquet file\n",
    "        save_path_full = os.path.join(directory_path, save_path) \n",
    "        final_df_valid.to_parquet(save_path_full, index=False)\n",
    "    \n",
    "    print(final_df_valid.shape)\n",
    "    #return final_df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b27d98b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:17:00.761421Z",
     "start_time": "2025-02-16T11:17:00.742220Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# This function verifies how many rows of endogenous_data are present in g_df.\n",
    "# Specifically, it checks how many endogenous data pairs have valid G combinations \n",
    "# by comparing the (i, j, t) values in both DataFrames.\n",
    "# \n",
    "# The output provides:\n",
    "# - The total count of matches and mismatches.\n",
    "# - A DataFrame showing which (i, j, t) pairs exist in g_df.\n",
    "################################################################################\n",
    "def sanity_check_g_df(g_df):\n",
    "    print(g_df.shape)\n",
    "\n",
    "    # First, check if i, j, t from endogenous_data exists in g_df\n",
    "    matched_df = pd.merge(endogenous_data.get_data()[['i', 'j', 't']], \n",
    "                           g_df[['i', 'j', 't']], \n",
    "                           on=['i', 'j', 't'], \n",
    "                           how='left', \n",
    "                           indicator=True)\n",
    "    \n",
    "    # Check which rows in endogenous_data.get_data() are found in g_df\n",
    "    matched_df['exists_in_df1'] = matched_df['_merge'] == 'both'\n",
    "\n",
    "    print(\"Count in in endogenous_data.get_data() found in g_df:\")\n",
    "    print(matched_df['exists_in_df1'].value_counts())\n",
    "    #print(matched_df[['i', 'j', 't', 'exists_in_df1']])\n",
    "\n",
    "    # For rows where exists_in_df1 is False, check if reverse (j, i, t) exists in g_df\n",
    "    matched_df['exists_in_reverse_df'] = False  # Initialize the column with False\n",
    "    \n",
    "    # Iterate through rows where exists_in_df1 is False\n",
    "    for index, row in matched_df[matched_df['exists_in_df1'] == False].iterrows():\n",
    "        # Check if the reversed combination (j, i, t) exists in g_df\n",
    "        reversed_match = g_df[(g_df['j'] == row['i']) & (g_df['i'] == row['j']) & (g_df['t'] == row['t'])]\n",
    "        \n",
    "        if not reversed_match.empty:\n",
    "            matched_df.at[index, 'exists_in_reverse_df'] = True\n",
    "    \n",
    "    print(\"Rows with reversed match (j, i, t) found in g_df:\")\n",
    "    print(matched_df[['i', 'j', 't', 'exists_in_df1', 'exists_in_reverse_df']])\n",
    "\n",
    "    # Count occurrences of rows where the match is found in either exists_in_df1 or exists_in_reverse_df\n",
    "    count_exists_in_either = matched_df[['exists_in_df1', 'exists_in_reverse_df']].sum(axis=1).value_counts()\n",
    "\n",
    "    print(\"Count of rows present in either exists_in_df1 or exists_in_reverse_df:\")\n",
    "    print(count_exists_in_either)\n",
    "\n",
    "    return matched_df, count_exists_in_either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc148",
   "metadata": {},
   "source": [
    "### For tau3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55d1401f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T11:17:36.285657Z",
     "start_time": "2025-02-16T11:17:01.892150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33\\G_values_batch_50_0_all_t.parquet\n",
      "C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33\\G_values_batch_50_3000_all_t.parquet\n",
      "C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33\\G_values_batch_50_6000_all_t.parquet\n",
      "C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33\\G_values_batch_50_9000_all_t.parquet\n",
      "C:\\Users\\w.bi\\OneDrive - IESEG\\Desktop\\Domino\\data\\G_tau33\\G_values_batch_50_12000_all_t.parquet\n",
      "(4333809, 9)\n"
     ]
    }
   ],
   "source": [
    "# Extract valid G row\n",
    "# directory_path = os.path.join(DATA_DIR, 'G_tau' + str()) \n",
    "directory_path = os.path.join(DATA_DIR, 'G_tau33') \n",
    "# valid_G_save_path=\"G_values_all_valid_tau2.parquet\"\n",
    "valid_G_save_path='G_values_all_valid_tau' + str() + '.parquet'\n",
    "extract_valid_G_rows(directory_path,valid_G_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dde9cedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T09:34:15.557288Z",
     "start_time": "2025-02-16T09:29:49.991376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4333809, 9)\n",
      "(3544743, 11)\n",
      "Count in in endogenous_data.get_data() found in g_df:\n",
      "exists_in_df1\n",
      "True     18777\n",
      "False      257\n",
      "Name: count, dtype: int64\n",
      "Rows with reversed match (j, i, t) found in g_df:\n",
      "           i       j     t  exists_in_df1  exists_in_reverse_df\n",
      "0     -43095  -13745    73           True                 False\n",
      "1     -96837  -73430    73           True                 False\n",
      "2     -76539  -96837    74           True                 False\n",
      "3     -15617  -73430    75           True                 False\n",
      "4     -86247  -57615    75           True                 False\n",
      "...      ...     ...   ...            ...                   ...\n",
      "19029 -97988  -84068  8630           True                 False\n",
      "19030 -97988  -84068  8631           True                 False\n",
      "19031 -97224  -49394  8634           True                 False\n",
      "19032 -18530   -3873  8635           True                 False\n",
      "19033 -86289  -51298  8636           True                 False\n",
      "\n",
      "[19034 rows x 5 columns]\n",
      "Count of rows present in either exists_in_df1 or exists_in_reverse_df:\n",
      "1    18777\n",
      "0      257\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "## we read the file \"G_values_all_valid_tau3.parquet\" generated in the above step as g_df \n",
    "## We drop all the rows that has either (one inactive train) i inactive or j inactive\n",
    "###############################################################################\n",
    "# directory_path = os.path.join(DATA_DIR, 'G_tau' + str()) \n",
    "directory_path = os.path.join(DATA_DIR, 'G_tau33') \n",
    "valid_G_save_path='G_values_all_valid_tau' + str() + '.parquet'\n",
    "\n",
    "g_df =  read_function_data(os.path.join(directory_path, valid_G_save_path))\n",
    "print(g_df.shape)\n",
    "\n",
    "## We drop all the that has either i inactive or j inactive\n",
    "g_df['a_it'] = g_df.apply(lambda row: get_a_it('i', 't', row), axis=1)\n",
    "g_df['a_jt'] = g_df.apply(lambda row: get_a_it('j', 't', row), axis=1)\n",
    "\n",
    "g_df_filtered = g_df[(g_df['a_it'] != 0) & (g_df['a_jt'] != 0)]\n",
    "matched_df,count_exists_in_either =  sanity_check_g_df(g_df_filtered)\n",
    "matched_df.to_parquet('Delayed_train_with_valid_G_tau' + str() + '.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d171d9a-86fc-4a35-9b6f-04a45a2f19a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>_merge</th>\n",
       "      <th>exists_in_df1</th>\n",
       "      <th>exists_in_reverse_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-6089</td>\n",
       "      <td>-22532</td>\n",
       "      <td>111</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-13869</td>\n",
       "      <td>-39859</td>\n",
       "      <td>116</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-58780</td>\n",
       "      <td>-13252</td>\n",
       "      <td>119</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-51208</td>\n",
       "      <td>-12350</td>\n",
       "      <td>168</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-60939</td>\n",
       "      <td>-50524</td>\n",
       "      <td>197</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18969</th>\n",
       "      <td>-15181</td>\n",
       "      <td>-27755</td>\n",
       "      <td>8596</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>-87423</td>\n",
       "      <td>-85801</td>\n",
       "      <td>8598</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>-82704</td>\n",
       "      <td>-71541</td>\n",
       "      <td>8615</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19008</th>\n",
       "      <td>-51298</td>\n",
       "      <td>-96659</td>\n",
       "      <td>8618</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19021</th>\n",
       "      <td>-64666</td>\n",
       "      <td>-84068</td>\n",
       "      <td>8625</td>\n",
       "      <td>left_only</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           i       j     t     _merge  exists_in_df1  exists_in_reverse_df\n",
       "66     -6089  -22532   111  left_only          False                 False\n",
       "75    -13869  -39859   116  left_only          False                 False\n",
       "86    -58780  -13252   119  left_only          False                 False\n",
       "179   -51208  -12350   168  left_only          False                 False\n",
       "211   -60939  -50524   197  left_only          False                 False\n",
       "...      ...     ...   ...        ...            ...                   ...\n",
       "18969 -15181  -27755  8596  left_only          False                 False\n",
       "18976 -87423  -85801  8598  left_only          False                 False\n",
       "19000 -82704  -71541  8615  left_only          False                 False\n",
       "19008 -51298  -96659  8618  left_only          False                 False\n",
       "19021 -64666  -84068  8625  left_only          False                 False\n",
       "\n",
       "[728 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = matched_df[matched_df['exists_in_df1']==0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9a0f691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:42:30.397036Z",
     "start_time": "2024-11-19T16:39:16.726237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3544743, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gplus_0</th>\n",
       "      <th>gplus_1</th>\n",
       "      <th>gplus_2</th>\n",
       "      <th>gminus_0</th>\n",
       "      <th>gminus_1</th>\n",
       "      <th>gminus_2</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>a_it</th>\n",
       "      <th>a_jt</th>\n",
       "      <th>c</th>\n",
       "      <th>w_{i,j,t}^c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3930509</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99970</td>\n",
       "      <td>-71996</td>\n",
       "      <td>831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99970</td>\n",
       "      <td>-71996</td>\n",
       "      <td>833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99970</td>\n",
       "      <td>-71996</td>\n",
       "      <td>1119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930512</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99970</td>\n",
       "      <td>-71996</td>\n",
       "      <td>1120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-99970</td>\n",
       "      <td>-71996</td>\n",
       "      <td>1121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-17</td>\n",
       "      <td>-9056</td>\n",
       "      <td>26120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-17</td>\n",
       "      <td>-9056</td>\n",
       "      <td>26121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-17</td>\n",
       "      <td>-9056</td>\n",
       "      <td>26122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-17</td>\n",
       "      <td>-9056</td>\n",
       "      <td>26123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-17</td>\n",
       "      <td>-9056</td>\n",
       "      <td>26124</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6198995 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gplus_0  gplus_1  gplus_2  gminus_0  gminus_1  gminus_2      i  \\\n",
       "3930509        1        0        0         0         0         0 -99970   \n",
       "3930510        0        0        0         1         0         0 -99970   \n",
       "3930511        0        0        2         0         0         0 -99970   \n",
       "3930512        0        1        3         0         0         0 -99970   \n",
       "3930513        0        0        1         0         0         3 -99970   \n",
       "...          ...      ...      ...       ...       ...       ...    ...   \n",
       "1357200        1        0        1         1         1         3    -17   \n",
       "1357201        0        0        0         0         1         5    -17   \n",
       "1357202        0        0        0         2         0         1    -17   \n",
       "1357203        0        0        0         1         0         1    -17   \n",
       "1357204        0        0        0         0         0         1    -17   \n",
       "\n",
       "             j      t  a_it  a_jt     c  w_{i,j,t}^c  \n",
       "3930509 -71996    831     1     1  1134            0  \n",
       "3930510 -71996    833     1     1  1134            0  \n",
       "3930511 -71996   1119     1     1  1134            0  \n",
       "3930512 -71996   1120     1     1  1134            0  \n",
       "3930513 -71996   1121     1     1  1134            0  \n",
       "...        ...    ...   ...   ...   ...          ...  \n",
       "1357200  -9056  26120     1     1  1137            0  \n",
       "1357201  -9056  26121     1     1  1137            0  \n",
       "1357202  -9056  26122     1     1  1137            0  \n",
       "1357203  -9056  26123     1     1  1137            0  \n",
       "1357204  -9056  26124     1     1  1137            0  \n",
       "\n",
       "[6198995 rows x 13 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "# This function extracts relevant G_column values from g_df for each i, j, c pair \n",
    "# in the endogenous_data DataFrame. It combines these values with the endogenous_data \n",
    "# and saves the result to a Parquet file at the specified path (ENDODATA_WITH_G_FILE_PATH).\n",
    "# \n",
    "# The resulting file will be used to populate regression input fields such as:\n",
    "# - primarydelay\n",
    "# - secondarydelay\n",
    "# - recovery\n",
    "# - total_delay\n",
    "################################################################################\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "def process_row(pair, g_df):\n",
    "    # Filter the relevant rows in g_df\n",
    "    df = g_df[(g_df['i'] == pair['i']) & (g_df['j'] == pair['j'])]\n",
    "    df['c'] = pair['c']\n",
    "\n",
    "    # Create the filtered_df excluding the current 't'\n",
    "    filtered_df = df[df['t'] != pair['t']].copy()\n",
    "    filtered_df['w_{i,j,t}^c'] = 0\n",
    "\n",
    "    # Current pair data where 't' matches\n",
    "    curr_df = df[df['t'] == pair['t']].copy()\n",
    "    curr_df['w_{i,j,t}^c'] = pair['w_{i,j,t}^c']\n",
    "\n",
    "    return pd.concat([curr_df, filtered_df])\n",
    "\n",
    "def fill_G_on_Endogenous_data(g_df, endogenous_data,save_path=None):\n",
    "    # Apply the process_row function to each row of endogenous_data\n",
    "    print(g_df.shape)\n",
    "    output_list = endogenous_data.get_data().apply(lambda row: process_row(row, g_df), axis=1)\n",
    "\n",
    "    # Concatenate all the DataFrames in the output list\n",
    "    output = pd.concat(output_list.tolist(), ignore_index=True)\n",
    "\n",
    "    # Sort the final output (optional if needed)\n",
    "    output = output.sort_values(by=['i', 'j', 't'])\n",
    "    \n",
    "    if save_path is not None:\n",
    "        # Save the result to a parquet file\n",
    "        output.to_parquet(save_path, index=False)\n",
    "        \n",
    "    return output\n",
    "\n",
    "tmax_sec_delay = sec_delay_df['t'].max()\n",
    "g_df_filtered = g_df_filtered[(g_df_filtered['a_it'] <= tmax_sec_delay)]\n",
    "fill_G_on_Endogenous_data(g_df_filtered, endogenous_data, save_path=ENDODATA_WITH_G_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a7d97-ea05-47e3-b28f-02af52880088",
   "metadata": {},
   "source": [
    "### Filling delay for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "296462d8-3be0-41e0-bc9e-8fa0eb4f966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wjt_observed(j,t,D_it,row=None, delay_df=w_it_df):\n",
    "    \"\"\"\n",
    "    Find total delay for a given train 'j' at the time t.\n",
    "\n",
    "    Parameters:\n",
    "    - j (int): Train identifier.\n",
    "    - t : time.\n",
    "    - D_i: Value for 'D_i' (Departure time of the train)\n",
    "    \n",
    "     Returns:\n",
    "    - int : total delay at time t .\n",
    "    \"\"\"\n",
    "    \n",
    "    if row is not None:\n",
    "        j = row['j']\n",
    "        t = row['t']\n",
    "        D_it = row['D_it']\n",
    "    \n",
    "    if t >= D_it:\n",
    "        return delay_df[j].iloc[t]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9cba1c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:06:35.517216Z",
     "start_time": "2024-11-20T01:27:42.197684Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# In this step, we process the data from the file ENDODATA_WITH_G_FILE_PATH \n",
    "# (generated in the previous step) and compute additional metrics for each row.\n",
    "#\n",
    "# Steps:\n",
    "# 1. Read the data file ENDODATA_WITH_G_FILE_PATH into a DataFrame (`result`).\n",
    "# 2. Compute the departure time ('D_it') for each train using the `get_D_it` function.\n",
    "# 3. Calculate the following delay metrics:\n",
    "#    - Secondary delay: Using the `get_secondary_delay` function.\n",
    "#    - Primary delay: Using the `get_primary_delay` function.\n",
    "# 4. Save the updated DataFrame, including the delay metrics, to the file \n",
    "#    ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH for further use.\n",
    "################################################################################\n",
    "\n",
    "result  =  read_function_data(ENDODATA_WITH_G_FILE_PATH)    \n",
    "result['D_it'] = result.apply(lambda row: get_D_it('i', 't', row), axis=1)\n",
    "result['D_it'] = result['D_it'].astype(int)\n",
    "\n",
    "# print(\"Filling secondary delay\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# result['secondary_delay'] = result.apply(lambda row: get_secondary_delay(row['j'], row['t'], row['D_it'],endogenous_data), axis=1)\n",
    "# # result['secondary_delay'] = result.apply(lambda row: get_secondary_delay(row['i'], row['t'], row['D_it'],endogenous_data), axis=1)\n",
    "\n",
    "# print(\"Filling primary delay\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# result['primary_delay'] = result.apply(lambda row: get_primary_delay(row['j'], row['t'], row['D_it']), axis=1)\n",
    "# # result['primary_delay'] = result.apply(lambda row: get_primary_delay(row['i'], row['t'], row['D_it']), axis=1)\n",
    "result.to_parquet(ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62b6b907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:34:05.567144Z",
     "start_time": "2024-11-20T04:31:54.047026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling wjt_observed 2025-12-21 04:40:16\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# In this step, we process the data containing secondary delay and primary delay\n",
    "# (from the file ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH) to compute additional metrics.\n",
    "#\n",
    "# Steps:\n",
    "# 1. Read the data file ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH into a DataFrame (`result`).\n",
    "# 2. Remove duplicate rows based on the columns combination ['i', 'j', 't', 'c'].\n",
    "# 3. Compute the below metrics:\n",
    "#    - `wit_observed`: Using the `get_wit_observed` function.\n",
    "#    - `recovery`: Calculated as the difference between `wit_observed` and the \n",
    "#       sum of `primary_delay` and `secondary_delay`.\n",
    "#    - `wit_estimated`: Calculated as the sum of `primary_delay`, \n",
    "#       `secondary_delay`, and `recovery`.\n",
    "# 4. Save the updated DataFrame to the file \n",
    "#    REGRESSION_INPUT_VALID_G_FILE_PATH to use for regression.\n",
    "################################################################################\n",
    "\n",
    "result = read_function_data(ENDODATA_WITH_G_PRI_SEC_DELAY_FILE_PATH)\n",
    "\n",
    "### bug checked\n",
    "result = result.sort_values(\"w_{i,j,t}^c\", ascending=False)\n",
    "result = result.drop_duplicates(subset=['i', 'j', 't', 'c'])\n",
    "result = result.sort_index()\n",
    "\n",
    "# result = result.drop_duplicates(subset=['i', 'j', 't', 'c'])\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "\n",
    "## change from wit to wjt\n",
    "print(\"Filling wjt_observed\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "result['wjt'] = result.apply(lambda row: get_wjt_observed('j', 't','D_it',row), axis=1)\n",
    "result['wit-1'] = result.apply(lambda row: get_wit_observed('i', 't','D_it',row), axis=1)\n",
    "\n",
    "\n",
    "# print(\"Filling recovery\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "# result['recovery'] = result.apply(lambda row: row['wit_observed']-(row['primary_delay'] + row['secondary_delay']), axis=1)\n",
    "# result['wit_estimated'] = result.apply(lambda row: (row['primary_delay'] + row['secondary_delay']) + row['recovery'], axis=1)\n",
    "\n",
    "result.to_csv(REGRESSION_INPUT_VALID_G_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0da0e6bc-31ef-4a84-a50f-f8ae3f724f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wjt_deltas(w_it_df):\n",
    "    \"\"\"Compute wjt, wjt-1, wjt-2, wjt-3 for each train j.\"\"\"\n",
    "    w_it_df = w_it_df.sort_index()\n",
    "    # delta_0 = wjt - wjt-1\n",
    "    delta_0 = w_it_df.diff(1)\n",
    "    \n",
    "    # delta_1 = wjt-1 - wjt-2\n",
    "    delta_1 = w_it_df.shift(1).diff(1)\n",
    "    \n",
    "    # delta_2 = wjt-2 - wjt-3\n",
    "    delta_2 = w_it_df.shift(2).diff(1)\n",
    "    \n",
    "    # delta_2 = wjt-2 - wjt-3\n",
    "    delta_3 = w_it_df.shift(3).diff(1) \n",
    "    \n",
    "    delta_0 = delta_0.fillna(0)\n",
    "    delta_1 = delta_1.fillna(0)\n",
    "    delta_2 = delta_2.fillna(0)\n",
    "    delta_3 = delta_3.fillna(0)\n",
    "    \n",
    "    return {\n",
    "        'wjt': delta_0,\n",
    "        'wjt-1': delta_1,\n",
    "        'wjt-2': delta_2,\n",
    "        'wjt-3': delta_3\n",
    "    }\n",
    "\n",
    "deltas = compute_wjt_deltas(w_it_df)\n",
    "\n",
    "delta_merge_df = (\n",
    "    pd.concat({\n",
    "        name: ddf.stack()\n",
    "        for name, ddf in deltas.items()\n",
    "    }, axis=1)\n",
    "    .reset_index()\n",
    ")\n",
    "delta_merge_df.columns = ['t', 'j', 'wjt', 'wjt-1', 'wjt-2', 'wjt-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b7ef0fc-6949-4389-9218-fdbd25625898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2fbbd71a-7de6-4205-b8f9-0ed89d754bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both are sorted by ['j', 't']\n",
    "result = result.sort_values(['j', 't'])\n",
    "delta_merge_df = delta_merge_df.sort_values(['j', 't'])\n",
    "\n",
    "# Initialize an empty list to collect results\n",
    "merged_parts = []\n",
    "\n",
    "# Loop through each j (train) to merge only relevant rows\n",
    "for j_val, part in result.groupby('j'):\n",
    "    delta_part = delta_merge_df[delta_merge_df['j'] == j_val]\n",
    "    merged = pd.merge(part, delta_part, on=['t', 'j'], how='left')\n",
    "    merged_parts.append(merged)\n",
    "\n",
    "# Concatenate all small merged results\n",
    "result = pd.concat(merged_parts, ignore_index=True)\n",
    "\n",
    "# Fill missing deltas with 0\n",
    "for col in ['wjt', 'wjt-1', 'wjt-2', 'wjt-3']:\n",
    "    if col in result.columns:\n",
    "        result[col] = result[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c4b663a-fcee-474f-9a5d-55ce06de3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result.merge(delta_merge_df, on=['t', 'j'], how='left')\n",
    "# result[['wjt', 'wjt-1', 'wjt-2', 'wjt-3']] = result[['wjt', 'wjt-1', 'wjt-2', 'wjt-3']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f284415-9044-4a8d-a188-7719907079fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gplus_0</th>\n",
       "      <th>gplus_1</th>\n",
       "      <th>gplus_2</th>\n",
       "      <th>gminus_0</th>\n",
       "      <th>gminus_1</th>\n",
       "      <th>gminus_2</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>t</th>\n",
       "      <th>a_it</th>\n",
       "      <th>a_jt</th>\n",
       "      <th>c</th>\n",
       "      <th>w_{i,j,t}^c</th>\n",
       "      <th>D_it</th>\n",
       "      <th>wjt</th>\n",
       "      <th>wit-1</th>\n",
       "      <th>wjt</th>\n",
       "      <th>wjt-1</th>\n",
       "      <th>wjt-2</th>\n",
       "      <th>wjt-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-39113</td>\n",
       "      <td>-99970</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-39113</td>\n",
       "      <td>-99970</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>12</td>\n",
       "      <td>-54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-39113</td>\n",
       "      <td>-99970</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>12</td>\n",
       "      <td>-64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-92825</td>\n",
       "      <td>-99970</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-39113</td>\n",
       "      <td>-99970</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1134</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>19</td>\n",
       "      <td>-20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409873</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7078</td>\n",
       "      <td>-17</td>\n",
       "      <td>26130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>26122</td>\n",
       "      <td>-122</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409874</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7078</td>\n",
       "      <td>-17</td>\n",
       "      <td>26131</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>26122</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409875</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-7078</td>\n",
       "      <td>-17</td>\n",
       "      <td>26132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>26122</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409876</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-7078</td>\n",
       "      <td>-17</td>\n",
       "      <td>26133</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>26122</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-7078</td>\n",
       "      <td>-17</td>\n",
       "      <td>26134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>26122</td>\n",
       "      <td>178</td>\n",
       "      <td>17</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2409878 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gplus_0  gplus_1  gplus_2  gminus_0  gminus_1  gminus_2      i  \\\n",
       "0              1        1        0         0         0         0 -39113   \n",
       "1              0        0        0         1         1         0 -39113   \n",
       "2              1        1        1         0         0         0 -39113   \n",
       "3              4        1        0         2         1         0 -92825   \n",
       "4              0        0        0         1         1         1 -39113   \n",
       "...          ...      ...      ...       ...       ...       ...    ...   \n",
       "2409873        1        0        0         0         0         0  -7078   \n",
       "2409874        4        2        2         1         0         0  -7078   \n",
       "2409875        3        1        2         4         2         2  -7078   \n",
       "2409876        2        1        0         3         1         2  -7078   \n",
       "2409877        0        0        0         2         1         0  -7078   \n",
       "\n",
       "             j      t  a_it  a_jt     c  w_{i,j,t}^c   D_it  wjt  wit-1  \\\n",
       "0       -99970    232     1     1  1134            0    205   12      8   \n",
       "1       -99970    233     1     1  1134            0    205   12    -54   \n",
       "2       -99970    234     1     1  1134            0    205   12    -64   \n",
       "3       -99970    235     1     1  1136            0    235   19      0   \n",
       "4       -99970    235     1     1  1134            0    205   19    -20   \n",
       "...        ...    ...   ...   ...   ...          ...    ...  ...    ...   \n",
       "2409873    -17  26130     1     1  1137            0  26122 -122     20   \n",
       "2409874    -17  26131     1     1  1137            0  26122   18      6   \n",
       "2409875    -17  26132     1     1  1137            0  26122   22     21   \n",
       "2409876    -17  26133     1     1  1137            0  26122   22     31   \n",
       "2409877    -17  26134     1     1  1137            0  26122  178     17   \n",
       "\n",
       "          wjt  wjt-1  wjt-2  wjt-3  \n",
       "0        -26.0    10.0    28.0     0.0  \n",
       "1          0.0   -26.0    10.0    28.0  \n",
       "2          0.0     0.0   -26.0    10.0  \n",
       "3          7.0     0.0     0.0   -26.0  \n",
       "4          7.0     0.0     0.0   -26.0  \n",
       "...        ...     ...     ...     ...  \n",
       "2409873    0.0   -44.0   -11.0   -63.0  \n",
       "2409874  140.0     0.0   -44.0   -11.0  \n",
       "2409875    4.0   140.0     0.0   -44.0  \n",
       "2409876    0.0     4.0   140.0     0.0  \n",
       "2409877  156.0     0.0     4.0   140.0  \n",
       "\n",
       "[2409878 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a211a421-ff1a-48dd-a1d8-4f5ffc275e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(REGRESSION_INPUT_VALID_G_DALTA_FILE_PATH , index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.036px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
